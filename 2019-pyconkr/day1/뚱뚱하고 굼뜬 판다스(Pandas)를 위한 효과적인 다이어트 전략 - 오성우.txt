https://youtu.be/0Vm9Yi_ig58

@오성우 님 강연 내용@
-안녕하세요? 이번 시간에는 오성우 님께서 뚱뚱하고 굼뜬 판다를 위한 효과적인 다이어트 전략이라는 내용으로 25분간 발표하겠습니다. 질의응답은 발표 후 시간이 남으면 하도록 하겠습니다. 그럼 큰 박수 부탁드리겠습니다.
-안녕하세요? 발표를 맡은 오성우입니다. 처음에 발표 제목을 정했을 때 공격적인 단어인데 뚱뚱하고 굼뜬 게 아니라 탐욕스럽고 게으른 판다. 판다를 알게 된 게 5년 전인데 그러다 판다스를 알면서 효율적으로 처리했고 판다스를 송별사로 진행하려고 했었어요. 데이터를 효과적으로 다루는 프로젝트. 중간에 물어보니까 여전히 데이터 분석을 입문하는 분들이 많아서 판다스 사용도 많고 궁금한 게 많다고 느껴서 어떻게 하면 실제 데이터 분석을 할 때 예제를 할 때랑 달라서 어떤 부분이 이슈가 있는지 그런 부분을 집중적으로 다루는 시간이 되도록 하겠습니다.
이후에 추가적인 궁금한 점 있으면 제 메일로 연락 주시면 감사하겠습니다. 판다스는 명실상부하게 모두가 인정하는 데이터 분석하는 자료 처리하는 자료구조죠. 공식 문서에 따르면 판다스는 관계형 데이터로 빠르게 효율적으로 사용한다고 나와 있는데 관계형에 집중해주면 좋을 것 같습니다. 이번에 말씀드리는 예제는 관계형이라는 의미가 많이 들어가서 데이터베이스에서 쓰는 걸 차용했습니다.
이 부분은 잘 모르는 분이 많은데 7월에 0.25버전 나오면서 1.0으로 가기 위한 마지막 단계를 밟았습니다. 어떤 부분이 변하게 될지 보도록 하겠습니다. 판다의 데이터 생태계를 보는데 심플해서 가져와봤습니다. 수치 양상이나 시각화에 대해서 사용하고 사실 처음 나왔을 때만 해도 매직 같았거든요. 파이썬의 기본 자료구조 자체를 써서 데이터를 처리하면 속도도 느린데 매직 같은 판다스가 실제 사용하다 보면 데이터를 읽지 못해서 메모리가 로딩되고 하루 종일 걸릴 때도 있고 쓰는 방식도 다 달라서 나중에 기술부채 발생해서 운영도 어렵고.
탐욕스럽고 게으른 판다인데 판다스가 가지는 문제점이 판다스 자체에 있습니다. 메모리 맵핑 이슈가 좀 있고 파이썬 자체가 가비지 콜렉팅을 모토로 하기 때문에 메모리 찌꺼기도 생기는 구조고 실제 데이터 처리할 때는 싱글 CPU 코어만 사용하는 문제가 있어서 판다스 빠르다는데 나는 왜 느리지? 이런 것을 느끼게 됩니다. 파이썬 웨이라는, 사람들이 쉽게 쓰다 보니까 쓰면서 실제로 느려지는 문제가 있는데 다이어트 전략이라고 해서 최근에 다이어트를 해봤어요. 덜 먹으면 일을 잘할까? 했는데 식사량을 조절하고 식이요법을 생활습관을 바꾸는 게 실제 다이어트에서 효과적인 것처럼 판다스도 이런 전략이 요구됩니다.
식사량 조절 같은 경우는 메모리를 어떻게 최적화하는지 그리고 식이요법 같은 경우는 우리가 맛있게 먹고 운동을 어떻게 하는지 퍼포먼스를 어떻게 하면 올리는지에 대한 내용이고 생활습관은 컨벤션에 대한 소개입니다. 다이어트 전략 공략하는 부분은 수치현상 부분이나 데이터 접근하는 것에 맞춰져 있습니다. 데이터 분석을 많이 하니까 예제 데이터로 보여주는 게 좀 그래서 우리가 많이 쓰는 데이터를 가져왔고 국민건강보험공단에서 공공데이터로 제공하는 4억 건 데이터 일부를 전철해서 사용했습니다. 사용하는 데이터는 건강검진 우리가 건강검진 받으면 예를 들면 혈당이 몇이고 신체지수가 어떻게 되고 이런 걸 다루고 병원에 방문하면 나타나는 진료 내역.
다이어트 전략은 쭉 순서대로 하나, 둘, 셋 이어서 설명드리도록 하겠습니다. 판다스를 만든 웨스 맥키니가 했던 말인데 실제 파일보다 5, 10배 메모리를 차지하더라. 3~5 배는 내가 생각했던 것보다 메모리를 차지했거든요. 큰 사이즈 데이터를 어떻게 효과적으로 처리하는지. 제가 실제로 하는 방법을 순서대로 보여드리려고 합니다. 코드화는 데이터베이스 모델링하거나. 자료 처리하는 건 숫자 맵핑하는 거 익숙한데 남자를 0, 여자를 1로 기호로 맵핑하는 게 코드화입니다. 한글 코드화 결과인데요.
성별이라든지 그 사람이 살고 있는 지역, 전라북도 이런 식으로 돼 있는 것들을 맵 코드화만 해도 굉장히 많은 메모리가 사용 감소됩니다. 다른 발표에서도 데이터 타입에 대한 내용이 나왔는데 판다스는 각 컬럼 자체 고정된 바이터 크기를 제공합니다. 그리고 이 방식 자체가 가장 큰 데이터 타입 주도로 돼 있기 때문에 그냥 내가 실습 리드하게 되면 굉장히 많이 사용하게 되고 그래서 탐욕스럽다고 표현했습니다.
저 같은 경우는 크게 3가지 경우로 나눠서 데이터 형식을 하는데 보통은 제가 데이터를 수집하고 처리하기 때문에 데이터 형식을 압니다. 직접 불러올 때 데이터 형식을 입력하는 경우를 많이 사용하는데 프로젝트에 들어가는데 모델 정의서가 없다든가 컬럼이 수백 개가 돼서 일일이 치기 어려울 때 함수를 이용해서 형식을 진행합니다.
문서로 소개하고 넘어가고요. 생각보다 많은 분이 잘 모르시더라고요. R에서 팩터 있잖아요. 판다스에서도 똑같이 카테고리라는 형태로 제공되는데 100% 기능은 동일하지 않아도 범주형을 다룬다는 차원에서 유사함이 있습니다. 데이터를 인트 형태로 저장하기 때문에 메모리 사용량이 우리가 일반적으로 하면 문자열은 오브젝트가 되거든요. 오브젝트보다 훨씬 많이 쓰고 데이터 처리할 때 많은 차이가 있습니다. 범주별 시각화할 때도 편의성이 높습니다.
카테고리 사용을 해서 분석이나 처리 속도가 굉장히 많이 빨라졌는데 진료 데이터 질병 병원을 방문하면 의사가 처방하는 처방전 봤을 때 최빈도 질병 어떤 질병이 많이 나타나는지 분석했을 때 오브젝트 타입과 카테고리 타입을 비교했더니 8배 이상 차이가 나는 걸 확인할 수 있었습니다. 다시 메모리 최적화로 돌아와 보면 이러한 일련의 과정을 거치면 메모리 사용량이 90% 가까이 줄어들게 됩니다. 개인 노트북을 쓴다든가 회사 데스크톱을 진행하면 데이터 열지도 못했는데 이런 방법을 사용하면 처리 속도도 빠르게 됩니다.
그리고 사실 저희가 한 번에 모든 일이 끝나지 않잖아요. 지속적으로 써야 하고 공유도 해야 하고 아니면 내가 다시 써야 할 때가 있죠. 그럴 때 데이터를 어떻게 저장할지 중요한데 csv를 많이 쓰는데 효율이 많이 떨어집니다. 스트링 기반이기 때문에. 예를 들면 데이터 형식이라든가 여러 가지 문제가 있습니다. 사실 실무에서 많이 쓰는 건 HDF5, 파켓 많이 쓰고 피클이나 페더는 보안 이슈가 없을 때 종종 사용합니다. 어떤 차이가 있는지 비교해보려고 하는데요. 데이터를 저장하고 로드하는 것도 되게 중요하잖아요.
csv는 굉장히 오래 걸리는 거 확인할 수 있고요. 그리고 인풋 아웃풋 우리가 할 때 메모리를 쓰게 됩니다. 그런데 실제 메모리를 최종적으로 쓰는 건 3GB지만 메모리를 읽는 과정에서 사용이 올라가는데 이럴 때 안전성도 중요합니다. 이럴 때는 팟케이가 안정성이 높고 우리가 다 돈이잖아요. AWS만 써도 돈인데 저장되는 크기도 중요하고 공유하려면 작아야 하잖아요. 시간이고 돈인데. 압축된 형태로 제공돼서 많이 작은 걸 확인할 수 있습니다. 개인적으로는 페더나 피클을 간단하게 쓸 때는 사용하는데요.
다른 사람들과 할 때는 내가 스파크 환경이나 다른 데스크나 파케이를 많이 쓰고 HDF5도 많이 쓰죠. 동일하게 판다스에서 사용할 수 있는 이러한 것들을 추천합니다. 첫 번째 전략을 요약하면 데이터 불러올 때 데이터 타입 형식이라든가 카테고리만 잘해도 90% 가까이 메모리를 줄일 수 있고 불러오지 못했던 것도 불러올 수 있고 시간과 메모리를 아낄 수 있다, 저장을 잘하자.
다른 방법도 있는데 이건 지나가도록 하겠습니다. 속도를 높이는 게 사실 어떻게 보면 관건이죠. 데이터 분석하다 딱 눌렀는데 얼마나 걸려야 하지 하고 멍때리다 내가 뭐 했지?, 까먹는 게 있죠. 일종의 팁을 말씀드리려고 합니다.
머신러닝이나 딥러닝 이야기가 나오면서 벡터화는 아실 건데 간단하게 말씀드리면 왼쪽에 있는 A와 B라는 2개의 배열을 각각의 원소를 더하거나 곱하거나 연산하면 우리가 반복문을 쓰게 되면 5번이 필요한데 벡터화 연산하면 1번만으로도 가능하게 돼서 굉장히 속도가 빨라지는 거죠.
이거 역시도 벡터라이지네이션이 실제 진행해봤는데 건강검진을 받은 100만 명 사람이 건강검진을 받으면 실제로 위험한지 스코어를 분석하는 걸 했습니다. 웨이트나 BMI 계산해서 계산하고 허리 둘레, 혈당 수치로 스코어 매기는 작업를 했습니다. 비교하는 내용들은 우리가 파이썬 딱 배우는 하는 것들 있잖아요. 랭스, 레인지 넣어서 반복문 돌리는 이 방법부터 판다스에서 제공하는 어플라이 벡터라이제이션은 판다스 시리즈랑 넘파이 배열 2개로 했습니다.
빨라도 너무 빨랐습니다. 600배 넘게 몇 분 걸리던 게 1초도 안 돼서 끝나는 걸 볼 수 있는데 벡터라이제이션을 어떻게 쓰는지가 중요합니다. 넘파이 계열을 쓰는 게 훨씬 빠르다. 텐서 오퍼레이션을 쉽게 바꿔주는 것처럼 데코레이터를 써주기만 해도 A와 B에 리스트를 넣으면 벡터 연산을 해줍니다.
두 번째는 효율적인 알고리즘를 고려해야 하는데 하다 보면 같은 건데 왜 오래 걸리지? 어떤 방법을 써야 하지? 이런 게 있는데 사실 정답은 없습니다. 그런데 판다스 안에 거의 수백 개의 메소드 어트리뷰트가 있어서 어떻게 조합하냐에 따라서 몇 시간 걸리던 게 1초에 끝나고 말도 안 되는 일들이 있는데 이런 게 중요하다는 걸 말씀드리기 위해서 진행하겠습니다.
이것도 실제 데이터 분석으로 진행했는데 진료 내역 데이터에는 청구할 때 돈이 필요하거든요. 청구비용이 높은 상위 4000만 개 중에서 5개를 뽑는 것을 진행했습니다. 일반적으로 우리가 생각했을 때는 내림차순으로 쭉 정렬해서 상위 5개를 뽑으면 상위 5개가 아니냐고 할 수 있는데 이렇게 했을 경우에는 8초 정도 걸렸고 아시는 분들도 많겠지만 판다스 N 가장 큰 메소드를 뽑아달라는 거 하면 0.68초? 실제 데이터에 가까워질수록 갭이 늘어나서 이런 게 쌓이다 보면 하나의 시스템 안에서 부하되는데 효율적인 알고리즘을 한 번이라도 생각해보고 하는 게 중요하다는 것을 말씀드리고 싶습니다.
제 주변에도 물어보는데 어플라이 쓰니까 왜 느린지 모르겠다. 커스텀 함수할 때 어플라이 넣어주면 빠른데 조건 추출한다거나 그룹 함수를 만들어서 뭔가 작업할 때 하는데 생각보다 네이버 알고리즘이 안 좋게 짜 있어서 속도가 항상 느립니다. 이걸 어떻게 하면 좋은 방법이 있을까 저도 고민을 많이 했고 한 예를 보여드리고 싶어서 가져왔습니다. 저희가 앞에서 벡터라이제이션 건강운영지수를 계산했잖아요. 건강표인데 상위에 문제가 있었던 7000명을 뽑았습니다. 7000명의 페이션트 ID 코드로 오른쪽에 있는 진료 데이터에서 페이션트들만 추출해보자 하는 게 이번 목표입니다.
진료내역을 추출하기 위한 방법인데 인 조건절을 써서 리스트 안에 환자가 있는지 조건을 통해서 추출하는 방법을 공통적으로 썼습니다. 이걸 위해서 어플라이도 사용하고 판다스에 있는 이지, 쿼리, 넘파이, 우리가 조인으로 쓰는 머지 같은 걸 가져왔습니다. 당연히 밑에 있는 게 훨씬 빨랐는데 빨라도 진짜 이것도 많이 차이가 났습니다. 우리가 어플라이를 썼을 때는 몇 분씩 걸리던 게 밑으로 갈수록 초단위로 빨라지죠. 흥미로운 건 조건을 확인하기 위해서 쉽게 이해할 수 있지만 머지 같은 경우는 생각하지 못했던 거죠.
데이터베이스를 짜는 분들은 이런 게 익숙한데 관계형이 중요하다는 이야기를 했었고 그래서 한번만 고민해보면 훨씬 더 빠르고 좋은 방법이 있다는 걸 말씀드리고 싶었습니다. 두 번째 전략을 요약해보면 가능하면 파이썬 이게 다른 언어 쓰시는 분들은 반복문 사용이 익숙해서 C++ 하시는 분들도 판다스 코드 짜는 거 보면 반복문을 사용하더라고요. 반복문 사용은 파이썬에서 피하고 벡터라이제이션 쓰시고 수행해보니까 감당할 수 없는 수준이라면 알고리즘을 고려해보고 커스텀 함수를 꼭 만들어야 하는지 고민해보면 좋을 것 같습니다.
가능하다면 빌트인을 조합하는 게 좋습니다. 마지막 생활습관까지 왔는데 컨벤션 같은 게 있습니다. 이런 걸 지켜주시는 게 앞으로 판다스 1.0에서 고려되는 것들이라 신경 써주면 좋겠습니다. 그래서 세 번째 전략은 마지막 전략인데 마지막 목표는 코딩 컨벤션이 어떤 게 있고 간략하게 소개하겠습니다. 첫 번째는 메소드 체이닝인데 컬럼에서 비율을 구하는 걸 해본 분들은 일종의 메소드 체인인데 오른쪽 아래 보시면 메소드 체이닝에 대한 예가 있는데 메소드를 함수를 계속 붙여나가는 방식이어서 가독성도 좋고 성능이 좋다고 판다스 개발자들은 말하는데 진짜 좋은지는 여러 검증을 해봤는데 좀 의문이었고 많은 소스를 봤을 때도 의문이 들기는 했습니다.
어쨌든 이 방법을 쓰라고 권장하고 있고 이런 식으로 개발하고 있다고 하더라고요. 그리고 인플레이스 파라미터인데 많이 사용하고 있습니다. 판다스 내부에서는 이슈가 많습니다. 얘를 꼭 써야 하냐? 쓰지 말아야 한다 이야기가 있고 써야 하는 사람들은 일부 데이터만 덮어씌우기 때문에 좋다고 하는데 반대하고 있거든요. 일부 메소드들은 제거하는 방향으로 이미 가닥을 잡았습니다. 이게 문제가 되는 게 인플레이스 실행한 다음에 메모리가 남아서. 어떤 식으로 사용하는가는 나중에 보시면서 이럴 때는 써야겠다, 데이터를 줄여야 할 때는 메소드 체이닝을 일부만 바꿀 때는 인플레이스를 사용하는 걸 추천합니다. 디프레케이션은 시간이 부족해서 판다스 핵심 개발자가 발표한 내용이 있는데 링크를 참고해서 보시면 좋을 것 같습니다.
이렇게 기타 유의사항이라고 적어놨는데 분석하면 판다스를 쓰다 보면 케이스 바이 케이스입니다. 방금 말씀드린 것도 데이터가 어떻냐에 따라서 달라지기 때문에 수백 개의 메소드를 어떻게 할지 고민하는 게 좋고 파이썬 자체의 한계이기도 한데 창조를 없앴음에도 메모리에 남아 있어서 나는 데이터 안 쓰고 있는데 메모리 다 차서 더 이상 안 된다 이런 얘기가 나왔는데 가비지 컬렉션 문제입니다. 필요할 때는 직접 딜리트를 사용해서 개체를 제거하는 게 중요합니다. 빅데이터를 위해서 고려된 게 아니기 때문에. 이렇게까지 데이터가 커질 줄 몰랐다고 하는데 개인적으로는 5에서 100기가 까지는 다음과 같은 전략으로 해소됐는데 100기가 이상부터는 어려웠습니다. 어떻게 해야 하냐? 더 사야겠죠. 돈을 더 써야겠죠. 돈이 없잖아요. 그럼 밑에를 고려하는 거예요. 넘바 같은 GPU. 이런 것을 써서 데이터 여정을 판다스와 즐겁게 하시는 여러분이 됐으면 좋겠습니다. 발표는 여기까지고요.
-발표해주신 오성우님께 감사하고요. 지금은 질의응답 시간입니다. 시간관계상 질의응답은 두 분만 받겠습니다. 질의해줄 분들은 저기 앞에 마이크가 있으니까 마이크에 질의응답 부탁드리겠습니다.
-좋은 발표 감사합니다. 벡터라이제이션을 쓰려고 많이 하다 보면 루프를 쓸 수밖에 없는 상황이 저 같은 경우는 복수조건문 써서 어떤 값을 로우별로 입력해야 할 때 보통 벡터라이제이션을 못 하고 루프를 쓰거든요. 혹시 이럴 때 사용하시는 방법이 있을까요?
-저 같은 경우는 인덱싱을 조건에 맞는 인덱싱을 뽑아서 인덱싱만 넣는 거죠. 데이터를 한 번에. 벡터라이제이션으로 말씀하신 조건의 애들을 계산해주고 인덱싱에만 넣어주는 방식.
-여러 줄로?
-얘가 인덱싱 슬라이스가 잘 돼 있어서 일부분만 뽑아서 넣어주는 방식을 쓰면 빠르게 돼요.
-감사합니다.
-질문하신 분 책 받아 가세요. 또 다른 질의자가 없으시면.
-머지 쓰는 게 신박한 방법인 것 같은데 어떻게 알게 됐나요?
-그 당시에는 그게 일반적이었는데 그때는 제가 그게 제일 빠른 방법이었어요. 인 조건문을 쓰면 느리잖아요. 경험적인 측면도 있고 관계형인 특성을 이용했습니다.
-질문하신 분 도서 받아 가세요. 발표 시간이 종료돼서 세션을 마무리하도록 하겠습니다. 지금까지 발표해주신 오성우 님께 큰 박수 부탁드리겠습니다. 감사합니다.