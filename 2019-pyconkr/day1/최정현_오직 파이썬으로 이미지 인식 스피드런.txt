@최정현 님 강의 내용@
-모두 자리에 앉아 주시기 바랍니다. 안녕하세요? 이번 시간에는 최정현 님께서 오직 파이썬으로 - 이미지 인식 스피드런이라는 제목으로 40분간 발표해주시겠습니다. 원활한 발표를 위해 질의응답은 발표 후 시간이 남으면 진행하도록 하겠습니다. 그럼 큰 박수 부탁드립니다.
-안녕하세요? 이번에 오직 파이썬으로 - 이미지 인식 스피드런을 발표하게 된 최정현이라고 합니다. 저는 신도림고등학교 재학 중입니다. 많이 봐 주세요. 여러분 오직 파이썬으로, 가장 빨리 아마도 여러분 그럴 때는 아나콘다 설치 초보자에게는 그리 친절하지 않은 듀토리얼이 많았습니다. 지금부터는 오직 파이썬으로, 딱 파이썬만 사용해서 MNIST를 인식하는 걸 따라감으로써 직관적으로 인공지능을 이해하는 시간이 됐으면 좋겠습니다. 혹시 지금 숫자들이 보이시나요? MNIST, 직관적인 건 아닌 것 같네요. 무척적인 많은 손글씨를 원하는 데이터베이스입니다. 각기 다른 스타일의 필기체 그리고 모형 그리고 글씨의 글들이 테스트용으로 1만 개가 모여 있는 게 데이터 세트입니다. 이번 시간 해결할 문제는 28*28 크기 이미지를 보고 이 이미지 숫자가 무엇인지 만드는 인공지능입니다.
왼쪽 숫자, 오른쪽 숫자 구별할 수 있을까요? 사람이니까 가능할 겁니다. 우리는 사람이니까 저기 5의 숫자를 보고 음영이 어디인지 끝나는 라인이 어디인지 그리고 5라는 숫자 의미가 뭔지 보고 예측할 수 있지만 컴퓨터는 저게 5인지 알지 못합니다. 이 연속된 배열이 어디서 끊어지는지. 약간 문제가 있었네요. 연속된 배열이 어떻게 나타나는지 인식하고 5라고 단정지을 수 있지만 컴퓨터는 알 수 없습니다. 5라는 숫자를 한번 펴 보겠습니다. 저것이 5라는 걸 알 수 있는 사람은 없을 것입니다. 이 코드가 무엇을 예측하는지 1분 동안 확인하겠습니다. 이게 끝입니다. 다른 거 없이 우리는 이 두 장의 코드로만 구현할 것입니다.
여기 QR 코드를 찍거나 링크를 따라 가면 코드를 볼 수 있습니다. 아마도 여태까지 나온 게 90줄 정도면 40분 안에 할 수 있지 않을까요? 우리가 인공지능 구현하는 방법에는 정확히는 Softmax 회귀라는 걸 사용할 건데 간단합니다. 소프트맥스 함수를 적용하면 끝입니다. 너무 난해하고 방대한 감이 없지 않은데 코드를 따라가 보면 확실히 왜 알 수 있을 것입니다. 소프트맥스 회귀는 간단합니다. X를 입력하면 X에 가중치 곱해지고 특정 원소에 국한되지만 소프트맥스 함수는 배열을 입력합니다. 그럼 두 번째는 원소 1을 잔상수에 제곱 처리하는 방법이 필요합니다. 새 배열 exp를 만듭니다. 만든 원소 exp 값 먼저 만들어놓은 값을 합친 것으로 합이 0이 나올 수 있으니 작은 값도 더해지는 걸 잊지 않아야 합니다. 모든 합을 원소를 나눠주는 거로 Softmax 함수는 마무리됩니다. 실험을 해보겠습니다.
지금 문제가 생겼네요. 죄송합니다. 소프트맥스 함수는 아주 작은 원소 하나가 전체의 값을 얼마나 차지하는지 알려주는 함수인데요. 우선 이건 소프트맥스 함수 과정을 단순화시켜 그린 그림입니다. 모두 합친 뒤 나온 28 곱하기 28, 출력으로는 10을 쓸 것이니 28*28*10이 됩니다. 앞으로 전파하는 과정에 대해서 설명하겠습니다. 첫 번째는 X가 이미지를 전방향으로 받고 두 번째로는 이미지를 가중치를 곱해줍니다. 가중치를 곱해준 이미지를 전부 합쳐주고 이걸 Softmax 함수에 적용하면 전방향 전파가 끝나게 됩니다. 끝나면 모든 숫자가 의미하는 확률로 나타나게 됩니다.
전방향 전파는 만들었는데 도대체 어떻게, 전방향 전파의 신경망은 무작위 결과를 내보내는 것이지 의미있는 결과를 추출하는 건 아닙니다. 오차함수를 정의하여 이걸 우리가 만드는 신경망으로 최적화시켜야 하는데요. 먼저 오차함수를 정의하고 낮아지는 방향으로 최적화하면. 가중치를 훈련시킬 수 있는 결과인데요. 가중치를 훈련시키려면 평균 제곱 오차가 작아지는 거로 하면 됩니다. 평균 제곱 오차는 각 원소의 오차를 곱한 뒤 이 원소를 제곱한 뒤 모두 합한 뒤 나눠주는 거로 평균을 취합니다. 가장 작아진 방향으로 업데이트하면 신경망이 업데이트되는데 경사하강법이라는 거로 업데이트할 겁니다. 경사하강법은 오차함수 낮아지는 방향으로 최적화 즉 경사하강법을 사용하게 되는데 오차함수를 정의한 뒤 낮아지는 방향 뭔가 익숙하지 않나요? 맞습니다. 오차함수 낮아지는 방향은 건. 경사하강법은 가중치에서 오차함수의 값을 빼는 방법으로 되는데. 오차함수를 코드로 변환하면 이렇게 되겠습니다. 모든 걸 순서대로 처리하기 때문에 순서대로 처리하는 코드가 들어가고 예측값과 실제값을 빼서 오차를 정리하는 부분. 모든 오차의 제곱값을 합치는 부분, 나눠서 평균을 구하는 부분이 되겠습니다. 경사하강법을 살펴보겠습니다. 경사가항법이 원래부터 부드러운 합슥을 위해 합습률을 추가하겠습니다. 학습률을 추가해서 약간 빠르게 해보겠습니다. 우리가 봐야 할 최적화의 장점은 이것입니다. 뉴런 n를 거치는 가중치가 얼마만큼 오류에 기여했냐. 뉴런 n를 거치는 즉 신경망을 지나온 값이 얼마인지 확인하는 코드가 들어가고요. 가중치 W를 지정해서 오류를 확인하는 코드 얼마만큼 오류가 들어갔나.
우선 뉴런 n를 거치는 diff는 우리가 앞서 정의한 평균제곱오차 평균값은 앞에 2가 들어가지만 생략했습니다. 얼마만큼 기여했는지는 뉴런 n의 원본을 곱해주면 되는데 평균제곱오차 평균값만큼 원본 소스에서 곱해주면 됩니다. 이제는 모든 신경망을 측정했으니 정확도 확인하는 게 필요합니다. 훈련 중 훈련 종료된 이후 정확도를 확인하기 위해서 확인하는 함수가 필요합니다. 정답에서 얼마만큼 확인할지 이미 정답을. 정확도는 어려울 거 없이 예측한 값이. 예측에 성공한 데이터 수를 예측에 실패한 데이터 수로 나눠주면 됩니다. 이제 모든 모델 정의가 끝났습니다. MNIST 데이터 세트를 확인할 차례입니다. 여기 앞에 라벨과 파일이 있는데 일반적으로 바이너리. 첫 번째로 MNIST 데이터 세트는 언사인트 바이트 즉 4비트의 데이터로 돼 있으므로 파이썬에 기본 적용하는 숫자 읽어오는 함수를 사용했습니다. MNIST 데이터 세트는 4개 파일로 나눠져 있으므로 오픈이라는 함수로 4개 파일로 불러오는 과정을 사용했습니다.
MNIST 데이터 세트는 헤더가 있는데 먼저 파일을 불러왔으니까 데이터 읽어오기에 앞서 헤더를 건너뛰어야 합니다. 훈련된 이미지는 32비트 숫자 4개 구성합니다. 32바이트는 이미지 헤터 파일 크기는 16바이트입니다. 가로 세로 해당하는 정보가 들어있지 않으므로 8바이트를 건너뛰면 됩니다. 이제 진짜 데이터를 불러왔으니 시험 데이터와 검증데이터 시간입니다. 시험 데이터 검증 데이터를 나눌 필요는 없는데 훈련 중에 출력된 데이터 세트 정확도가 확인할 때. 훈련 과정 중 만족스럽지 못한 결과가 나왔을 경우 훈련 종료하고 다시 훈련을 실행하는 경우가 있는데 검증 데이터에서는. 테스트 데이터를 5로 나누고 앞부분을 테스트 데이터로 정의합니다. 모든 불러오기와 훈련과정 정의가 끝났으니 데이터를 훈련하는 과정이 필요합니다. 전체 데이터를 여러 번 훈련시킬 수 있으니까. 예측값과 실제값을 준비해서 예측값은 전방향 전파 포워드 함수를 이용하고. 10 크기의 배열로 예측값도 맞춰주는 과정이 필요합니다. 예측값 실제값을 이용해 오차 역전파를 실행하고 역전파 함수는 우리의 에러를 에러 함수를. 500개의 이미지를 학습했다면 진행상황을. 노트북 가져오신 분은 이걸 찍으면 코드를 같이 실행할 수 있을 겁니다. 인터프리터가 깔려 있다면 실행 가능할 것 같습니다.
스크립트 다운을 받았다면 pypy로 실행하면 빠릅니다. MNIST 데이터가 잘 불러왔는지 확인하겠습니다. 모두 정확히 데이터가 불러와진 걸 확인할 수 있고 전체 데이터를 2번 학습시키기 했습니다. 생각보다 빠른 속도를 보여주고 지금 신뢰도를 보여주고 한 500세트 전체 평균적인 값의 평균적 오차를 보여줍니다. 학습이 끝났습니다. 이제 데이터를 보여주는데요. 예측은 4인데 정답은 9네요. 그럴 만하게 보입니다. 데이터를 확인할 수 있고 제대로 학습된 것처럼 보입니다.
최종 정확도는 93.95%가 나왔고 다른 거 아무것도 쓰지 않고 파이썬만 써서 93.95%는 굉장히 좋은 결과라고 할 수 있겠네요. 이제 그래프도 볼 수 있는데요. 골뱅이 표시되는 건 정확도고 그리고 샵으로 표시된 건 예측함수를 나타냅니다. 정확도는 올라가고 우리의 오차를 정의한 건 낮아지는 걸 봅니다. 여기까지 발표였지만 부족한 감이 있어서 10분간 요약해드리겠습니다. 손글씨 문제, 28*28 이미지 보고. MNIST 데이터라고 손글씨 확인하는 이미지 만들었고 6만 개에서 1만 개로 이루어져 있고. 코드를 보여드렸고 소프트맥스는 Softmax 함수 이용해서 만든 신경망이고 Softmax 함수는 exp값 전체 합의 평균을 구해서. 마지막으로 가중치는 28*28의 이미지에서 10개를 보려 하므로. 전방향 전파 X 입력값을 이미지로 갖고 전부 더한 뒤 Softmax 함수를 정의했습니다. 가중치를 최적화하기 위해 평균제곱오차를 정의해서 낮아지는 방향으로 정의했습니다. 경사하강법 이용했는데요. 경사에 따라 하강하는 법 오차를 최소화하는 방법을 선택했습니다. 경사하강법은 부드러운 학습률을 위해 학습을 추가하고 오차함수와 가중치에 대한 평균값으로 업데이트를 진행했습니다. 정확도를 확인하고요. 데이터 세트를 불러오고 마지막으로 테스트를 진행하였습니다. 많이 부족한 발표였던 것 같은데 일단 여기까지 발표였고요. 일단 들어주셔서 정말 감사합니다.
-발표해주신 발표자님 감사드립니다. 궁금한 점 있으면 가운데 마련된 스탠딩마이크에 질문해주시면 감사드리겠습니다. 원활한 질의응답을 위해 질문은 1, 2개 정도로 짧게 부탁드립니다. 그래야 발표자도 질문 내용을 쉽게 기억할 수 있으니 양해 바랍니다. 참고로 제가 빼먹은 내용이 있는데 질문을 하시면 앞에 있는 도서를 선물로 드립니다.
-발표 재미있게 잘 들었습니다. 사실 MNIST가 기본적인 거라서 코드가 많이 나와 있는데 다른 길을 택한 것 같은데 그런 이유를 듣고 싶고 또 하나는 마지막에 그래프가 굉장히 인상적이었는데 사진을 찍고 싶어서 다시 한번 보고 싶습니다.
-제가 파이썬으로 코드를 작성한 이유는 이 발표를 위해서 작성했는데 논파이 같은 거로 작성돼 있으니까 논파이를 활용한 듀토리얼에서는. 저는 애초에 우리는 **을 모르더라도 파이썬만 알더라도 MNIST 데이터 세트를 따라갈 수 있게 파이썬으로 코드를 작성했습니다.
-발표 잘 들었습니다.
-지금은 만들지 않았습니다.
-텐서 플로어나 케라스나 라이브러리 써서 하면 기본적으로 구현할 수 있는 방법이 있는데 말씀해주신 것처럼 직접 구현하셨는데 새롭게 얻은 인사이트 같은 게 있는지 궁금합니다.
-제가 파이파이를 이용해 돌렸는데 보시면 알겠지만 파이파이로 로딩하고 훈련하는 과정이 굉장히 빠릅니다. 파이파이 내부 구연을 확인했더니 가속하는 연산이 들어 있었고 이렇게 파이썬 코드를 작성한다 해도 AI를 가속하는 기능이 들어있는 건 파이파이를 통해 처음 알게 됐습니다. 답변이 난해하네요. 파이파이를 이용하면 AI를 가속할 수 있다는 새로운 사실을 알게 됐습니다.
-비슷한 질문인데 저렇게 하는 거랑 라이브러리 쓰는 거랑 성능 차이에 대해서 인사이트가 있는지.
-20% 차이 정도밖에 안 났습니다.
-20% 빠르다는 건가요?
-20% 차이밖에 안 나고 빠르고 단순 파이썬을 이용한 경우보다 파이파이를 이용하면 15배 빠르다는 걸 확인했습니다.
-제가 알기로는.
-로그 도형을 사용하기 때문에 미분값을 나타내기가 난해하고 MSA 같은 경우는 2-y가 돼서.
-아까 부드러운 학습을 위해서 학습률을 곱했다고 하는데 곱한 것과 안 곱한 것과 어떤 차이가 있나 궁금합니다.
-빠른 속도로 학습이 진행될 경우 최저점을 지나치는 오류, 영원히 고정되는 오류가 생길 수 있습니다. 예를 들어서 학습률이 1일 경우 숫자가 100, 200 뛰어버리면 오버플로우가 나기도 하고 낮을 경우. 부족한 발표 들어주셔서 정말 감사하고 제가 자료 날려버려서. 혹시 코드를 보시면 다시 한번 코드 이해해보시면 직관적으로 이해할 수 있게 될 겁니다. 다음 질문 있으신가요?
-이건 그냥 생각난 건데 이거 보면 정답률이 97% 정도 나온 건가요?
-정답률은 93% 정도 나왔습니다.
-7% 정도가 틀렸는데 맞히는 거 말고 틀린 거만 모아서 어떤 게 틀렸는지 추가로. 어떤 특징이 있을 때 틀렸나 보고. 지금 한 번 돌렸잖아요. 반대로 어떤 게 틀렸는지 봐서 7이랑 9랑 비슷하니까 틀렸으면 7이랑 9랑 틀리는 게 상대적으로 210개 중에서 7이랑 9의 비중이 높으면 거기에 대한 분포나 그런 걸 가정해서 개선하는 방향으로 2번 돌리는 거 해보면 재미있을 것 같습니다.
-데이터 편향을 고려하라는 말씀이신가요?
-그런 건 아니고 지금까지 책들을 보면 보통 한 번 돌려서 맞히는 거에 고민을 하잖아요. 그런데 맞히는 걸 보면 에폭시를 돌면서 ** 나오는 계수들은 결국 애버리지 밸류에 가장 맞는 결과가 나오는 건데 한 번 돌리고 최적화된 옵티멀이 됐잖아요. 틀린 게 있다는 건 학습이 어렵고 덜 되는 부분이 있다는 거기 때문에 그 부분에 초점을 맞춰서 맞추는 거에 초점을 맞췄으니까 왜 틀리는지 인사이트를 좀 더 추가하면 그런 부분에서 좀 더 지금은 MNIST를 가지고 한 거고 어떤 모형을 빨리 학습하는 게 중요한 게 아니라 사람을 분류했을 때 지금 이건 숫자가 분류인데. 틀린 거에 대한 고민이나 틀린 결과가 나온 거에 대한 분석을 하는 게 중요할 수 있으니까 그런 부분에 인사이트를 하면 좋을 것 같습니다.
-발표 시간이 종료돼서 세션을 마무리하도록 하겠습니다. 이만 마치도록 하겠습니다. 지금까지 발표해주신 최정현 님께 큰 박수 부탁드리겠습니다. 감사합니다.