<한국어 띄어쓰기 프로그램 도전기>
-안녕하세요? 많은 자리가 차졌네요. 이른 아침에도 불구하고 일요일인데 시간을 내주셔서 자리에 와주셔서 너무 감사드립니다.
시작하기에 앞서서 혹시 여기서 제가 좀 질문을 할 건데 혹시 자연어처리에 대해서 개발이나 연구를 하고 계시거나 머신러닝에 대해서 배경을 아시는 분이 계신지? 한번 손을 좀 들어보실 수 있을까요?
아, 네. (웃음) 상당히 많군요.
어떤 걸 기대하고 오셨는지는 모르겠지만 제가 발표하고자 하는 것에 대해서는 도전기입니다.
그래서 이 내용이 되게 좀 쉬운데? 좀 되게 간단한 걸 왜 고급으로 두고 얘기했지? 이런 생각이 좀 드실 수도 있겠지만 어떻게 보면 기본적인 개발에 대한 것들을 이야기를 풀고자 합니다.
그래서 그런 부분에 맞춰서 봐주시면 좋겠고요.
안녕하세요? 저는 최태균이고 그리고 자연어처리 개발자입니다. 제가 오늘 발표할 내용은 한국어 띄어쓰기 프로그램 도전기입니다.
이번 발표에서는 제가 한 달 반 동안 띄어쓰기 프로그램 개발을 했는데 이것에 대한 시도는 어땠고 그리고 결과가 어떠했는지 공유하는 시간을 가지도록 하겠습니다.
이야기는 크게 다섯 개로 나누어서 하고자 합니다. 그래서 서론에서는 띄어쓰기 프로그램이 왜 필요했는지, 그리고 한계가 어떤 것들이 있는지 이야기를 하고 그런 다음에 띄어쓰기프로그램 구조는 어떤 식으로 설계를 했고 모델개발은 어떻게 했고 결과는 어떻게 나왔는지를 이야기하고 마지막으로 한국어 BERT를, 근래 많이 나오는 모델이다 보니까 이런 거를 활용했을 때 결과가 어떻게 됐는지, 그리고 결론 이야기하면서 마무리하려고 합니다.
서론부터 시작해보도록 하겠습니다.
자연어처리에서 띄어쓰기를 통해서 입력 텍스트를 가지고 토큰 단위로 나눠서 보는데 이런 토큰 단위로 나누는 것은 스페이스 단위로 쉽게 나눌 수가 있겠습니다.
그런데 한국어에서는 이런 구분을 가지고 하는 데 있어서 띄어쓰기가 큰 영향을 줍니다.
왜냐하면 이 텍스트 하나하나 토큰마다에 대해서 의미를 구분하는 게 영향이 많이 가거든요.
그래서 예시를 보면서 하겠습니다.
띄어쓰기가 어떤 영향을 줄 수 있는지 살펴보려고 하는데요.
여기 예시로 '아버지가방에들어가신다'라고 되어 있는데 이 띄어쓰기가 맞다고도 될 수 있습니다. 그런데 여러분도 아시다시피 이렇게 이해할 수도 있겠죠.
문맥 없이 띄어쓰기를 보다 보면 의미를 명확하게 파악하지 못하는 점이 있고 이런 점이 자연어처리를 하는 데 있어서 어려움을 겪게 합니다.
형태소 분석이 띄어쓰기로 인해서 문제가 발생할 수 있는 케이스는데요. 문장 예시를 보시면, 너무기대안하고갔나 재밌게봤다 이런 문장이 있는데 이걸 konlpy에 Okt 형태소 분석기를 통해를 보면 여기서는 너, 무기, 대안 이런 식으로 분석이 되어 있습니다.
그래서 이런 띄어쓰기 문제를 해결하고자 프로그램들이 나왔습니다. 오픈소스들도 있고요.
대체로 미리 학습된 알고리즘으로 구성이 되어 있습니다. 이러한 프로그램들을 보면 텍스트 코퍼스에 크게 많이 영향을 받게 되는데 그 코퍼스 도메인이 달라짐에 따라서 띄어쓰기 성능이 달라질 수 있습니다.
대표적인 사례로 오픈소스인 pykospacing을 보려고 하는데요.
여기에 입력으로 '너는나의원수야'라는 구어체 문장을 해봤습니다. 물론 띄어쓰기는 안 한 상태이기는 하지만요. 이걸 넣었을 때 우리가 만족할 만큼의 띄어쓰기가 되지 않 는 문장을 볼 수 있습니다.
이런 한계점을 보고 제가 제가 수집한 데이터셋을 가지고 띄어쓰기 알고리즘을 만들 수 있는 프로그램을 생각해는데 여기서는 주로 실행과 학습 위주에 대한 설계를 이야기할 겁니다.
먼저 띄어쓰기 프로그램의 실행구조를 보겠습니다. 먼저 텍스트 문장을 입력을 하고 모든 띄어쓰기 공백을 제거하고 내가 학습한 띄어쓰기 모델을 통해서 띄어쓴 텍스트를 출력하는 겁니다.
학습 가능한 띄어쓰기 프로그램을 하기 위해서는 모델학습이 필수적인데 두 과정을 거치게 됩니다.
먼저 띄어쓰기를 할 학습데이터를 구성을 하고 그 데이터를 토대로 모델학습과 평가를 합니다.
평가 한 후에는 테스트 성능을 확인한 다음에 만족한 성능이 나오면 그걸 활용하면 되고 아닌 경우에는 이 두 가지 과정을 계속해서 반복할 수 있도록 합니다.
띄어쓰기 프로그램 구조를 설계할 때는 가급적 객체지향적인 구현을 시도했습니다.
이러한 시도는 모델 학습의 평가나 실행, 그리고 학습기능을 구분하는 데 있어서 구분해서 개발하는 데 효과적이었습니다.
띄어쓰기 프로그램 구조에 대해서 잠시 살펴보고 가도록 하겠습니다.
먼저 Configs.json 파일을 설정을 해놓고 여기에는 모델학습이나 실행과 같은 설정들을 여기에 담아놓습니다.
그러면 이 값들을 이제 메인실행객체인 Agent 객체에 등록을 하게 되는데요.
이 Agent 객체는 모델과 토크나이저, 그리고 단어사전 등을 가지고 있습니다. 걸 가지고 학습, 평가, 실행 기능을 수행할 수 있도록 합니다.
각 실행 함수는 학습 데이터관리, 평가객체라는 별도의 객체를 두어서 각 함수 안에서 기능수행을 하는 데 중요한 역할들을 하게 되고요.
이렇게 설계한 프로그램 구조는 다음과 같이 간단한 구현을 통해서 실행이 가능하도록 했습니다.
이제 띄어쓰기 프로그램 구조를 봤다면 본격적으로 핵심인 띄어쓰기 모델 개발에 대해서 이야기해보도록 하겠습니다.
띄어쓰기 모델은 시퀀스 분류 모델을 가지고 구현합니다. 예를 들어서 '오늘서울날씨'라는 텍스트가 있는데 이 텍스트를 모델에 입력하면 띄어쓰기 정보로 각 음절 위치에 B, I 와 같은 태그를 가지고 띄어쓰기 정보에 대한 예측을 하는 겁니다.
띄어쓰기 모델은 대표적인 RNN, CRF 와 같은 알고리즘을 활용하는데 제가 베이스라인으로 활용할 모델은 BiLSTM-CRF입니다.
BiLSTM-CRF 모델은 RNN 계열 모델 중에 BiLSTM 모델과 Condition Random Field 모델로 구성되어 있습니다.
BiLSTM은 입력한 토큰과 앞뒤 시퀀스 정보를 조합해서 띄어쓰기 점 인지를 예측하고 CRF는 예측값의 순서를 보정합니다.
실제 코드를 보겠습니다.
이 모델은 파이토치 기반으로 구현이 되어 있고 크게 모델 생성과 loss 연산, 모델추론 등으로 구성되어 있습니다.
모델생성을 보도록 하겠습니다. 모델생성은 각 네트워크들을 생성하는 과정인데 워드 임베딩 레이어와 BiLSTM, 그리고 CRF 레이어를 생성하고 있습니다.
생성된 네트워크는 loss 값을 구하거나 모델 추론 연산에 사용하게 되는데 loss 연산하는 것부터 먼저 보시면 Padding 정보를 무시하기 위한 마스크를 먼저 생성을 합니다.
그런 다음에 이를 가지고 입력값과 함께 모델연산을 하고 마지막으로 CRF 레이어에 와서 loss 값을 출력하도록 했습니다.
모델추론도 loss 값 연산하는 것과 유사한데 여기서 그 차이는 마지막에 CRF 레이어에서 Viterbi 디코딩을 활용해서 최적의 띄어쓰기 시퀀스를 출력하도록 하는 데에서 차이가 있습니다. 이제 모델학습 데이터셋이 필요할 겁니다.
구축할 데이터셋은 띄어쓰기가 잘 된 거여야 하는데 이런 데이터는 대체로 세종코퍼스, 위키피디아 데이터, 신문 데이터셋 정도가 있습니다. 이중에 저는 세종 코퍼스 데이터셋을 활용하고자 합니다.
세종코퍼스 데이터수집은 깃허브에 쿨엔지니어라는 분께서 만드셨는데 이걸 활용했습니다.
이걸 활용하면 간단하게 네 줄의 커맨드만으로도 띄어쓰기 문장을 구축할 수 있었고요.
구축한 데이터셋은 코퍼스가 한 160만 개 정도였습니다. 그리고 100만 개 정도의 문장이 있었고요.
문장에서 한 80% 정도는 문어체였고 20% 정도가 구어체로 구성되어 있었습니다.
제 데이터 분석을 보려고 하는데 학습데이터에 대한 문장길이를 먼저 살펴봤습니다.
이 경우는 어절 단위 경우는 한 10 정도에 크게 많이 분포되어 있었고 가장 긴 문장의 경우에는 100 정도의 길이에 있었습니다.
음절의 경우에는 10에서 30 정도에 분포가 되어 있고 가장 긴 길이가 130 미만이었습니다.
이 정보는 나중에 모델 하이퍼 파라메터에 사용하는 데 사용됩니다.
또 확인해본 거는 세종코퍼스 어절단어에 대한 분포였습니다. 나중에 모델예측을 할 때 어느 정도 추론을 하고자 얻은 정보인데 주로 보시면 동사에 관련된 어휘가 많이 나와 있고 이 중 '하다'와 관련된 파생어가 많이 나와있다는 걸 확인할 수 있었습니다.
또 '이'나 '그'와 같은 지칭대명사 같은 단어, 한 자리 음절 단어들이 많이 보였습니다.
모델학습방식은 Self supervisd learning으로 했습니다.
이 방식은 데이터 자체만으로 수퍼바이징 러닝을 하는 방식인데 입력 데이터에 의해서 라벨링이 가능한 상태이기 때문입니다.
띄어쓰기의 경우는 단어의 시작과 끝지점을 활용해서 라벨을 생성할 수가 있습니다.
라벨링 방식에는 보통 띄어쓰는 지점을 표시하는 경계인식방식을 많이 활용합니다.
경계인식 같은 경우는 경계지점만을 판별하는 학습을 하는데 여기서 저는 단어 영역을 인식할 수 있는 영역 인식 방식을 같이 고안해서 학습해봤습니다.
보다 구체적으로 라벨링 방식에 대해서 보도록 하겠습니다.
경계인식은 다음 예시와 같이 단어의 시작지점을 경계로 보아서 시작지점을 Begin, 아닌 지점을 Inside로 해서 학습을 했습니다. 영역인식방식의 경우는 단어의 시작, 중간, 끝지점을 각각 다른 태그로 학습을 해서 단어의 영역이 어디인지를 알 수 있도록 했습니다.
만약에 어절이 한 개 음절로 되어 있는 경우에는 Single 태그로 두어서 구분해두었고요.
이제 학습 데이터에 대한 전체 구성을 어떻게 했는지 보도록 하겠습니다.
학습데이터셋 같은 경우는 전체 데이터셋의 90%를 두었고 나머지 10%에 대해서 평가데이터셋을 하였습니다.
검증데이터셋의 경우는 학습데이터 안에서 무작위로 10%를 추출해서 성능을 보는 것으로 했고요.
모델 학습 하이퍼 파라메터는 다음과 같습니다.
워드 임베딩 같은 경우는 보캡사이즈가 3710개 정도에 32디멘젼으로 되어 있고 그리고 BiLSTM의 경우는 64에 양방향으로 구성되어 있습니다.
옵티마이저는 아담을 활용했고 기본 러닝 레이트로 설정해두었습니다.
배치사이즈는 128에 길이제한은 100으로 설정을 했습니다.
학습은 검증 f1 스코어가 수렴될 때까지 학습을 했는데 이 시간이 반나절에서 하루 정도 걸리는 시간이었습니다.
모델평가는 세 가지로 평가를 했습니다.
첫 평가지표는 경계인식기준에서 F1스코어였는데 이 평가는 기존 띄어쓰기 모델에서 활용하는 방식입니다.
두 번째는 WER 스코어입니다.
주로 음성인식에서 많이 활용하는 평가기준입니다.
예측한 문장을 정답 문장하고 비교해서 동일한 문장으로 만드는 데 연산횟수를 가지고 점수를 내는 방식이고요.
마지막으로 SER인데 이것 같은 경우는 문장이 완전히 일치하는지를 보는 점수였습니다.
이제 모델도 구성했고 데이터도 구축했고 학습까지 다 돌렸으면 결과를 봐야겠죠.
베이스라인 성능은 다음과 같습니다.
우선 세종코퍼스 평가 데이터셋 기준으로 봤을 때는 Kospacing보다 조금 더 나은 성능을 볼 수 있었고 근소한 차이기는 하지만 영역인식방식이 경계인식방식에 비해서 조금 더 높은 것을 볼 수 있습니다.
성능도 확인했고 이제 False Case를 보도록 하겠습니다.
주로 띄어쓰기 예측을 못하는 경우는 복합명사에 많이 있었습니다.
사실 이런 부분은 일반인도 잘 구분하기가 쉽지 않습니다.
여러분들도 띄어쓰기를 하다 보면 이 명사가 복합명사인지부터 판별을 해서 띄어쓰기를 하려면 그게 쉽지가 않은 방법입니다.
이런 부분에서 모델예측에서 좀 어려워하는 부분이 있었고요.
아마도 학습데이터에서도 크게 영향을 주는 것 같습니다.
다른 False Case는 한 글자 어절에 대한 띄어쓰기였습니다.
앞서 데이터 분석을 보면 한 글자 어절에 대해서 크게 많이 분포되어 있다는 걸 눈으로 확인할 수 있었는데 그럼에도 불구하고 띄어쓰기가 잘 안 되는 결과를 볼 수 있었습니다.
아마도 한 글자가 어절인 경우에는 주변 음절 글자에 따라서 모델이 띄어쓰기를 판단하는 데 좀 혼동이 있을 가능성을 확인할 수 있었고 이 점을 모델에 대해서 좀 개선할 점이라고 생각을 했었습니다.
이렇게 해서 결과를 봤습니다. 모델학습과 평가한 결과를 봤는데 제가 앞서 설명한 경계인식방식와 영역인식방식의 차이는 무엇인지 궁금해하셨을 겁니다.
저도 이 부분에서 많이 궁금했는데 우선 False Case를 통해서 두 방식의 차이를 확인하려고 했지만 좀처럼 쉽지는 않았습니다.
그런데 분명히 라벨링 방식에서는 차이를 뒀었는데 이러한 영향이 어디서 보일 수 있는지 고민을 했었고 띄어쓰기를 판별하는 데 입력정보가 어떻게 영향을 줄 수 있는지에 대해서 고민을 했었습니다.
LIME 알고리즘은 보통 분류모델을 해석 및 검증을 하는 데 사용을 합니다.
주로 모델예측을 할 때 크게 영향을 주는 단어가 무엇인지를 보는 데 사용하는 알고리즘인데 특히 시각적으로 표현해주는 역할로 가장 임팩트있는 알고리즘이라고 보고 있습니다.
띄어쓰기에서 LIME 알고리즘은 한 음절 토큰이 띄어쓰기를 예측할 때 어떤 음절토큰이 가장 기여를 할 수 있는지 확인하는 데 사용했습니다. 아래 예시에서 '안녕하세요 저는 홍길동입니다'라는 문장이 있는데 이 점에서 '홍'이라는 단어의 씌어쓰기를 예측하는데 각 음절토큰을 제거해보면서 어떤 것이 가장 영향을 줄 수 있는지 확인해보았습니다.
이런 LIME 알고리즘을 통해서 분석을 한 결과를 보면 경계인식모델의 경우 띄어쓰기 전 토큰에서 크게 영향을 주는 것으로 많이 볼 수 있었고 영역인식방식의 경우에는 띄어쓰는 지점 주변 토큰에서 영향을 고르게 받을 수 있다는 것을 확인했습니다.
옆에 예시를 좀 보시면 같은 문장이죠. 앞서 본 것과.
여기서 '홍'이라는 음절 위치에 띄어쓰기를 예측할 때 경계인식방식에서는 '홍'자 앞에 있는 '는'자에 크게 수치의 영향을 받고 있는 것을 확인할 수 있었고 영역인식모델에서는 '홍' 주변에 있는 음절토큰이 나름 고른 수치로 영향을 주고 있는 것을 확인할 수 있습니다.
이 결과로만 봤을 때는 상대적으로 입력정보를 편향적으로 받지 않는 것이 띄어쓰기 예측에 도움을 줄 수 있다는 것을 확인할 수 있었고 그런 점이 영역인식모델에서 드러나고 있다는 것을 확인할 수 있었습니다.
마지막으로 한 가지 더 보려고 합니다.
한국어 BERT입니다. 여기서 BERT 모델을 띄어쓰기 모델에 적용을 했을 때 성능이 어떻게 나오고 어떤 영향을 줄 수 있는지 살펴봤습니다.
BERT를 알아보기 전에 Transformer Network를 먼저 알아보도록 하겠습니다. Transformer Network는 Self Attention로 이루어진 네트워크입니다.
이 기법은 시퀀스 전체 정보를 학습하는 데 사용하는데요. 여기서 multi-head attention를 적용해서 다양한 관점에서 시퀀스 관계를 학습하도록 하였습니다.
한국어 BERT는 Transformer Encoder 모델로 이루어져 있습니다.
이 모델을 한국어 텍스트 데이터를 통해서 먼저 마스킹된 단어를 예측하는 학습하고 다음 문장을 예측하는 학습을 하는데 이를 저희는 Semi-Unsupervised Learning이라고 이야기를 합니다.
이렇게 Semi-Unsupervised Learning을 통해서 언어모델을 만들게 됩니다.
이렇게 만들어진 Pre-traind 모델을 가지고 각 NLP task에 Fine-tune을 해서 적용을 해보면 기존 모델보다 조금 더 나은 성능들을 보이고 있는 편입니다.
이제 BERT를 적용한 띄어쓰기 모델을 구현해보도록 하겠습니다. 먼저 BiLSTM-CRF 모델과 같이 모델 네트워크를 생성을 하는데 가장 중요한 것은 그냥 Bert모델입니다. 이건 제가 따로 구현하지는 않았고 Hugging-face라는 Bert 라이브러리를 활용하였습니다. 간단하게 한 줄로 구현할 수 있었고.
그다음에 Dense Layer를 생성합니다. 여기서 activation는 tanh를 활용하였고 이후에 리니어 레이어 역시 생성하였습니다.
이렇게 모델구성을 하면 BiLSTM 모델과 같이 연산과정을 맞춰주기만 하면 됩니다.
여기서 조금 다른 점은 Bert 모델에 입력할 값을 새로 맞춰져야 된다는 건데 모델 입력 마지막 지점에 cls라는 입력값을 넣어야 됩니다. 그래서 이 값을 같이 넣어서 모델에 입력할 수 있도록 구성을 해주는 과정이 있고요. 나머지는 BiLSTM-CRF하고 비슷한 과정으로 보시면 되겠습니다.
이렇게 구현한 BERT 모델 성능을 보면 다음과 같습니다. 기존 BiLSTM-CRF보다훨씬 더 높은 F1스코어와 WER스코어, 그리고 SER 스코어를 볼 수 있는데 놀랍게도 레이어를 12개를 다 쓰지 않고 3개 정도의 레이어만 사용을 하더라도 충분히 좋은 성능을 낼 수 있는 걸 확인할 수 있었습니다.
번외로 해봤던 거는 한국어 BERT 말고 단순히 Transformer 모델로도 학습을 해봤는데 상당히 효과가 러닝 속도에서는 느린 편이 있지만 성능은 BERT와 비슷하게 올라가는 걸 확인할 수 있었습니다.
하지만 BERT 모델의 아쉬운 점은 모델추론속도에 있었습니다.
BiLSTM-CRF 성능과 비교를 하자면 Bert 3레이어 기준에서 3~4배 정도 이상의 성능 속도 차가 나는 걸 볼 수 있었고 문장 길이가 길어질수록 속도가 비례해서 늘어난다는 것도 볼 수 있었습니다.
이제 제 이야기의 마무리를 좀 짓도록 하겠습니다.
저는 수집한 데이터를 활용한 띄어쓰기 프로그램을 개발하였고 세종 코퍼스 데이터셋을 통해서 검증을 하고자 했습니다.
학습 모델 실험을 통해서 모든 범주에 대한 띄어쓰기를 잘 할 수 있지 않다는 점을 확인했고 만약에 띄어쓰기 프로그램을 활용하고자 한다면 먼저 평가할 데이터셋을 먼저 구축하고 그다음에 그 기준 안에서 학습이 잘 되는 것이 중요하다고 봤습니다.
또 다른 이야기는 이제 띄어쓰기 정보를 좀 수용할 수 있는 학습이 필요하다고 생각을 했는데 왜냐하면 사용자가 입력한 띄어쓰기 정보가 때로는 유용할 수 있어서 그랬습니다.
마지막으로 띄어쓰기 프로그램을 개발하기 위해서는 가급적 띄어쓰기가 잘 된 데이터셋을 많이 활용해보는 것을 권장하도록 하겠습니다.
마지막 번외로 제가 그동안 진행했던 프로젝트를 소개하고자 합니다.
TaKos 프로젝트입니다.
그래서 데이터학습이 가능한 띄어쓰기 알고리즘을 만들기 위한 프로젝트를 제가 기획했는데 현재 깃허브에 올라온 상태이고 간단하게 명령어를 통해서 설치가 가능합니다.
현재는 알파 버전에 있고 개발진행 단계나 있고요. 기능이나 성능에 대한 테스트가 진행 중에 있고 이게 안정화가 됐을 때 다시 소셜미디어를 통해서 공개할 예정입니다.
현재는 프로젝트를 받으시면 이렇게 구현해서 띄어쓰기 프로그램을 실행시킬 수 있습니다.
제 발표는 여기까지고요. 혹시 궁금한 점이 있으시면 질문 부탁드리겠습니다.
-(사회자) 지금 시간상 하나 정도만 질문 받도록 하겠습니다.
-(질문) 발표 잘 들었습니다. 띄어쓰기를 보면 가장 많이 틀리는 건 결국 한 글자 띄어쓰기라고 생각하는데요. 그 한 글자 띄어쓰기에 맞춰서 평가를 하거나 그걸 조금 더 강조해줄 수 있는 평가지표를 테스트해보거나 아니면 지금 평가지표가 그것에 맞는 것인지도 궁금합니다.
-(발표자) 저도 고민을 해봐야 되는 문제이기는 한데 한 글자인 지점에 대해서 띄어쓰기를 하는 방법이 어떻냐는 질문이신 거죠?
-(질문) 그건 아니고 평가방식이 한 글자씩 띄어서 되는 게 많잖아요. 그런 경우 가중치를 가지고 평가가 되고 있는 건지 아니면 그런 단어들도 다른 띄어쓰기와 동일한 가중치를 가지고 평가가 되고 있는지 궁금하고요.
-(발표자) 그렇게도 평가를 해볼 수는 있을 것 같습니다. 그런데 그런 평가를 해보는 데 있어서 저는 약간 일반적인 평가지표를 뒀어야 했고 말씀하신 방법을 가지고도 한번 고민을 해서 평가지표를 둬봐야 될 수도 있을 것 같습니다. 감사합니다.
-(사회자) 발표 진행해주신 발표자 분께 다시 한 번 박수부탁드리겠습니다.
(박수)
지금부터 쉬는 시간입니다. 쉬는 시간 후에 다시 뵙도록 하겠습니다. 감사합니다.