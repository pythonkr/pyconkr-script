https://youtu.be/HpMYWk566OA

< 실시간 의료 인공지능 데이터 처리를 위한 Django Query Optimization - 윤소영 >
-지금 발표가 약간 지연되고 있습니다. 죄송합니다.
잠시 시간이 55분에서 2시로 지연되었습니다. 죄송합니다.
1분 뒤에 바로 시작될 예정입니다. 빈자리에 앉아주시기 바랍니다.
안녕하세요? 이번 시간에는 윤소영 님께서 실시간 의료 인공지능 데이터 처리를 위한 Django Query Optimization이라는 제목으로 40분간 발표해주시겠습니다. 원활한 발표를 위해 질의응답은 발표 후 시간이 남으면 진행하도록 하겠습니다. 그러면 큰 박수 부탁드립니다.
(영어로 통역 중)
(박수)
-(발표자) 안녕하세요? 오늘 실시간 의료 인공지능 데이터 처리를 위한 Django Query Optimization 발표를 하게 된 윤소영입니다.
저에 대해 간단히 소개를 해드리자면 저는 현재 카이스트 4학년이고 올해 1월부터 휴학을 하고 일을 하고 있고 그때 배운 점들을 공유해드리고자 합니다.
제가 조금 빠르게 말씀드리는 점 양해 부탁드립니다.
제가 발표할 내용은 다음과 같습니다. 먼저 회사에서 개발 중인 장고를 이용한 서비스를 성능의 문제점을 중심으로 설명드리려고 합니다.
그다음 문제점을 개선하기 위해 쿼리를 분석해야겠죠. 그러려면 약간의 ORM에 관련된 지식과 프로파일링 툴에 대한 소개가 필요하기 때문에 그 부분을 설명드리고 마지막으로 실제 사례를 보면서 속도를 어떻게 얼마나 개선시켜드렸는지 보여드리려고 합니다.
먼저 회사에서 개발 중인 장고를 이용한 서비스에 대해서 보겠습니다.
저희는 병원입원한 환자들이 급성질환에 걸릴 확률을 예측해서 보여주는 서비스를 하고 있습니다. 병원에서 환자 정보를 머신러닝 모델에 보낸 후 환자가 특정 질병에 걸릴 확률을 예측합니다.
환자들은 급성질환에 걸릴 확률이 매우 높다고 합니다. 그런 것은 조기치료가 매우 중요합니다. 그래서 저희는 빠르게 환자의 건강상태를 업데이트 하여 조기대응 서비스를 만들고 있습니다.
병원과 저희 없습니다. 실시간으로 정보를 업데이트해주는 것이 필수적입니다. 앞서 말씀드렸듯이 환자의 상태가 이상해서 알람이 발생했을 때 신속하게 알려 빠른 처치가 이루어지도록 하는 게 사망률을 낮추는 데 중요하기 때문입니다.
먼저 병원에서 들어온 데이터를 처리해주기 위해 데이터를 저장하는 부분을 자세히 보겠습니다. 병원에서는 매 분마다 수백 명의 환자 정보가 새로 갱신되어 들어오게 됩니다.
그러면 저희는 그렇게 API로 들어온 정보를 장고 ORM를 이용해서 저장 또는 업데이트를 합니다.
바로 여기에서 성능상 문제가 있습니다. 매분마다 수백 명의 환자 정보가 한꺼번에 들어오는데 이 데이터를 저장하는 데 상당히 많은 시간이 소요되고 있습니다. 저희 서비스는 1초라도 빠르게 데이터를 동기화하는 것이 중요하기 때문에 이 부분에 쿼리최적화는 필수적이었습니다.
그다음으로 데이터를 빠르게 전송해주는 방법에 대해 보겠습니다.
현재 저희의 급성질환솔루션은 1시간 단계로 데이터를 보내주고 서버는 그 정보를 가지고 몇 시간 뒤 환자가 특정 별에 걸릴 확률을 저희에게 보내주고 저희는 그 값을 저장합니다.
메인서버에서는 각 환자에 대해 특정 시간 간격 사이의 환자 생체정보를 모아서 머신러닝 서버에 보내게 됩니다.
그러면 서버는 그 정보를 ML model에 넣고 결과로 각 환자에 대한 예측값을 보내주게 됩니다. 이걸 매 분마다 보내주고 예측값을 받아서 저장해야 합니다. 따라서 가르게 fetching하고 결과값을 빠르게 저장해주기 위해서 쿼리 Optimization이 수행되어야 할 것입니다.
정리를 하자면 저희는 병원 덴이터와 연동하여 환자가 급성질환에 걸릴 확률을 예측해주고 있고 그를 위해 실시간 환자 데이터를 빠르게 동기화하고 시간대별로 빠르게 fetching하는 것이 중요한 서비스입니다.
그리고 지금 이 두 부분이 느리게 진행되고 있어서 앞으로 이 부분에 대한 성능개선에 대해서 말씀드릴 예정입니다.
그러면 지금 서비스의 성능상 문제점을 소개드렸으니 현재 서비스의 성능을 정량적으로 측정하고 슬로우 쿼리를 분석해봐야겠죠. 그전에 잠깐 장고 ORM에 대해서 설명하겠습니다.
장고 ORM이랑 Object Relational Mapping이라는 뜻으로 객체지향적인 방법으로 데이터를 다룰 수 있게 해줍니다.
즉 로우쿼리를 쓰지 않아도 그것과 동일한 연산을 수행할 수 있도록 모델 매니저가 도와준다는 뜻입니다.
저희 서비스는 장고 ORM를 이용하고 있습니다.
먼저 get은 셀렉트를 수행합니다. 예를 들어서 환자 테이블에서 uid가 10110인 환자를 가져오고 싶다면 Patient.objects.get(uid=10110)를 쓰게 됩니다.
세이브는 오브젝트를 생성하거나 업데이트합니다. 의사선생님께서 자유롭게 작성할 수 있는 메모기능이 있는데 memo.save()를 부르게 되면 이미 있는 메모는 업데이트를 부르고 신규메모는 인서트를 호출합니다.
get_or_create는 먼저 셀렉트를 통해 해당조건을 만족하는 오브젝트가 있는지를 찾고 있다면 다시 셀렉트를 수행하고 리턴합니다.
만약 해당조건을 만족하는 것이 없다면 get_or_create는 오브젝트를 만들고 반환합니다.
즉 총 두 개의 쿼리를 수행하게 되는 거죠.
bulk_create()는 쿼리 한번으로 여러 개의 오브젝트를 한번에 생성합니다.
다만 주의하실 점은 이 친구는 세이브를 부르지 않는다는 점입니다. 즉 장고 내부에서 보내주는 시그널이 불리지 않습니다. 생성된 이후에 어떤 작업을 하기 위해 장고 시그널을 사용했다면 이 부분을 염두에 두시면 좋을 것 같습니다.
그다음 장고 ORM의 특징입니다.
레이지 로딩을 합니다. ORM에서 레이지로딩은 두 가지가 있는데 첫 번째 쿼리셋에 아래 코드와 같이 필터와 같은 체인을 막 달다가 그 더이터에 접근하는 시점에 실제 커리가 일어납니다.
즉 쿼리를 쓴다고 해서 바로 실행이 되는 게 아니라 특정한 부분에서만 실제로 쿼리가 이벨류에이션 되는 특징입니다.
두 번째는 릴레이티드 오브젝트에 실제로 접근할 때 그때서야 패치해오는 겁니다.
장고 ORM은 이 두 가지의 레이지로딩 방법을 모두 채택하고 있습니다. 그런데 이 레이징 fetching 때문에 장고 ORM에서는 N+1 프라블럼이 발생합니다.
이것은 예를 들어서 책과 작가가 어써-아이디로 연결되어 있다고 할 때 각 책의 어써 네임을 뽑아오고 싶다고 합시다.
그를 위해 위와 같은 코드를 실행하였을 때 실제 SQL 쿼리는 총 책의 개수 플러스 한 개가 발생하게 됩니다.
이것은 먼저 fetching을 해주는 것을 써서 해결할 수 있습니다. 두 개에 대해서는 나중에 설명하겠습니다.
그래서 장고 ORM에 대해서 정리를 하자면 객체지향적인 방법으로 쿼리에 접근할 수 있는 방법이고 레이지로딩을 하기 때문에 N+1 프라블럼과 같은 문제가 있습니다. 그리고 저희 회사 코드에 쓰이는 몇 가지 ORM 함수들도 살펴봤습니다.
좋아요. 이제 현재 서비스를 어떻게 정량적으로 체크할 수 있는지 프로파일링 툴에 대해서 소개하려고 합니다.
먼저 간단하게 쉘 상에서 ORM으로 실행한 실제 SQL을 보는 방법에 대해서 알려드리겠습니다.
리턴값이 쿼리셋일 경우 내장된 쿼리라는 attribute를 컨버트해서 보면 전환된 쿼리스트링을 볼 수 있습니다.
또는 커넥션 모듈을 사용해서 커넥션.쿼리의 가장 마지막 인덱스를 호출할 수도 있습니다.
참고로 im인데 쉘에서 보여준 쿼리스트링이 실제로 실행되는 벨리드 sql은 아닙니다. 장고 ORM은 쿼리가 파라미터를 각각 보내는 것이고 실제 작업은 데이터베이스 어답터가 한답니다.
그다음에 조금 더 구체적으로 쿼리문을 비교하고 성능을 측정하고 싶을 때 쓸 수 있는 프로파일링 툴들을 소개해드리겠습니다.
먼저 장고 디버그 툴바부터 보겠습니다.
설치 방법은 다음과 같습니다.
그러면 로컬호스트를 실행했을 때 DJDT 메뉴가 생기는데요. 이걸 누르면 이런 많은 것들을 모두 보여줍니다.
그래서 개발자들의 디버깅용으로 유명한 프로파일링 툴이죠.
하지만 DJDT는 로컬에서만 돌아가는 툴입니다. 즉 실제로 해당 url에 포스트로 들어오는 데이터에 대해서는 프로파일링을 할 수 없다는 단점이 있습니다.
그렇기 때문에 저는 실크라는 프로파일링 툴을 사용했습니다. 실크는 장고 프레임워크를 위한 라이프 프로파일링 툴입니다.
해당 url에 라이브 벤치마킹이 가능하고 과거 이력도 DB에 보여줘서 비교가 용이합니다.
설치방법은 다음과 같습니다.
그리고 마지막으로 프로파일링을 원하는 곳에 데코레이터를 붙여줍니다.
실크 페이지로 가보게 되면 데코레이터를 붙인 url에 대해서 리스폰스가 오기까지 걸린 시간과 쿼리의 총 갯수, 그리고 쿼리에 걸린 시간을 한눈에 보여줍니다.
각 이벤트들에 대한 상세페이지로 들어가보면 실크는 실제로 실행된 쿼리문까지 모두 보여줍니다.
또 각 함수의 트레이스백도 보여주고 프로파일 그래프도 보여줍니다.
실크에 대해서 정리를 하자면 라이브 환경에서 사용 가능한 프로파일링 툴이고 예전 히스토리를 저장해놓을 수 있어서 여러 이벤트들을 모아서 한번에 볼 수 있는 장점이 있습니다. 또 프로파일 그래프와 트레이스백도 지원하죠.
하지만 실제로 실크를 붙여보면 데코레이터를 붙인 rul에 대한 응답이 느려집니다.
또 페이지 자체도 상당히 느리고 ORM를 사용하지 않은 쿼리에 대해서는 보여주지 않는다는 단점이 있습니다.
그래서 쿼리 프로파일링을 하는 법에 대해서 정리를 해보자면 쿼리 스트링을 보는 방법으로는 ORM의 쿼리 attribute나 커넥션 쿼리스가 있습니다.
그래서 여기까지 기본적으로 살펴보았습니다.
이제 드디어 프로파일링 하는 법도 알았고 ORM이 뭔지도 알았으니 실제 서비스의 속도를 개선한 사례에 대해서 말해보려고 합니다.
아까 말씀드린 두 가지 지점 중 API로 들어온 대용량의 데이터를 빠르게 DB로 저장할 때의 쿼리 Optimization에 대해서 설명해드리겠습니다.
처음에 보셨듯이 병원에서 받은 데이터를 저장하는 속도가 너무 느렸습니다. 이걸 분석하기 위해서 데이터를 어떻게 처리했는지 보겠습니다.
먼저 병원에서 매분 수백 개의 페이션트 오브젝트가 리스트로 한번에 들어옵니다. 여기에서 uid란 환자 개개인의 고유한 아이디입니다.
현재 들어온 데이터를 파싱해줘서 저장하는 코드입니다.
환자 하나하나에 대해서 돌게 되는데 해당 uid를 가진 환자를 먼저 get_or_create을 한 다음 필드들의 값을 업데이트해준 다음에 세이브를 호출해서 저장합니다.
일단 가장 큰 문제는 환자를 하나씩 호출해서 저장하기 때문에 느리다는 것입니다.
그러면 환자 한 명씩 저장하지 말고 마지막에 한번에 저장하면 되겠다! 라고 생각하게 되었고 그래서 첫 번째 방법으로 bulk_create()이라는 것을 시도했습니다.
기존의 나이브한 구현과 바뀐 구현의 차이점을 설명드리겠습니다. 하나씩 처리하는 방법에서 여러 개를 처리하는 방법으로 정리하였고 기존의 get_or_create는 그대로 하되 하나씩 세이브하는 것이 아니라 한번에 하도록 구현했습니다.
이 구현은 실패했습니다. 왜냐하면 이미 get_or_create을 통해 생성되거나 가져온 이미 존재하는 것을 다시 생성할 수 없었기 때문입니다.
그래서 두 번째로 시도한 방법은 바로 딜리트 앤 크리에이트입니다. get_or_create을 했기 때문에 이미 존재한 로우를 bulk_create() 할 수 없는 문제가 발생했으니 기존값이 있으면 다 지워버리고 bulk_create()를 시키는 딜리트 올 크레이트를 구현했습니다.
기존에 있던 값을 지우는 것은 두 가지 방법이 있습니다.
로우커리는 성능을 극대화할 수 있다는 장점이 있다면 보안이슈에 취약하고 ORM보다 편리하지 않기 때문에 해당기능을 해주는 ORM이 있다면, 그리고 로우쿼리와 성능차이가 그렇게 나지 않는다면 저는 ORM를 쓰는 것을 추천해드리고 싶습니다.
여기서는 ORM와 로우쿼리간 성능차이가 얼마 나지 않았기 때문에, 그리고 ORM이 있었기 때문에 ORM를 사용했습니다.
실제 코드를 잠깐 보시면 예전 함수에 있었던 get_or_create와 세이브 함수가 사라지고 대신 딜리트 앤 크리에이트가 들어간 것을 볼 수 있습니다. 그러면 여기서는 뭘 하냐. 먼저 해당uid의 환자들을 모두 지우고 한번에 bulk_create()를 하게 됩니다.
이제는 잘 되지 않을까 생각을 했었으나 역시 문제가 있었습니다. 예를 들어 병원에서 소영윤에 대한 환자정보를 6월 10일에 처음 보여주고 한 달 뒤에 환자가 사망해서 정보가 다시 들어왔습니다. 오른쪽과 같이 정보가 모두 들어온다면 우리가 원하는 것처럼 잘 들어가게 됩니다.
그런데 병원에서 업데이트한 정보를 보낼 때마다 모든 정보를 보내지는 않습니다. 이 경우에는 사망 시간을 업데이트하고 싶은 거니까 사망시각과 uid값만 있는 딕트를 내려줍니다.
이 경우에 해보면 기존 정보가 다 삭제되고 마지막에 들어온 정보만 저장되므로 나머지 값들은 다 NULL이 되어버리게 됩니다.
그래서 딜리트 앤 크리에이트의 한계를 정리하자면 업데이트를 해야 할 오브젝트가 왔을 때 업데이티드 된 필드를 제외하고 기존에 저장되어 있던 값들이 덮어씌워집니다.
또 딜리트를 하고 bulk_create()를 하는 것이 각각 개별 쿼리를 수행하는 개별 동작이기 때문에 트랜젝션이 아토믹하지 않습니다.
그래서 딜리트를 하고 bulk_create()를 하는 동안에 어떤 일이 발생할지 예측할 수가 없습니다.
그럼이걸 어떻게 극복할 수 있을까 0방법은 여러 오브젝트에 대해 없는 데이터는 인서트하고 있는 데이터는 업데이트, 줄여서 업설트를 해주는 것입니다.
하지만 장고 ORM으로는 벌크 업설트를 수행할 수 없습니다.
네? 장고 ORM에 없다고요? 잘 안 찾아보신 거 아니에요? 그럴 리가. 라고 생각하실 수 있지만 실제로 그렇습니다.
하나의 오브젝트에 대한 것은 있었지만 우리가 필요한 것은 여러 오브젝트를 한번에 하는 것이었습니다.
또 벌크 업데이트는 있지만 저희는 업데이트할 필드를 선택적으로 정할 수 있게 해주어야 하고 특정 필드를 모두 다른 값으로 세팅할 수 있는 기능이 필요한데 여기에서 제공된 벌크 업데이트는 굉장히 제한된 업데이트만 가능했습니다.
다시 정리를 하자면 제가 필요한 기능은 벌크 업설트이고 이것은 mysql에서는 온 듀플리케이트 키 업데이트라고 부릅니다.
그래서 여기서 ORM의 한계를 느끼고 결국 시도했던 마지막 방법은 로우 쿼리를 만드는 것이었습니다.
지금까지 모든 예시를 환자정보저장으로만 들었지만 실제 서비스에서는 환자 정보만 저장하는 게 아니라 입퇴실정보, 복약정보 등등 다양한 데이터를 저장합니다.
따라서 이 모든 곳에 사용될 수 있도록 제너럴한 함수를 만들었고 이 함수는 결국 sql상의 온 듀플리케이트 키 업데이트를 실행시켜줍니다.
먼저 매핑이 되는 것을 간단히 보겠습니다.
먼저 첫 번째로 들어간 모델 클래스로 테이블 네임을 가져오고 두 번째 인자의 딕셔너리 키 값으로 인서트 해야 하는 필드들을 가져온 뒤 밸류에 넣어둔 람다 펑션으로 각 오브젝트에서 필드와 대응되는 값을 뽑아와서 넣어주고 마지막인자의 업데이트 키스로 업데이트할 필드를 선택적으로 정할 수 있게 해줍니다.
그러면 이제 저희가 시행착오를 겪으며 구현했던 함수들이 어떻게 개선이 되었는지를 한번 보겠습니다.
먼저 get_or_create를 하고 세이브를 했던 기존 구현으로 parse.py를 돌렸을 때 총 1838ms가 걸린다고 나오네요.
좀 더 자세히 살펴보았습니다. 100개의 환자에 대해 300개 정도의 쿼리가 나왔으니 한 환자에서 3개의 쿼리가 발생하다는 것을 알 수 있습니다.
처음 두 개는 겟 올 크리에이트에 의해 불린 것이었고 마지막은 세이브에 의해서 불린 업데이트문이었습니다.
그다음으로 딜리트 앤 크리에이트를 프로파일링 해봤습니다. 쿼리가 300개에서 3개로 줄어들었고 오버롤 타임은 7배 정도 줄었습니다.
실행된 쿼리 수는 하나로 모든 동작이 수행되었습니다.
제가 샘플로 준 100개의 데이터 중 이미 존재하는 게 없었기 때문에 딜리트문은 불리지 않았고 bulk_create만 불렸었네요.
여기서 겟 올 크리에이트 댄 세이브와 딜리트 앤 크리에이트가 어떤 점이 다른지를 보겠습니다.
기존의 나이브한 구현은 인서트 인투 문을 환자 수만큼 수행하지만 딜리트 앤 크리에이트는 bulk_create()를 통해서 한번에 수행합니다. 따라서 시간이 짧아집니다.
마지막으로 구현한 벌크 업설트에 대한 프로파일링입니다.
그런데 이 쿼리는 셀렉트문입니다.
그래서 찾아보니까 실제로 실크에서 로우쿼리는 보여주지 않는다는 2016년에 오픈된 이슈가 있었습니다. 그래서 쿼리가 잘 들어갔나만 확인해보기 위해서 다른 프로파일링 툴인 DJDT를 이용해보았습니다.
그랬을 때 잘 들어간 것을 확인할 수 있었습니다.
지금까지의 긴 여정을 정리해보자면 기존 구현이 너무 느려서 처음에 bulk_create()를 시행했으나 실패하고 결국 로우쿼리로 최적화하는 작업을 진행하였습니다.
결론적으로 나이브한 구현에 비해서 25배이상의 퍼포먼스 개선을 보였습니다. 환자의 수가 더 많아지면 개선은 더욱더 되겠죠.
결론적으로 포린키 매핑이 지워지는 기능상의 문제도 없고 원하는 대로 만드는 데 성공했다는 결론을 지을 수 있었습니다.
자, 이제 마지막 주제로 DB 안에 데이터를 ML모델로 넣을 때 시도했던 Optimization 방법에 대해서 보겠습니다.
DB 안의 데이터를 빠르게 검색해서 ML 모델로 보내는 것과 결과값을 저장하는 것은 이 부분이고 아까 보신 것과 같이 저희 서비스에서는 환자 정보를 시간별로 검색해서 가져오고 받은 예측값을 빠르게 저장하는 것이 필수적입니다.
빠르게 데이터를 가져올 수 있는 방법으로는 풀패칭과 인덱싱이 있고 빠르게 저장하는 방법으로는 배칭이 있습니다.
먼저 셀렉트 릴레이티드와 프리패치 릴레이트는 하나의 쿼리셋을 가져올 때 릴레이티드 오브젝트까지 다 불러와줍니다.
셀렉트 릴레이티드는 조인을 사용해서 쿼리 한번만에 릴레이티드 오브젝트를 패칭해놓는 게 가능합니다.
대신 싱글 밸류드 릴레이션쉽에서만 사용이 가능합니다.
프리패치 릴레이티드는 모든 곳에서 사용이 가능하지만 쿼리 두 번이 필요합니다.
실제 저희 서비스에서 사용한 사례를 보겠습니다.
저희는 겟 애버리지 옵설베이션을 통해서 환자의 데이터를 1시간 간격으로 averaging 한 다음 모델 서버에 값을 보냅니다.
1시간 간격의 옵설베이션스를 가져오기 위해서 먼저 여기 있는 로 해당 쿼리를 가져오게 됩니다.
하지만 이 위에 해당 타임 레인지의 옵설베이션스만을 프리패치해주는 코드를 추가한다면 어떻게 될까요? 이것을 추가한다면 전에 페이션트 닷 옵설베이션스로 가져왔던 코드는 삭제가 가능해집니다.
대신 페이션트 닷 옵설베이션스 인 레인지를 사용해주면 됩니다.
이렇게 함으로서 우리는 DB접근을 최소화 할 수 있습니다.
그다음 방법으로는 인덱싱이 있습니다. 해당 칼럼이 인덱싱을 하면 이후 해당 칼럼 밸률로 검색했을 때 해당 테이별의 레코드를 풀스캔하는 것이 아니라 검색해서 속도를 빠르게 하게 됩니다. 예를 들어서 입원일에 대해서 인덱싱을 해놓았고 입원일에 2018년 7월 26일인 환자를 찾을 때 해당 테이블을 모두 스캔한다면 O(n)의 시간이 걸리겠지만 인덱싱테이별로 찾으면 빠르게 찾을 수 있습니다. 하지만 인덱싱을 성으로 걸고 성이 김인 환자를 찾을 때는 해당하는 로우가 여러 개이기 때문에 스캔속도가 그렇게 빨라지지 않습니다.
정리하자면 인덱싱은 데이터모디피케이션이 많이 일어나는 칼럼에서는 변경이 일어날 때마다 인덱싱 테이블도 같이 변경해줘야 하므로 오히려 속도 저하를 유발할 수 있기 때문에 무조건 좋은 것은 아닙니다.
또 데이터가 많이 중복되는 칼럼에는 크게 효과가 없습니다.
그런데 저희가 ML모델에 보내주기 위해서 패칭해야 하는 데이터는 시계데이터입니다.
그래서 시간 기준으로 자주 검색되어지고 시간데이터는 많이 중복되는 데이터도 아닙니다.
따라서 시간필드에 인덱싱을 하기가 매우 적절합니다.
인덱싱은 실제 코드에서 인덱스를 걸고 싶은 칼럼에 옵션을 주면 됩니다.
또 아까 데이터가 중복되는 칼럼에서는 인덱싱이 큰 효과가 없다고 말씀드렸는데 이런 식으로 여러 개의 칼럼을 한번에 인덱싱할 수도 있습니다. 처음에 성만으로 검색할 때는 별로 큰 효용이 없었던 것이 이름과 함께 있으니 효용성이 높아진 것을 보실 수 있습니다.
이것은 모델클래스 메타에 인덱스 투게더로 선언해주면 됩니다.
마지막으로 배칭에 대해서 보겠습니다. 베칭은 ML모델에서 보내주는 예측값을 저장할 때 사용할 수 있는데 매 분 100개 이상의 결과를 받는 경우에 요청이 100개 쌓였을 때 한번에 저장해주는 방식입니다.
지금까지 제가 어떻게 어떤 방법으로 서비스의 장고 쿼리를 옵티마이제이션을 시켰는지 보았습니다.
먼저 처음에 회사에서 개발 중인 장고 서비스에 대한 간략한 소개와 데이터 처리가 느린 부분에 대해서 설명을 드렸고 성능을 최적화하기 위해 필요한 선수지식을 위해 ORM 지식과 쿼리 프로파일링 툴을 설명드렸습니다. 이후 실제사례를 소개시켜드렸는데 처음는 대용량의 업데이트 또는 생성해줘야 하는 데이터가 들어온 상황, 두 번째는 시간기준으로 빠르게 fetching 해줘야 하는 상황이었습니다.
첫 번째는 결국 로우커리를 만들었고 두 번째는 성능을 개선시켰습니다.
추가적으로 받은 예측값을 빠르게 저장하기 위해 베칭도 소개시켜드렸습니다.
제가 발표한 부분은 제너럴한 부분보다는 특정 케이스에 집중되어 있는 부분이 많지만 그래도 이 발표를 통해서 개발자 분들이 비슷하게 고민하는 문제들에 저만의 해결방안을 공유드리고 싶었습니다.
그래서 여러분이 자신의 상황에 맞는 장고의 기능이 어떤 것인지 알고 쓰셨으면 좋겠습니다. 감사합니다.
이 자리를 빌려서 지난 7개월의 인턴 기간 동안 제가 이 모든 걸 할 수 있게 이끌어주시고 도와주셨던 AITRICS 개발팀 안재만 팀장님께 감사하다는 말씀 드리고 싶습니다.
바로 전에 굉장히 유익한 발표를 해주셨는데요. 관심 있으시면 나중에 들어가서 영상을 보시면 좋을 것 같습니다.
저희 회사에서 이번에 많이 발표를 하는데요. 다음 발표는 바로 이겁니다. 분명히 재미있을 테니까 많은 관심 부탁드립니다. 감사합니다. (박수)
-(사회자) 발표를 진행해주신 윤소영 님, 감사드립니다. 지금부터 질의응답 시간을 가지겠습니다. 궁금한 점이 있으신 분은 가운데 마련된 스탠딩마이크 앞에 나와서 짧게 질문해주시면 됩니다. 원활한 질의응답을 위해서 질문은 한두 개 정도로 부탁드립니다. 그래야 발표자 님께서도 질문내용을 쉽게 기억하고 답변 가능하시니 양해 부탁드립니다.
(영어 통역 중)
-(질문) 발표 잘 들었습니다. 궁금한 게 두 가지 있는데요. 하나는 서버가 몇 대가 있는지가 궁금했어요.
왜냐하면 서버가 약간 마이크로서비스처럼 벌크하게 있으면 그 쿼리튜닝을 그렇게 하지 않더라도 여러 가지 서버에서 한번에 여러 API 리퀘스트를 분산해서 처리할 수 있으니까 굳이 그렇게 할 필요가 없을 것 같았고.
또 하나 질문은 키가 좀 확실하게 정해져있는 것 같은 경우는 업설트가 자동으로 되는데 그런 것에 대해서 생각해보지는 않으셨는지 궁금했거든요.
그러니까 지금 DB를 어떤 걸 쓰셨는지 잘 모르겠는데...
-(발표자) Mysql을 썼습니다.
-(질문) 다른 걸 사용하는 걸 고려해보셨는지.
-(발표자) 그 부분도 지금 저희가 래디스를 사용하고 있는데 그거는 파이콘의 장고랑은 딱히 상관이 없다고 생각이 들어서 뺐고요. 물론 그걸 이용하면 더 빠른 패칭이 가능하게 되죠.
그리고 첫 번째 질문에 대해서는 잠시만요.
여기 보시면 저희는 지금 저희 회사가 엄청 크고 이러지는 않아서 시범적으로 병원과 API를 호출하고 받는 부분을 운영을 하고 있어서 일단 지금 저희의 급성질환예측솔루션 서버는 한 개고 머신러닝 모델 서버 한 개가 돌아가고 있는 상황입니다.
그래서 병렬적으로 처리를 하게 되면 분명히 빨라지겠지만 지금 저희가 있는 상황에서는 최대한 빠르게 할 수 있는 게 그거라고 생각했습니다.
감사합니다.
-(질문) 안녕하세요? 발표 잘 들었고요. 저도 회사에서 프로파일링 툴 두 개 다 사용하고 있어서 공감하면서 들었는데요.
실크 같은 경우에는 모든 프로파일링이 DB에 남기 때문에 실시간으로 서빙할 때는 좀 사용하기가 꺼려지더라고요.
그리고 로우가 다 쌓이다 보니까 그런 아카이브전략들을 어떻게 세우셨을지가 궁금했거든요.
-(발표자) 음... 그 부분에 대해서는.
-(질문) 주기적으로 데이터를 삭제를 하셨는지...
-(발표자) 저는 딱히 삭제하지는 않았고 이거는 저희가 뭔가 브로드하게 사용한 게 아니라 그냥 이 성능을 개선하기 위해서 잠깐 사용한 거라서 그 부분에 대해서는 저도 잘 아는 게 없는 것 같습니다.
-(질문) 감사합니다.
-(질문) 발표 잘 들었고요. 저는 데이터 쪽으로 궁금한 게 있는데 지금 뭔가 환자데이터가 시계열로 들어오는데 환자분께서 돌아가시거나 했을 때 양식이 다른 게 받아지잖아요.
-(발표자) 키는 같은데 모든 키가 들어오는 게 아니라 해당 키만 들어오게 되는 거예요.
-(질문) 그래서 벌크를 처리할 때 그런 예외 케이스의 비율이 어느 정도 되는지 궁금합니다.
그러니까 벌크 처리를 하는 데 있어서 만약에 환자 100명을 처리를 하는데 예외적으로 들어오는 것들이 100에 70 정도로 많이 들어오는지. 왜냐하면 병원에서 들어오는 응급데이터니까. 아니면 일상적으로 받을 때 꾸준하게 벌크로 처리할 수 있을 정도로 대부분이 동일한 양식으로 들어오는지 그런 게 궁금하더라고요.
왜냐하면 그게 좀 벌크로 처리할 수 있으려면 다 비슷하게 들어오면 일부의 케이스 시간대에서만 좀 예외케이스의 쿼 리를 처리할 수도 있는 방법이 있을 것 같은데 그런 쪽으로 궁금해서 질문드렸습니다.
-(발표자) 지금으로서는 그렇게 업데이트되는 값이 그렇게 많이 들어오지는 않습니다. 정량적으로 말씀드릴 수는 없는데 5% 정도인 것 같습니다. 그래서 말씀하신 것처럼 예외적으로 처리를 할 수 있는 방법도 있는 것 같은데 그런 부분들이 계속 에러를 내다 보니까 그런 상태입니다.
-(질문) 감사합니다.
-(질문) 발표하느라 수고하셨습니다. 제 질문은 아키텍쳐에 조금 더 가까운 건데요. 지금 얘기를 들었을 때는 이 API가 싱크로나스하게 돌아갈 필요가 없는 것 같거든요. 앱서비스가 아니니까요. 그런데 왜 샐러리 같은 백그라운드로 저장하는 방식을 사용하지 않았는지.
-(발표자) 그 부분도 저희가 샐러리를 사용하고 있고요. 그리고 그 부분도 파이콘와 관련이 없다고 생각해서 빼고 이 부분만 이야기를 한 거고 저희 지금 실제 서비스에서는 샐러리워커를 이용해서 이거를 멀티스레딩 해서 저장을 하고 있고 그 외에 제가 장고로 Optimization 할 수 있는 방법들을 소개해드린 거라고 보시면 됩니다.
-(질문) 샐러리면 파이콘하고 굉장히 관련이 있을 것 같기는 합니다만, 실제로는.
파이콘과 관련이 클 것 같다고요. 샐러리가.
답변 잘 들었습니다.
(박수)