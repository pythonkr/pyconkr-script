1
00:00:00,790 --> 00:00:07,070
안녕하세요 소개받은 이용중입니다

2
00:00:07,070 --> 00:00:10,720
세션 제목이 집에서 만든 머신러닝기반

3
00:00:10,720 --> 00:00:12,330
자동번역기 인데요

4
00:00:12,330 --> 00:00:18,180
사실은 슬라이드 제목은 이거예요

5
00:00:18,180 --> 00:00:22,400
esmt 베이스 로만 투 코리아

6
00:00:22,400 --> 00:00:26,080
코리아 트랜스 L L 오라고 입으시면 되고

7
00:00:26,080 --> 00:01:13,680
도대체 이게 뭐 하는 거냐 를 잠깐 보여 드리겠습니다

8
00:01:13,680 --> 00:01:28,110
요 거예요 자 막상 봤는데

9
00:01:28,110 --> 00:01:30,450
도대체 이걸 어디다 쓰는 야

10
00:01:30,450 --> 00:01:33,200
뭐 이런 생각 하실 분들 분명히 있을 겁니다

11
00:01:33,200 --> 00:01:36,490
그래서 설명을 조금 드리고 시작을 할게요

12
00:01:36,490 --> 00:01:45,820
저는 윈도우 3.1 뭐 이럴 때도 컴퓨터를 썼었습니다

13
00:01:45,820 --> 00:01:47,940
많은 분들이 보셨을 거 같지만

14
00:01:47,940 --> 00:01:51,910
사실 또 어떤 분들은 자기는 그 수업 시간에

15
00:01:51,910 --> 00:01:53,530
천공카드 에다가 이 말하고

16
00:01:53,530 --> 00:01:55,080
omr 카드 처럼 생긴 애가 구멍

17
00:01:55,080 --> 00:01:56,470
뚫어 가지고 숙제 제출했다고

18
00:01:56,470 --> 00:01:59,970
이런 말씀 하시는 분도 봤는데 아

19
00:01:59,970 --> 00:02:02,330
옛날에는 모터스 시절에도 그랬지만

20
00:02:02,330 --> 00:02:06,280
한글 입력하는 게 그렇게 불편해 있었어요

21
00:02:06,280 --> 00:02:09,340
가려고 이제 한글 입력기 가

22
00:02:09,340 --> 00:02:12,370
윈도우에 기본으로 달려 오지 않는 경우도 있었기 때문에

23
00:02:12,370 --> 00:02:16,610
클래식 나가지고 죽어 버리는 경우도 특히 그래

24
00:02:16,610 --> 00:02:21,120
윈도우 하고 랭귀지 팩을 따로 구매를 하다 보니까

25
00:02:21,120 --> 00:02:22,650
제외를 나가게 된다거나

26
00:02:22,650 --> 00:02:26,240
그럴 때 이제 111 안 들고 나가면

27
00:02:26,240 --> 00:02:28,480
그 나라 키보드를 써야 되니까

28
00:02:28,480 --> 00:02:29,810
한글을 쓸 수가 없게 된다

29
00:02:29,810 --> 00:02:32,010
그러면 이메일을 보낸다던가

30
00:02:32,010 --> 00:02:40,030
채팅을 할 때 되게 곤란한 상황이 발생을 하는 거죠

31
00:02:40,030 --> 00:02:44,910
아시는 분들 어 이게 접속인원 안녕하세요

32
00:02:44,910 --> 00:02:47,250
97년도 형아 이거 꽤 오래 됐죠

33
00:02:47,250 --> 00:02:49,380
저는 봤습니다 이 무슨 영화

34
00:02:49,380 --> 00:02:52,150
아니면 저 위에 있는 게 한 석계역 이 사람

35
00:02:52,150 --> 00:02:53,820
아이디가 해피엔드 고요

36
00:02:53,820 --> 00:03:00,250
밑에가 전동 여기는 2라는 아이디로 나가서 둘이서 채팅하면서

37
00:03:00,250 --> 00:03:04,120
밀당 하는 이야기를 다 이거 안 보신 분들은 재밌으니까 물어보세요

38
00:03:04,120 --> 00:03:05,890
계속 만날까 말까 만날까 말까

39
00:03:05,890 --> 00:03:08,800
이렇게 하는 그런 중한데

40
00:03:08,800 --> 00:03:10,680
둘이 이제 채팅 하는 장면이 있죠

41
00:03:10,680 --> 00:03:13,030
저도 이런 경험을 여러 번 해봤는데

42
00:03:13,030 --> 00:03:16,960
조화 이틀 채팅 채팅 이런 거야

43
00:03:16,960 --> 00:03:20,990
이게 둘이서 처음 채팅에서 만났던 온라인상에서 만났던

44
00:03:20,990 --> 00:03:23,100
그 때 그 영상이에요

45
00:03:23,100 --> 00:03:27,190
그래서 해피엔드 한석규가 이수현님 맞습니까 라고 물었을 때

46
00:03:27,190 --> 00:03:30,430
전도연이 끄덕끄덕 이렇게 대답을 하지

47
00:03:30,430 --> 00:03:33,640
근데 잠깐 지 10초 전으로 들어가서

48
00:03:33,640 --> 00:03:35,540
한석규가 말을 처음으로 걸어왔는데

49
00:03:35,540 --> 00:03:37,100
한글 입력이 안 되는 거예요

50
00:03:37,100 --> 00:03:40,830
어떻게 할 거야

51
00:03:40,830 --> 00:03:43,270
조금 뭐 지금 해외 출장 중이라서

52
00:03:43,270 --> 00:03:44,150
한글을 쓸 수가 없어요

53
00:03:44,150 --> 00:03:46,000
대답을 해야 될 텐데

54
00:03:46,000 --> 00:03:48,690
그럼 지금 같으면 이런 방법이 있겠죠

55
00:03:48,690 --> 00:03:55,410
뭐 이렇게 물론 이응 자를 대신 대문자 이렇게 쳐야 되겠지

56
00:03:55,410 --> 00:03:59,910
만 근데 당신은 이라는 말이 없었어요

57
00:03:59,910 --> 00:04:04,640
이렇게 했을 리가 없죠 이렇게 했었습니다

58
00:04:04,640 --> 00:04:09,190
예스아이엠 유창한 영어로 근데 그러면 상대방이 굉장히 싫어해요

59
00:04:09,190 --> 00:04:12,700
재수 없다고 하고

60
00:04:12,700 --> 00:04:14,930
응 못 갔네요 왕이니까

61
00:04:14,930 --> 00:04:17,910
유창한 영어로 대답을 할 수 있었겠지만

62
00:04:17,910 --> 00:04:22,890
현실적인 방법이 이렇게 알파벳으로

63
00:04:22,890 --> 00:04:24,110
우리말을 치는 거예요

64
00:04:24,110 --> 00:04:28,010
끄덕끄덕 상대방이 별로 좋아하지는 않습니다

65
00:04:28,010 --> 00:04:33,040
근데 어떤 사람들은 재밌게 받아들여 주기로 했었어요

66
00:04:33,040 --> 00:04:34,710
진짜 재미 없는 경우

67
00:04:34,710 --> 00:04:39,060
이런 거야 영문으로 영어를 발음나는대로 쓰는 거

68
00:04:39,060 --> 00:04:40,250
이런 경우도 진짜 있었어요

69
00:04:40,250 --> 00:04:44,710
저는 이런 식으로 해외에서 이메일 써 본 적이 있어요

70
00:04:44,710 --> 00:04:45,800
입력이 안 돼서 인도

71
00:04:45,800 --> 00:04:51,780
같은 데 가면 한글 입력 만드는 컴퓨터를 자주 만나게

72
00:04:51,780 --> 00:04:54,280
저는 이런 경험들을 오래전에 했었는데

73
00:04:54,280 --> 00:04:58,850
어느날 구글 툴스 라는 거를 보게 됐어요

74
00:04:58,850 --> 00:05:03,420
이게 뭐냐면은 여러분도 안 써 보신 분들이 많을 거야

75
00:05:03,420 --> 00:05:06,510
이거 6월에 접속하시면 경험할 수 있는데

76
00:05:06,510 --> 00:05:10,460
가장 저거 를 활성화 시켜 놓고 이메일 같은 데다가

77
00:05:10,460 --> 00:05:13,210
이렇게 영문으로 가령

78
00:05:13,210 --> 00:05:15,810
이제 운동 같은 경우에 방문으로 나마스테

79
00:05:15,810 --> 00:05:20,110
이렇게 치면 현진 말로 타이핑이 됩니다

80
00:05:20,110 --> 00:05:22,760
이런 거를 이제 트랜스레이션 이라고 한다는 거를

81
00:05:22,760 --> 00:05:23,730
이걸 보고 처음 알았어요

82
00:05:23,730 --> 00:05:27,090
제가 해서 지원하는 오른쪽에 테이블

83
00:05:27,090 --> 00:05:29,770
지원하는 언니가 굉장히 많은데

84
00:05:29,770 --> 00:05:33,130
그 케이블 크로스 된 거라고 보시면

85
00:05:33,130 --> 00:05:37,720
고기가 이제 트랜스레이터 레이션을 지원하는 언어들 목록 거든요

86
00:05:37,720 --> 00:05:39,620
근데 코리아는 없습니다

87
00:05:39,620 --> 00:05:41,150
우리 말은 지금 현재까지도

88
00:05:41,150 --> 00:05:44,220
트랜스레이터 되지 않고 있어요

89
00:05:44,220 --> 00:05:46,720
그래서 아내가 만들어 보자 라고 시작

90
00:05:46,720 --> 00:05:57,430
한 개 바로 막 좀 아까 보신 거예요

91
00:05:57,430 --> 00:06:01,010
저거를 만들기 위해서 뭐 몇 가지 궁리를 했었는데

92
00:06:01,010 --> 00:06:02,540
하시는 저게 머신

93
00:06:02,540 --> 00:06:04,840
트랜스레이션 기술을 사용을 해

94
00:06:04,840 --> 00:06:06,790
가지고 만들어진 거거든요

95
00:06:06,790 --> 00:06:11,230
등장이 일반적인 자동번역기 수를 그대로 사용을 했기 때문에

96
00:06:11,230 --> 00:06:13,390
일단 제 머신 트랜슬레이션

97
00:06:13,390 --> 00:06:16,270
에 대해서 일반적인 설명을 드리고

98
00:06:16,270 --> 00:06:21,530
그 다음에 이 프로젝트를 그 일관적인 트랜스레이션 문제

99
00:06:21,530 --> 00:06:24,430
테이블 해서 트레이닝 하고

100
00:06:24,430 --> 00:06:33,860
뭘 만드는 과정에 대해서 요런 순서대로 설명을 드리겠습니다

101
00:06:33,860 --> 00:06:34,970
전화도 못 하는 사람

102
00:06:34,970 --> 00:06:36,880
옛날 있었어요 이 사람이 자기 농

103
00:06:36,880 --> 00:06:39,390
물에다가 그린상가 켰는데요

104
00:06:39,390 --> 00:06:42,390
왼쪽 하단에 보면 이제 소스텍스트 가 있고

105
00:06:42,390 --> 00:06:45,220
오른쪽 하단에 이제 타겟 텍스트가 있죠

106
00:06:45,220 --> 00:06:47,120
이거 이렇게 번역하는 당귀에 대해서

107
00:06:47,120 --> 00:06:49,310
그렇게 도식화 해 놓은 건데요

108
00:06:49,310 --> 00:07:02,700
상중하로 3단계로 나눠져 있는 것을 볼 수가 있습니다 이

109
00:07:02,700 --> 00:07:04,240
가장 아래에 있는 다이렉트

110
00:07:04,240 --> 00:07:06,850
트랜슬레이션 부터 확인해 보면요

111
00:07:06,850 --> 00:07:08,470
근데 이거는 단어 하나하나

112
00:07:08,470 --> 00:07:11,850
번역해 가지고 나열하는 방식이 되겠죠

113
00:07:11,850 --> 00:07:13,990
이게 이게 일단 어떤 언어에 대한 분석

114
00:07:13,990 --> 00:07:17,600
이런 게 전혀 없다 보니 문자가 많이 생기는데

115
00:07:17,600 --> 00:07:19,970
예를 들면 오순이 다른 경우

116
00:07:19,970 --> 00:07:24,220
번역을 할 수가 없게 되어 있는 것처럼

117
00:07:24,220 --> 00:07:28,510
SO sad The bible study

118
00:07:28,510 --> 00:07:34,900
영어를 번역을 하면 우리나라 말하고는 어순이 다르기 때문에

119
00:07:34,900 --> 00:07:36,900
그대로 단어를 나열 하게 되면

120
00:07:36,900 --> 00:07:42,590
소식 소식통은 어제 IBM 로터스를 샀다고 말했다

121
00:07:42,590 --> 00:07:46,140
하겠지

122
00:07:46,140 --> 00:07:49,980
호순이 이제 집 앞에 있죠

123
00:07:49,980 --> 00:07:53,250
그 다음에 같은 단어가 다른 의미로 사용되는 경우

124
00:07:53,250 --> 00:07:55,900
애도 이거는 이제 대응을 할 수가 없습니다

125
00:07:55,900 --> 00:08:00,830
그 밑에 데이셀 I like ice cream 하고

126
00:08:00,830 --> 00:08:01,760
밑에 있는 데

127
00:08:01,760 --> 00:08:05,750
일 라잇 깔아 스크린 하고는 의미가 다른 말이 잖아요

128
00:08:05,750 --> 00:08:08,140
근데 얘는 그걸 9분을 못 해요

129
00:08:08,140 --> 00:08:12,450
이런 문제도 있죠 다시 한번 올라가 볼게요

130
00:08:12,450 --> 00:08:14,080
인터링구아 스테이션 애경

131
00:08:14,080 --> 00:08:17,820
오늘 오늘 의성에 그 시멘트 레벨까지

132
00:08:17,820 --> 00:08:20,780
분석을 해서 동일한 의미를 가진 파괴

133
00:08:20,780 --> 00:08:27,290
너를 그렇게 제너레이션 해주는 형태 트랜슬레이션 방법이에요

134
00:08:27,290 --> 00:08:28,720
지금 나오는 딥러닝

135
00:08:28,720 --> 00:08:32,750
권역 기술들이 여기에 점점 더 가까워지고 있죠

136
00:08:32,750 --> 00:08:34,040
이거 사이에 이제 트랜스포머

137
00:08:34,040 --> 00:08:36,860
트랜스레이션 이라고 하는 게 있던데

138
00:08:36,860 --> 00:08:40,160
소스 오늘의 스트럭쳐를 하고

139
00:08:40,160 --> 00:08:43,370
왼쪽에 이제 스트럭쳐를 분석하는 아날리시스

140
00:08:43,370 --> 00:08:44,450
화살표가 올라가죠

141
00:08:44,450 --> 00:08:47,750
어느 단계에 이르면 그거를 타겠네

142
00:08:47,750 --> 00:08:49,800
스트럭처 로 트랜스프리 나옵니다

143
00:08:49,800 --> 00:08:51,190
그리고 다시 타게

144
00:08:51,190 --> 00:08:53,100
언어를 제너레이션 함으로써

145
00:08:53,100 --> 00:08:59,230
밑으로 내려 오는 거는 방식의 번역 기술인데 법인데

146
00:08:59,230 --> 00:09:00,310
여기서 말하면 오후에

147
00:09:00,310 --> 00:09:03,220
구조는 또 세 개로 나눌 수가 있어요

148
00:09:03,220 --> 00:09:07,720
이렇게 모드 베이스 플레이스페이스 신택스

149
00:09:07,720 --> 00:09:10,880
베이스 트랜슬레이션 등의 그거 된다

150
00:09:10,880 --> 00:09:14,520
요번 쪽에 보시는 것처럼

151
00:09:14,520 --> 00:09:20,090
월드 베이스 경우 여기 많이 하나 라는 게 스페인어로 아침

152
00:09:20,090 --> 00:09:23,870
또는 내일이라는 의미를 가지고 있거든

153
00:09:23,870 --> 00:09:28,450
그 오늘을 매칭되는 단원으로 바꿔주는

154
00:09:28,450 --> 00:09:31,010
그리고 순서를 일찍이 바꿔도 돼 소결하는 고개

155
00:09:31,010 --> 00:09:34,660
이제 어드밴스트 트랜스레이션 이고

156
00:09:34,660 --> 00:09:38,540
중간에 있는 것처럼 이거를 그 얼라이먼트 하고

157
00:09:38,540 --> 00:09:40,160
번역을 프레이즈 베이스로

158
00:09:40,160 --> 00:09:43,530
어떤 어부 어부 같은 거를 대출을 해 가지고

159
00:09:43,530 --> 00:09:46,940
그거를 베이스로 똑같은 일을 하는 게

160
00:09:46,940 --> 00:09:49,300
이제 플레이스페이스 고요

161
00:09:49,300 --> 00:09:55,200
마지막으로 문장에 그 문법적인 구조를 트리로 파싱을 한 다음에

162
00:09:55,200 --> 00:10:00,100
그거 에서부터 단위로 트랜스포머 더 하고

163
00:10:00,100 --> 00:10:07,940
이제 순서정렬 도하는 이게 이게 킨텍스 베이스추천 스테이션입니다

164
00:10:07,940 --> 00:10:10,720
우리는 오늘 이것 중에 가장 낮은 단계의 월드 베이스

165
00:10:10,720 --> 00:10:15,150
트랜슬레이션 을 보고 해야 될 거예요

166
00:10:15,150 --> 00:10:20,020
트랜슬레이션 얼마나 원시적인 기술인 지는 머신 머신 트랜슬레이션

167
00:10:20,020 --> 00:10:24,510
역사를 보면 알 수가 있어요

168
00:10:24,510 --> 00:10:29,650
일단 중간에 smt 스티커 스티커 스티커 붙어 보시면요

169
00:10:29,650 --> 00:10:31,620
88년에 아이비 에이비

170
00:10:31,620 --> 00:10:36,400
처음으로 어드벤처 스페이스 레이션을 개발했습니다

171
00:10:36,400 --> 00:10:40,970
올해는 시간이 지나서 스페이스 모델로 발전을 했고요

172
00:10:40,970 --> 00:10:42,720
급진전을 해가지고 2006년

173
00:10:42,720 --> 00:10:47,270
드디어 구글에서 트랜스레이션 서비스가 실적에 됐죠

174
00:10:47,270 --> 00:10:52,160
그러다가 이제 2013년의 뉴럴 네트워크 기반의 번역

175
00:10:52,160 --> 00:10:57,660
기 번역기에 관련된 논문 발표가 됐어요

176
00:10:57,660 --> 00:10:59,860
2013년이면 인물로부터

177
00:10:59,860 --> 00:11:03,840
딥러닝 에 대한 얘기가 막 활발하게 시작되던 물어봤거든요

178
00:11:03,840 --> 00:11:10,050
결국 2016년 부터는 기존의 smt 베이스

179
00:11:10,050 --> 00:11:12,980
번역기들 전부 다 대체를 해버립니다

180
00:11:12,980 --> 00:11:16,980
3년 만에 합계에서 막 얘기 된 게

181
00:11:16,980 --> 00:11:18,250
프로덕션 내 100까지 가는 건

182
00:11:18,250 --> 00:11:21,700
근성이 3년이라는 시간이 굉장히 짧은 거거든요

183
00:11:21,700 --> 00:11:25,660
문제 8만 원 정도가 이루어졌다

184
00:11:25,660 --> 00:11:31,000
파파고 도 2016년에 나왔어요

185
00:11:31,000 --> 00:11:32,700
근데 자동번역기 연구는 4

186
00:11:32,700 --> 00:11:36,790
7 80년대 혹시 이전부터 시작이 됐었거든요

187
00:11:36,790 --> 00:11:38,110
88년에 ibm 왓슨

188
00:11:38,110 --> 00:11:44,220
연구소 에서 어떤 획기적인 연구 결과를 내놓기 전까지

189
00:11:44,220 --> 00:11:45,760
좋은 결과가 나오지 못한 채로

190
00:11:45,760 --> 00:11:48,120
굉장히 많은 시간이 흘렀습니다

191
00:11:48,120 --> 00:11:49,060
그러다가 이제 이거는

192
00:11:49,060 --> 00:11:51,400
비용이 많이 드는 영국이 때문에 하지 말아야 된다

193
00:11:51,400 --> 00:11:53,410
뭐 이런 식으로 포트도 있어 가지고

194
00:11:53,410 --> 00:11:55,060
경북 소들에게 펀딩이 끊겨 가지고

195
00:11:55,060 --> 00:11:59,920
더 이상 연결을 못 하는 상황에 까지도 일을 하셨어요

196
00:11:59,920 --> 00:12:06,290
그런데 사실 smt 기술이 활발하게 발전하는데

197
00:12:06,290 --> 00:12:09,000
굉장히 중요한 키가 됐던 이론이나

198
00:12:09,000 --> 00:12:13,190
기술들은 1940년대에 만들어진 코딩이론

199
00:12:13,190 --> 00:12:14,710
암호화기술 이었거든요

200
00:12:14,710 --> 00:12:17,150
심지어는 더 것을 올라갔을 경우에 18

201
00:12:17,150 --> 00:12:20,900
베이스 요령 같은 것도 굉장히 큰 역할을

202
00:12:20,900 --> 00:12:25,600
우리는 거기서부터 이제 얘기를 시작을 해 볼 거예요

203
00:12:25,600 --> 00:12:31,550
훗날에 이제 48년에 노이즈 채널이라는 이론이 클로드섀넌

204
00:12:31,550 --> 00:12:33,210
일하는 사람을 위해서 만든 건데

205
00:12:33,210 --> 00:12:35,580
이게 현관에 이제 머신 트랜스레이션

206
00:12:35,580 --> 00:12:38,180
굉장히 큰 기여를 하게 되죠

207
00:12:38,180 --> 00:12:41,770
원래 노인층을 일하는 거는 통신 할 적에

208
00:12:41,770 --> 00:12:46,210
뭐 채널 프리스티지를 계산하는 목적으로 하려고 그런

209
00:12:46,210 --> 00:12:48,670
그런 목적으로 만들어진 일요일인데

210
00:12:48,670 --> 00:12:51,010
통신상의 에러를 검출하거나 수정하고

211
00:12:51,010 --> 00:12:53,210
혹은 뭐 암호화 이게

212
00:12:53,210 --> 00:12:56,400
이제 세계대전 2차 세계대전 바로 집으로 있기 때문에

213
00:12:56,400 --> 00:12:59,150
아무 하고 복호화하는 기술의 사용됐던 일원입니다

214
00:12:59,150 --> 00:13:06,680
그게 한참 더 지나서 트랜스레이션 사용했던 거죠

215
00:13:06,680 --> 00:13:09,780
추천 어리 머신 트랜스 트랜슬레이션 에서

216
00:13:09,780 --> 00:13:11,740
어떤 식으로 기어를 하냐면

217
00:13:11,740 --> 00:13:13,140
왼쪽에 이제 굿모닝 이라는

218
00:13:13,140 --> 00:13:15,010
영어 문자가 그 영어

219
00:13:15,010 --> 00:13:18,610
문장이 들어왔을 때 이 노이지 채널을 통해서 9교시

220
00:13:18,610 --> 00:13:23,640
부에노스디아스 라고 스페인어로 출력이 되는 겁니다

221
00:13:23,640 --> 00:13:25,210
이거를 계속 반복을 하면

222
00:13:25,210 --> 00:13:29,570
우리가 어떤 패턴을 파악할 수 있겠다 라고

223
00:13:29,570 --> 00:13:36,030
생각을 했던 거죠 이 그림을 좀 더 이해를 하시려면

224
00:13:36,030 --> 00:13:38,350
그리고 앞으로의 내용들을 더 많이 이해를 하시려면

225
00:13:38,350 --> 00:13:41,410
컨벤션에 하나 익숙해져야 될 수도 있는데요

226
00:13:41,410 --> 00:13:43,320
파란상자 소개 랭귀지

227
00:13:43,320 --> 00:13:45,720
이대 문자 이기는 소스 랭귀지 예요

228
00:13:45,720 --> 00:13:48,460
이건 대문자 A 는 언어를 뜻하는 거고요

229
00:13:48,460 --> 00:13:51,800
여기서는 잉글리쉬의 이겠죠

230
00:13:51,800 --> 00:13:54,000
그리고 그거에 속한 송은

231
00:13:54,000 --> 00:13:58,010
자기는 센터스 한 문장을 뜻하는 겁니까

232
00:13:58,010 --> 00:13:59,620
마찬가지로 랭귀지 F

233
00:13:59,620 --> 00:14:03,980
는 프렌치 또는 폴린 랭귀지 AF650

234
00:14:03,980 --> 00:14:09,150
소문자 F 는 랭귀지 센터

235
00:14:09,150 --> 00:14:11,640
이게 왜 이렇게 되냐면 smt

236
00:14:11,640 --> 00:14:13,000
에그 왓슨연구소 에서 아까

237
00:14:13,000 --> 00:14:17,200
얘기했던 논문에서 사용했던 게 프렌치 하고

238
00:14:17,200 --> 00:14:19,910
영어의 급해 갖고 버스 옆에 그냥 그래 가지고

239
00:14:19,910 --> 00:14:23,570
그 때부터 컨벤션 만들어져서 마침 F 가

240
00:14:23,570 --> 00:14:28,100
이제 포린 랭귀지 for 일하는 중에 적이 있었기 때문에

241
00:14:28,100 --> 00:14:29,550
오늘 상관없이 소스

242
00:14:29,550 --> 00:14:34,170
텍스트는 텍스트는 소스텍스트

243
00:14:34,170 --> 00:14:35,830
4프로 사용하는 경우도 많습니다

244
00:14:35,830 --> 00:14:38,500
앞으로 계속 사용되기 때문에

245
00:14:38,500 --> 00:14:40,960
우리가 프렌즈에서 영어로 번역한다

246
00:14:40,960 --> 00:14:43,560
돈을 벌기 위해서 영어로 번역한다

247
00:14:43,560 --> 00:14:50,080
이렇게 이해를 하시면 돼요

248
00:14:50,080 --> 00:14:56,990
아까처럼 그 소스 랭귀지 입력이 되었을 때

249
00:14:56,990 --> 00:14:59,430
타 계량기 gif 5가 출력

250
00:14:59,430 --> 00:15:03,070
이대역 되면은 우리가 배울 수 있는 확률 모양은

251
00:15:03,070 --> 00:15:07,920
이에 대한 조건부 feedinfo 전방유리 되겠죠

252
00:15:07,920 --> 00:15:14,010
위에 표시된 PF 기분이 모임 일정 근데 사실

253
00:15:14,010 --> 00:15:15,520
우리가 하고 싶은 트랜슬레이션

254
00:15:15,520 --> 00:15:22,370
맨 밑에 F 를 입력하는 티하우스 거거든요

255
00:15:22,370 --> 00:15:25,730
근데 이거는 소스가 프렌치 하겠지

256
00:15:25,730 --> 00:15:31,620
그래서 소스 FM 대한 접근 공유를 조사를 하게 돼요

257
00:15:31,620 --> 00:15:34,570
방향이 반대죠 왜 이렇게 됐냐면

258
00:15:34,570 --> 00:15:38,430
기술이 사용되기 때문인데요

259
00:15:38,430 --> 00:15:43,090
우측에 요거 이거

260
00:15:43,090 --> 00:15:48,690
베이즈 룰이 데이비드 해서 이렇게 바뀐 거예요

261
00:15:48,690 --> 00:15:52,670
여기 밑에 보는 거에 for 대한 확률이 없어졌죠

262
00:15:52,670 --> 00:15:53,820
이거는 아

263
00:15:53,820 --> 00:15:56,140
그 맥스 일을 인자로

264
00:15:56,140 --> 00:15:59,560
하나금 엑셀을 시장을 하면서 이 파라미터가 FL

265
00:15:59,560 --> 00:16:03,300
작용을 하지 않기 때문에 그냥 생각한 겁니다

266
00:16:03,300 --> 00:16:09,100
그래서 트랜스레이션 시스템은 용인시까지 같이 표시를 해요

267
00:16:09,100 --> 00:16:11,420
F 를 입력으로 하고

268
00:16:11,420 --> 00:16:16,140
그거는 이에 대한 확률과 이에 대한 FA

269
00:16:16,140 --> 00:16:22,370
컵 에 대한 마그맥스 결과

270
00:16:22,370 --> 00:16:25,570
뮤직에서 우리는 세 가지 쿠폰으로 나눌 수가 있어요

271
00:16:25,570 --> 00:16:30,970
첫 번째가 이제 랭귀지 모델 peeve

272
00:16:30,970 --> 00:16:34,180
두 번째가 이제 트랜스레이션 모델

273
00:16:34,180 --> 00:16:39,360
이에 대한 조금 조금 확률 마지막으로 뒤 포도입니다

274
00:16:39,360 --> 00:16:51,920
아 그 맥스 랭귀지 뭐 다른 그 번역기의 어떤 유창함

275
00:16:51,920 --> 00:16:55,050
뭐 이런 걸 담당을 하겠죠

276
00:16:55,050 --> 00:16:58,770
랭귀지 모델을 학습할 때는 영어

277
00:16:58,770 --> 00:17:01,810
코퍼스 하나만 있으면 되게 되게

278
00:17:01,810 --> 00:17:07,710
트랜슬레이션 모델은 번역기에 정확도 를 맡게 되는데

279
00:17:07,710 --> 00:17:12,130
요거를 가려면은 4를 남기죠

280
00:17:12,130 --> 00:17:17,440
영어의 페어와이즈 코스가 필요하게 되면

281
00:17:17,440 --> 00:17:20,940
마지막에 디코더는 위에서 트레이닝 트레이닝

282
00:17:20,940 --> 00:17:24,960
랭귀지 모델과 트랜슬레이션 모델을 가지고

283
00:17:24,960 --> 00:17:27,860
어떤 이미 그 캔디데이트

284
00:17:27,860 --> 00:17:29,550
캔슬레이션 결과를 만들어 낸 거야

285
00:17:29,550 --> 00:17:34,440
대해서 스코어링 한 다음에 제일 좋은 결과

286
00:17:34,440 --> 00:17:38,680
좋은 결과를 준 문장이 일을 찾아내는 거예요

287
00:17:38,680 --> 00:17:40,320
그래서 이걸 뭐라고 불러요

288
00:17:40,320 --> 00:17:50,820
이거는 이제 검색 영역이 되겠고요

289
00:17:50,820 --> 00:17:56,190
생각보다 시간이 굉장히 빨리 가네요

290
00:17:56,190 --> 00:17:59,460
시스템 관점에서 보면 요런 식으로 그럴 수가 있는데요

291
00:17:59,460 --> 00:18:06,110
가영 좀 그러니까 뭐 문자 있다면

292
00:18:06,110 --> 00:18:10,140
요게 트랜슬레이션 모델을 통해 했을 경우에

293
00:18:10,140 --> 00:18:13,540
요런 몇 가지의 그 캔디데이트 문장들

294
00:18:13,540 --> 00:18:15,450
만들어 줄 수가 없대요

295
00:18:15,450 --> 00:18:18,940
그거에 트랜스레이션 probit 는 오른쪽에

296
00:18:18,940 --> 00:18:22,870
빨간색으로 표시된 여기서

297
00:18:22,870 --> 00:18:30,930
제일 좋은 결과를 지금 보여 주는 거는 맨 아래에 있는 I

298
00:18:30,930 --> 00:18:32,110
have TO GO

299
00:18:32,110 --> 00:18:37,160
어떻게 좀 뭔가 부족하죠 뭔가 좀 이상하죠

300
00:18:37,160 --> 00:18:38,530
여기에 이제 랭귀지 모델

301
00:18:38,530 --> 00:18:42,900
어떤 역할을 하려면 다시 이게 0호를 가져왔어

302
00:18:42,900 --> 00:18:47,450
치킨 남기지 모델 대해서 문장들을

303
00:18:47,450 --> 00:18:49,350
이렇게 업데이트 문장들이 입력을 하면 나

304
00:18:49,350 --> 00:18:52,550
그러면 그거에 대한 그 확률이 리턴이 되고

305
00:18:52,550 --> 00:18:57,100
그거를 해 줬을 경우에 그 결과는 바뀌게 돼요

306
00:18:57,100 --> 00:19:00,540
그러면 이제 아까는 거의 꼴찌였던 아이엠스 홍비가

307
00:19:00,540 --> 00:19:03,960
이번에는 가장 높은 확률로

308
00:19:03,960 --> 00:19:06,570
아 금액에서 출력 될 수 있도록 되는 거

309
00:19:06,570 --> 00:19:10,500
저렇게 3가지 같이 이렇게 워킹에서 트랜슬레이션

310
00:19:10,500 --> 00:19:15,700
CCTV 부성이 되는 거예요

311
00:19:15,700 --> 00:19:18,000
이렇게 센티는 3가지 컴포넌트

312
00:19:18,000 --> 00:19:20,320
오늘 시스템으로 구성이 되어 있는데

313
00:19:20,320 --> 00:19:22,830
근데 이거 각각에 대해서 어떻게 학습시키고

314
00:19:22,830 --> 00:19:29,400
어떻게 구해 나는지를 보도록 하겠습니다

315
00:19:29,400 --> 00:19:32,890
나 먼저 랭귀지 모델인데요

316
00:19:32,890 --> 00:19:36,750
위에처럼 세가지 문장으로 서부성당

317
00:19:36,750 --> 00:19:39,180
이제 미니 쿠퍼 수가 있다고 생각을 해 보죠

318
00:19:39,180 --> 00:19:45,400
아이엠샘 semi Korea

319
00:19:45,400 --> 00:19:50,840
I AM 이라는 워드 스폰서가 주어졌을 때

320
00:19:50,840 --> 00:19:57,170
그 다음에 나올 단어의 확률은 무엇이 될까

321
00:19:57,170 --> 00:20:02,730
확률로 표시를 하면 pof3 기분

322
00:20:02,730 --> 00:20:09,820
아이엠 이렇게 되겠죠

323
00:20:09,820 --> 00:20:13,590
확률을 구하려면 아이엠이 추천하는 김도

324
00:20:13,590 --> 00:20:19,930
아니 아이언 빈도를 IM2 출연하는 카운트

325
00:20:19,930 --> 00:20:23,580
서로 나눠 주면 돼요 2분이 2분의 1이 답인데

326
00:20:23,580 --> 00:20:29,180
이렇게 두 단어 다음에 다음 단어가 나올 조건부확률을

327
00:20:29,180 --> 00:20:30,540
트라이그램 이라고 부른다

328
00:20:30,540 --> 00:20:34,050
세 개니까 트라이 G 만약에 너라면

329
00:20:34,050 --> 00:20:43,750
이런 식으로 어 MI 다음에 확률 아 이 개수를 카운트하고

330
00:20:43,750 --> 00:20:44,740
images 를

331
00:20:44,740 --> 00:20:47,990
카운터에서 2 나눠주면 2분에서 3분의 2

332
00:20:47,990 --> 00:20:54,240
이렇게 확률을 구해 수학의 바이블 아니라고요

333
00:20:54,240 --> 00:21:00,510
그래서 랭귀지 모델은 조건 방역이 아니라

334
00:21:00,510 --> 00:21:04,220
문장 전체에 대한 확률도 알려 줄 수 있습니까

335
00:21:04,220 --> 00:21:05,870
주어진 문장이 실제로

336
00:21:05,870 --> 00:21:08,970
얼마나 있을 법한 얼마나 자연스러운 문장

337
00:21:08,970 --> 00:21:15,390
인지를 수포로 나타낼 수 있는 역할을 하는 거죠

338
00:21:15,390 --> 00:21:18,700
이제 정리를 해 보면 좀 일반화시켜 얘기했을 때

339
00:21:18,700 --> 00:21:22,720
랭귀지 모델이란 DK 의 어떤 시퀀스가 있으면

340
00:21:22,720 --> 00:21:26,200
그것보다 짧은 길이의 어 두시 콘서트에 대해서

341
00:21:26,200 --> 00:21:27,710
그 다음 번에 할 수 있는

342
00:21:27,710 --> 00:21:30,690
단어의 조건부확률을 구하는 기능도 하고

343
00:21:30,690 --> 00:21:32,320
ktx 를 갖는 모두

344
00:21:32,320 --> 00:21:35,350
시퀀스 전체에 확률을 스코어링 할 수도 있게

345
00:21:35,350 --> 00:21:38,240
해주는 역할을 하는 게 바로 랭귀지 모델이 되겠습니다

346
00:21:38,240 --> 00:21:41,680
남기지 모델을 활용한 야식은 장이 여러분들

347
00:21:41,680 --> 00:21:43,990
주변에서 많이 되고 있어요

348
00:21:43,990 --> 00:21:48,280
무슨 뭐 스피치 레크레이션 스펠링 콜렉션 이런 거 뿐만 아니라

349
00:21:48,280 --> 00:21:53,400
도움 못 빼더라도 검색엔진에서 워드 입력하면

350
00:21:53,400 --> 00:21:55,510
그 다음 거 있잖아 그거 다 나오잖아요

351
00:21:55,510 --> 00:21:59,520
그것도 랭귀지 모델 활용해서 만들어 주는 거

352
00:21:59,520 --> 00:22:02,320
그리고 여러분이 텍스트 메시지 이메일을 한다던가

353
00:22:02,320 --> 00:22:05,230
학원 뭐 그 문자 메시지 보낼 때

354
00:22:05,230 --> 00:22:07,390
내가 몇 글자 쓰시면

355
00:22:07,390 --> 00:22:12,270
내가 원하는 어떤 그런 단어가 나오잖아요

356
00:22:12,270 --> 00:22:15,980
그게 평소에 여러분들이 입력하고 있는 글자 에 대해서

357
00:22:15,980 --> 00:22:17,910
이런 모바일 G 트라이그램 을

358
00:22:17,910 --> 00:22:21,600
계속 트레이닝을 하고 있다가 학습한 결과를 여러분들에게 보여주는구나

359
00:22:21,600 --> 00:22:29,030
굉장히 많이 이용하고 사용되는 못 해 줘

360
00:22:29,030 --> 00:22:36,230
요거를 어떻게 계산을 할 수가 있을까 이

361
00:22:36,230 --> 00:22:39,160
단어의 조합이 너무 많기 때문에

362
00:22:39,160 --> 00:22:42,410
그 많은 조합에 해당하는

363
00:22:42,410 --> 00:22:45,700
그 스트링을 찾아낸다는 것은 불가능한 일이에요

364
00:22:45,700 --> 00:22:49,050
그렇기 때문에 우리 이거를 에스티메이션 해야 돼

365
00:22:49,050 --> 00:22:52,510
데스티네이션 하는 방법은 모체인 룰을 사용하고

366
00:22:52,510 --> 00:22:57,480
채널을 사용해도 여전히 먹었기 때문에 막 호법성 시험도 사용하고

367
00:22:57,480 --> 00:22:58,480
2막 수 없어 없어

368
00:22:58,480 --> 00:23:03,910
나는 미래에 어떤 스테이트는 현재의 또는 바고

369
00:23:03,910 --> 00:23:08,220
몇 개 2만 의존한다 라면 가정 이거든요

370
00:23:08,220 --> 00:23:11,290
그렇기 때문에 긴 체인에 대해서

371
00:23:11,290 --> 00:23:15,550
굉장히 짧게 줄일 수가 있게 되어 속으론 목포

372
00:23:15,550 --> 00:23:25,180
손시헌을 사용하게되면 예

373
00:23:25,180 --> 00:23:26,250
맨 밑에 그 맞고

374
00:23:26,250 --> 00:23:29,890
포스 옵션 밑에 수식 대로

375
00:23:29,890 --> 00:23:33,420
예 요걸로 스테이션 할 수 있게 되고

376
00:23:33,420 --> 00:23:40,040
가령 NE 가 되면 요긴 조건에 대한 아이 번째 워드의 조건방

377
00:23:40,040 --> 00:23:43,470
누른 그냥 이전 단어의 조건으로

378
00:23:43,470 --> 00:23:45,360
건 환율로 계산할 수가 있게 되어

379
00:23:45,360 --> 00:23:53,670
이게 이제 아까 오셨던

380
00:23:53,670 --> 00:23:56,760
그래서 바이그램 을 제공할 수 있게 했으니까

381
00:23:56,760 --> 00:23:58,410
조금 아까 봤던 그 미니쿠퍼

382
00:23:58,410 --> 00:24:02,960
스웨덴에서 전체 시퀀스에 대해 iamsam 일하는 거

383
00:24:02,960 --> 00:24:09,550
flower 하려면 아이유 확률 M 기분 아이 확률

384
00:24:09,550 --> 00:24:11,830
쌤 기브넨 확률을 해주면 됩니다

385
00:24:11,830 --> 00:24:14,080
그럼 이번에 체육에서 아니 돼요

386
00:24:14,080 --> 00:24:17,810
근데 여기에 노멀라이제이션 길게 설명 안 할 텐데

387
00:24:17,810 --> 00:24:23,580
그 확률을 고르게 공포 시키기 위해서 타투 하고

388
00:24:23,580 --> 00:24:26,740
문장에 시작과 끝을 표시하는 요

389
00:24:26,740 --> 00:24:29,820
에스라는 태그를 사용을 해 가지고

390
00:24:29,820 --> 00:24:35,930
앞에 앞에 거를 조금 확률로 시작을 끝에도

391
00:24:35,930 --> 00:24:39,430
그 마지막 단어에 대한 &

392
00:24:39,430 --> 00:24:40,270
조건부 확률 로

393
00:24:40,270 --> 00:24:44,930
끝나도록 요런 식으로 확률구하기 됩니다

394
00:24:44,930 --> 00:24:46,730
그렇게 하면 있는 것처럼

395
00:24:46,730 --> 00:24:48,730
스타트 I AM sam

396
00:24:48,730 --> 00:24:54,110
and 에 대한 확률은 또 다른 값을 가지고 해 줘

397
00:24:54,110 --> 00:24:55,300
이렇게 하는 게

398
00:24:55,300 --> 00:25:02,020
제 N G 모델 구하는 방법이 되겠어요

399
00:25:02,020 --> 00:25:04,410
약간의 코드를 넣어봤는데

400
00:25:04,410 --> 00:25:10,670
나중에 시간 되시면 한번 읽어 보시면 되겠고요

401
00:25:10,670 --> 00:25:12,630
똑같은 코퍼스 가지고

402
00:25:12,630 --> 00:25:18,960
바이그램 남기지 모델 만드는 거에 대한 코드입니다

403
00:25:18,960 --> 00:25:20,710
그다음에 이제 트랜슬레이션 모델인데

404
00:25:20,710 --> 00:25:22,730
트랜슬레이션 모델이라는 거는

405
00:25:22,730 --> 00:25:28,730
주어진 영어문장에 대해서 가장 가까운 프렌치 문장을

406
00:25:28,730 --> 00:25:31,560
혹은 문장을 얻어낸 거예요

407
00:25:31,560 --> 00:25:33,930
끄려면 어떻게 계산을 해야 겠어요

408
00:25:33,930 --> 00:25:40,780
어떤 단어가 단어의 얼마나 잘 매칭이 되는지를

409
00:25:40,780 --> 00:25:43,790
우리가 계산을 해야 되겠죠

410
00:25:43,790 --> 00:25:46,720
근데 아까 약간 예를 들었던 거

411
00:25:46,720 --> 00:25:53,930
많이 하나 하는 거는 모닝 일하고 매칭이 되었는지

412
00:25:53,930 --> 00:25:57,820
혹은 통화를 하고 며칠 되었는지

413
00:25:57,820 --> 00:26:01,220
요런 거를 계산을 하는 조건부 확률이 되겠어

414
00:26:01,220 --> 00:26:05,340
조건부확률의 바로 트랜슬레이션 모델이 되겠습니다

415
00:26:05,340 --> 00:26:10,320
근데 이거 에 문제가 뭐냐면 언어마다 어순이 달라요

416
00:26:10,320 --> 00:26:13,760
그래서 뭐 어떤 거 가지고

417
00:26:13,760 --> 00:26:18,730
이제 여기서 예시를 등본은 영어에서 엔더 프로그램 has

418
00:26:18,730 --> 00:26:21,070
been implemented 라는 문장은

419
00:26:21,070 --> 00:26:23,230
여섯 개의 단어로 이루어져 있죠

420
00:26:23,230 --> 00:26:26,890
프랑스 일정 좋겠습니까

421
00:26:26,890 --> 00:26:31,360
7단으로 이루어진 문장으로 매칭이 되는데

422
00:26:31,360 --> 00:26:36,060
이거에 얼라이먼트는 순서가 다 각자 다릅니다

423
00:26:36,060 --> 00:26:39,910
이거 요거는 이제 해당되는 방도 없고

424
00:26:39,910 --> 00:26:43,870
개 같은 경우에는 세 개 다 너 왜 칠해져

425
00:26:43,870 --> 00:26:45,370
그리고 어떤 경우에는 요게

426
00:26:45,370 --> 00:26:49,640
이제 한글과 우리말과 영화 같은 경우에는

427
00:26:49,640 --> 00:26:53,010
여기 순서가 엑스자로 엇갈리기도 해요

428
00:26:53,010 --> 00:26:55,600
그러면 우리가 트랜슬레이션 모드를 구할 수가 없죠

429
00:26:55,600 --> 00:26:58,010
일단 얼라이먼트 부터 워드 워드

430
00:26:58,010 --> 00:27:01,840
가네 얼라이먼트 부터 정확하게 얻어내야 하지만

431
00:27:01,840 --> 00:27:06,690
그 다음에 이제 트랜슬레이션 모델을 구하기 위해서

432
00:27:06,690 --> 00:27:09,730
매칭되는 단어들을 살 수 있으니까요

433
00:27:09,730 --> 00:27:13,430
그래서 트랜스레이션 모델 만들기 위해서는

434
00:27:13,430 --> 00:27:19,520
모두에 대한 얼라이먼트 문제부터 풀어야 됩니다

435
00:27:19,520 --> 00:27:21,650
왜 그 머신 트랜스레이션 비싸

436
00:27:21,650 --> 00:27:24,350
아니면 이렇게 얼라이먼트 같은 거를

437
00:27:24,350 --> 00:27:26,850
누군가 레이블링을 해야 돼요

438
00:27:26,850 --> 00:27:30,950
그럼 그 사람들이 돈을 주고서 막 수십만개의 문자

439
00:27:30,950 --> 00:27:33,550
이런 거를 레이블링 하라고 하면

440
00:27:33,550 --> 00:27:35,840
너무 비싼 연구가 되는 거죠

441
00:27:35,840 --> 00:27:37,090
그래서 사람들이 생각을 했어요

442
00:27:37,090 --> 00:27:40,030
아 이거를 어느 수퍼바이저 풀자

443
00:27:40,030 --> 00:27:44,930
사용되는게 EM 알고리즘 인데

444
00:27:44,930 --> 00:27:47,140
시간상 좀 여기는 뛰어 놓을게요

445
00:27:47,140 --> 00:27:55,460
EM 알고리즘 을 통해서 아 그러니까 이런 거죠

446
00:27:55,460 --> 00:27:57,700
우리가 얼라인먼트를 알고 있어요

447
00:27:57,700 --> 00:28:00,800
그러면 트랜스레이션 파라미터를 구할 수가 있죠

448
00:28:00,800 --> 00:28:04,900
반대로 트랜슬레이션 파라미터로 알고 있으면

449
00:28:04,900 --> 00:28:08,000
어떤 단어가 다른 단어에 어떻게 매칭 되는 줄 알기 때문에

450
00:28:08,000 --> 00:28:09,460
얼라이먼트도 갈 수 있어요

451
00:28:09,460 --> 00:28:12,860
이거는 이제 가려고 이제 치킨 에그 게임 같은 거예요

452
00:28:12,860 --> 00:28:16,860
어떤 게 먼저 선호관계 있다고 할 수 없기 때문에

453
00:28:16,860 --> 00:28:18,430
익스펙테이션 값을 받고

454
00:28:18,430 --> 00:28:21,220
맥시마 이게 이상한 거를 반복함으로써

455
00:28:21,220 --> 00:28:27,650
가장 필요한 얼라인먼트를 풀어내는 거죠

456
00:28:27,650 --> 00:28:34,590
그리고 그거를 중으로 해서 트랜스레이션 모델을 만들어 내겠습니다

457
00:28:34,590 --> 00:28:35,740
호 내용들이 거야

458
00:28:35,740 --> 00:28:38,510
그렇게 처음에는 어떤 단어가 어떤 나 너하고

459
00:28:38,510 --> 00:28:40,380
매칭이 되는 지 모르지만

460
00:28:40,380 --> 00:28:42,000
2M 알고리즘을 계속

461
00:28:42,000 --> 00:28:44,990
이터레이션 돌면서 점점 굵어지는 선들이 있죠

462
00:28:44,990 --> 00:28:46,510
얘네들이 요거 하고

463
00:28:46,510 --> 00:28:49,300
며칠 되겠구나 해서 얼라이먼트를 알게 되고

464
00:28:49,300 --> 00:28:50,870
이렇게 얼라이먼트를 알게 되면

465
00:28:50,870 --> 00:28:55,460
밑에처럼 해당되는 단어끼리 에 트랜지션 10시간이고

466
00:28:55,460 --> 00:28:58,560
트랜스레이션 profile for 수가 있기 때문에

467
00:28:58,560 --> 00:29:06,010
그거를 집합해서 플레이스테이션 모델을 만들 수가 있게 되는

468
00:29:06,010 --> 00:29:07,400
거예요

469
00:29:07,400 --> 00:29:11,140
요코는 그렇게 하는 알고리즘이 여러 가지가 있어요

470
00:29:11,140 --> 00:29:13,860
IBM 모델 1에서 5까지 있고

471
00:29:13,860 --> 00:29:17,420
그 순간에 이체메모 일하는 것도 있고

472
00:29:17,420 --> 00:29:19,690
다른 모델도 몇 가지 더 있는데

473
00:29:19,690 --> 00:29:27,950
가장 원시적인 모델 코드 조금 줄여 가지고 이렇게 적어 놨으니까

474
00:29:27,950 --> 00:29:39,390
혹시 나중에 시간이 되시면 보시고요

475
00:29:39,390 --> 00:29:42,020
마지막으로 뒤코 던데요

476
00:29:42,020 --> 00:29:47,250
디코딩은 검색입니다 랭귀지 모델과 트랜스레이션 모델의 곱이

477
00:29:47,250 --> 00:29:50,780
가장 큰 문장을 찾아내는 거죠

478
00:29:50,780 --> 00:29:56,160
아 그 밑으로 근데 사실 디코딩 원 엠피커플 문제예요

479
00:29:56,160 --> 00:30:01,830
이거는 트레블링 세일즈맨 pro 볼 수가 있는데

480
00:30:01,830 --> 00:30:08,860
트랜슬레이션 모델을 통해서 얻어낸 그 4번은 확인

481
00:30:08,860 --> 00:30:14,360
언어의 단어들을 그래프의 로드라고 보고 버텍스 라고 보고

482
00:30:14,360 --> 00:30:17,440
그 사이에 찌를 랭귀지 모델

483
00:30:17,440 --> 00:30:21,020
밝은면퀴즈 모델의 웨이트 거라고 생각이 됩니다

484
00:30:21,020 --> 00:30:26,790
그랬을 경우에 가장 좋은 조합으로 한 줄 국기를 하는 거예요

485
00:30:26,790 --> 00:30:32,790
뭐 여기는 이제 이렇게 한 줄로 짝

486
00:30:32,790 --> 00:30:38,460
닦은 거 패스를 찾는 것과 같은 문제거든요

487
00:30:38,460 --> 00:30:40,640
그래서 굉장히 어려워요

488
00:30:40,640 --> 00:30:47,790
요거 문제를 풀기 위해서 이거는 만약에 러닝모델 러닝

489
00:30:47,790 --> 00:30:50,880
트레이닝 단계는 좀 시간이 오래 걸려도 괜찮아요

490
00:30:50,880 --> 00:30:53,840
근데 이거 디코딩은 인포를 살아 남기 거군요

491
00:30:53,840 --> 00:30:56,340
감사합니다

492
00:30:56,340 --> 00:30:59,670
이렇게 입력을 하면 아홉시 바로 나와야 되는데

493
00:30:59,670 --> 00:31:02,230
그렇지 않고 되게 오래 걸린다는 성적이 안 쓰겠죠

494
00:31:02,230 --> 00:31:06,200
그래서 나는 굉장히 이제 속도에 민감한 문제기 때문에

495
00:31:06,200 --> 00:31:08,230
진짜 이제 사용할 수 있는 수를 찾아줘 따는 거

496
00:31:08,230 --> 00:31:10,140
다이나믹 프로그래밍 하는 게 있고요

497
00:31:10,140 --> 00:31:12,350
많이들 해 보셨겠지만

498
00:31:12,350 --> 00:31:14,620
토이콤플렉스 티를 익스포넨셜 해서

499
00:31:14,620 --> 00:31:17,310
폴리노미얼 줄여주는 역할을 하게 됩니다

500
00:31:17,310 --> 00:31:20,270
이전에 풀었던 프로 볼륨을 저장해 놨다가

501
00:31:20,270 --> 00:31:22,750
나중에 이제 다시 풀지 않도록 하는

502
00:31:22,750 --> 00:31:26,610
그런 그 프로그램이 기법이 비터비알고리즘

503
00:31:26,610 --> 00:31:28,220
일하는 게 있는데

504
00:31:28,220 --> 00:31:29,640
얘는 이제 다익스트라 알고리즘

505
00:31:29,640 --> 00:31:31,790
눈처럼 패스트패스를 찾는 거예요

506
00:31:31,790 --> 00:31:37,280
대신에 그 스케이트 개수가 고정이 되어 있어야 되고요

507
00:31:37,280 --> 00:31:38,570
그것과 유사한 게

508
00:31:38,570 --> 00:31:43,490
이제 빔서치 또는 디스텍 디코딩하는 방법이 있는데

509
00:31:43,490 --> 00:31:45,450
아 btob 있었지

510
00:31:45,450 --> 00:31:49,870
일을 하면서 전부 다 리스트업 해 가지고

511
00:31:49,870 --> 00:31:53,580
이제 그 트리를 막 해서 층을 하는 게 아니라

512
00:31:53,580 --> 00:31:56,320
베스트엠 게 캔디데이트 모아가지고

513
00:31:56,320 --> 00:32:00,160
서칭을 때문에 속도가 훨씬 빠른 입니다

514
00:32:00,160 --> 00:32:02,400
저는 빔서치 스택

515
00:32:02,400 --> 00:32:06,460
디코딩을 구현해 가지고 사용을 했고요

516
00:32:06,460 --> 00:32:08,660
이건재 스테끼 코디인데

517
00:32:08,660 --> 00:32:11,750
여기 보시면 스택 사이즈를 조절함으로써

518
00:32:11,750 --> 00:32:13,880
여기 스택 사이즈를 수용함으로써

519
00:32:13,880 --> 00:32:17,060
내가 담는 캔디데이트 숫자를 탑앤

520
00:32:17,060 --> 00:32:19,650
게로 조정을 한번 와서

521
00:32:19,650 --> 00:32:24,350
이제 서칭 속도를 빠르게 할 수가 있어요

522
00:32:24,350 --> 00:32:28,770
나 이제 마지막으로 음

523
00:32:28,770 --> 00:32:31,150
코리아나 해 줘 제가 이렇게 부쳤습니다

524
00:32:31,150 --> 00:32:37,170
SMT 트랜스레이터 푸 오겠습니다

525
00:32:37,170 --> 00:32:39,190
이건 뭐 한글 다 아시니까

526
00:32:39,190 --> 00:32:44,830
한글 특성에 대한 거는 이제 생략을 하고요

527
00:32:44,830 --> 00:32:47,160
로마니제이션 이라는 게 있어요

528
00:32:47,160 --> 00:32:49,780
이게 뭐냐면 어떤 어떤 언어를

529
00:32:49,780 --> 00:32:53,730
로마는 그 표기로 바꿔서 쓰는 거예요

530
00:32:53,730 --> 00:32:59,990
가장 뒤에 보시는 땐 나를 알파벳으로 써 놓은 거를

531
00:32:59,990 --> 00:33:04,840
로마니제이션 반대로 제가 아까

532
00:33:04,840 --> 00:33:07,480
그거 해 가지고 보여드렸던 거는

533
00:33:07,480 --> 00:33:08,780
로마니제이션 되어 있는 거 를

534
00:33:08,780 --> 00:33:12,030
우리말로 우리 라이팅 스타 슈팅 시스템으로 다 있었으니

535
00:33:12,030 --> 00:33:16,870
바꿨으니까 이거 빼고 로마니제이션 이겠죠

536
00:33:16,870 --> 00:33:17,940
그래서 -

537
00:33:17,940 --> 00:33:23,470
코리안 색으로만 에디션은 로 만두 korean tradition

538
00:33:23,470 --> 00:33:25,370
한국 같은 겁니다

539
00:33:25,370 --> 00:33:28,380
이게 약간 제의색깔 있어 가지고

540
00:33:28,380 --> 00:33:29,780
트랜스뮤테이션 이라고 부르면

541
00:33:29,780 --> 00:33:32,980
반드시 앞에 로 만두 코리아는 붙여야 되고

542
00:33:32,980 --> 00:33:34,890
색으로만 에디션이라고 하려면

543
00:33:34,890 --> 00:33:36,610
그 빼게 대상이 코리안 일하는 거야

544
00:33:36,610 --> 00:33:37,570
꼭 부쳐 줘야 되거든요

545
00:33:37,570 --> 00:33:43,210
그래가지고 헷갈리지 않게 짚고 넘어갈 거야

546
00:33:43,210 --> 00:33:50,870
자유 시스템의 목적은 그 로만 캐릭터로 발음

547
00:33:50,870 --> 00:33:57,240
나는 대로 사용된 모드를 한글 시스템으로 다시 써 주는 근데

548
00:33:57,240 --> 00:34:06,300
이게 살펴보면 그 얼라이먼트 문제 하고 똑같아요

549
00:34:06,300 --> 00:34:10,070
하령 한글이 라고 쓰면 한 그릇

550
00:34:10,070 --> 00:34:12,030
이라고 영어로 여러 가지 수가 있어요

551
00:34:12,030 --> 00:34:20,660
hangul hau GL.H NG eul hangul

552
00:34:20,660 --> 00:34:22,980
이렇게 해도 다 한글이라고 읽어 줘야 되기 때문에

553
00:34:22,980 --> 00:34:25,500
여러 가지 경우가 경우의수가 생겨요

554
00:34:25,500 --> 00:34:27,580
그러니까 누굴 베이스로 코드 가려면

555
00:34:27,580 --> 00:34:29,000
너무 많은 눈물을 코딩

556
00:34:29,000 --> 00:34:30,480
해 줘야 되기 때문에 를

557
00:34:30,480 --> 00:34:32,460
베이스로 만들기 어려운 이유가 바로 이겁니다

558
00:34:32,460 --> 00:34:33,910
그래서 아 이거는 뭐

559
00:34:33,910 --> 00:34:37,870
러닝으로 해야겠구나 라고 생각을 했던 이유가 되겠고요

560
00:34:37,870 --> 00:34:45,310
그다음에 이제 세그멘테이션 있어 밑에 칸막이 썼을 때

561
00:34:45,310 --> 00:34:47,470
우리 누나 이걸 아니까

562
00:34:47,470 --> 00:34:50,800
우리는 그 냄비 중 오늘이 안에 내장이 되어 있기 때문에

563
00:34:50,800 --> 00:34:55,350
이거를 칸 요렇게 얼라인먼트를 하는데

564
00:34:55,350 --> 00:34:58,750
외국 사람들이 읽을때는 칸막이

565
00:34:58,750 --> 00:35:00,590
이렇게 온라인 못 할 수 있겠죠

566
00:35:00,590 --> 00:35:01,920
아 이거는 못 해 라고

567
00:35:01,920 --> 00:35:04,840
얼라이먼트 모델이 우리 애기 때문에

568
00:35:04,840 --> 00:35:09,000
그 음조를 세그먼테이션 할 수 있는 거거든요

569
00:35:09,000 --> 00:35:12,870
아 그러면 이거를 원투맨 열라 이마트

570
00:35:12,870 --> 00:35:21,090
저 트랜슬레이션 단어에 대한 랭귀지 모델링을 통해서 프로보

571
00:35:21,090 --> 00:35:27,070
그렇게 해서 만들어 코리아나 해 주고요

572
00:35:27,070 --> 00:35:32,980
처음에는 이제 캐릭터를 자음과 모음을 둘리 해가지고

573
00:35:32,980 --> 00:35:35,490
영어 로만 캐릭터 하고

574
00:35:35,490 --> 00:35:36,730
며칠 시킨 다음에 다시

575
00:35:36,730 --> 00:35:38,580
재조합을 하는 방법을 쓰려고 했는데

576
00:35:38,580 --> 00:35:43,080
문제점이 뜰이 좀 있어 가지고 로만 캐릭터 하고

577
00:35:43,080 --> 00:35:46,340
우리 음절 자음 모음

578
00:35:46,340 --> 00:35:51,210
받침이 합쳐진 음절의 덩어리 세그먼트 하고

579
00:35:51,210 --> 00:35:53,490
얼라이먼트 하는 방법으로

580
00:35:53,490 --> 00:35:56,990
다시 바꿔서 트레이닝을 했어요

581
00:35:56,990 --> 00:36:02,330
그래서 디코딩 뭐 아까 말씀드린 대로 아

582
00:36:02,330 --> 00:36:11,410
그 맥스를 택배 있어 뒤 코딩으로 구현을 했고요

583
00:36:11,410 --> 00:36:13,350
코리아나 의자는 몇 년 전에 만들었습니다

584
00:36:13,350 --> 00:36:14,810
몇 년 된 거예요

585
00:36:14,810 --> 00:36:20,920
근데 당시에는 틀어 놓고 버스가 필요하다고 했잖아요

586
00:36:20,920 --> 00:36:25,220
우리말을 발음 나는 대로 영어로 써 있는 걸 어디서 보셨어요

587
00:36:25,220 --> 00:36:27,000
9월 수가 없었어요

588
00:36:27,000 --> 00:36:30,980
그래가지고 되게 제한된 냥이코패스 밖에 없었는데

589
00:36:30,980 --> 00:36:35,160
얼마 전에 우연히 그 케이팝 팬들이 케이팝

590
00:36:35,160 --> 00:36:38,110
한글 가사를 영어 캐릭터로

591
00:36:38,110 --> 00:36:42,200
로마니제이션 하는 걸 발견하려고 그거 전부 다 큰 올리겠습니다

592
00:36:42,200 --> 00:36:44,540
그래서 아 다시 이거 해 보자 해 가지고

593
00:36:44,540 --> 00:36:46,820
여기까지 오게 된 거예요

594
00:36:46,820 --> 00:36:51,940
뭐 뭐 뭐 무슨 많이 사용하시는 라이브로 사용해 가지고

595
00:36:51,940 --> 00:36:59,760
12만 2천 계곡에서 가사 150만 원 요조를 취했고

596
00:36:59,760 --> 00:37:03,390
그 중에 모르는 이렇게 모르는 일이라고

597
00:37:03,390 --> 00:37:04,950
바이 텍스트 바이워드

598
00:37:04,950 --> 00:37:07,720
페어를 190만 개월 수가 있었어요

599
00:37:07,720 --> 00:37:09,380
그 중에서 유니크 한 곡만 뽑아 내니까

600
00:37:09,380 --> 00:37:16,380
12만 개의 파이텍스 로드 수고했습니다 있었습니다

601
00:37:16,380 --> 00:37:20,380
요거를 아까처럼 트랜슬레이션 못 하고

602
00:37:20,380 --> 00:37:22,990
또 한글 단어 에 대해서는 남기지 모델 트레이닝 하고

603
00:37:22,990 --> 00:37:23,940
두 개 급해 가지고

604
00:37:23,940 --> 00:37:28,970
아그네스 쉬워서 출력물을 보이는 게 바로 지금

605
00:37:28,970 --> 00:37:31,880
저희도 쿠앱 에다가 코팅을 해 놨는데

606
00:37:31,880 --> 00:37:33,180
이거 제가 돈 안 내고

607
00:37:33,180 --> 00:37:34,790
그냥 싱글 프로세스 1

608
00:37:34,790 --> 00:37:39,600
태어났기 때문에 여러분들이 많이 사용해주시기 덥겠지만

609
00:37:39,600 --> 00:37:42,300
많이 접속을 죽을지도 몰라요

610
00:37:42,300 --> 00:37:45,970
당분간 떼어 놓을 거니까 한번 갖고 놀아 보시고요

611
00:37:45,970 --> 00:37:52,090
발표 들어주셔서 감사합니다
