1
00:00:01,090 --> 00:00:03,080
안녕하세요 온라인 뉴스

2
00:00:03,080 --> 00:00:05,460
댓글은 정말 사람들의 목소리일까

3
00:00:05,460 --> 00:00:07,680
파트 2 발표를 진행할 2진법이다

4
00:00:07,680 --> 00:00:14,870
반갑습니다 공격적으로 발표를 시작하기 전에

5
00:00:14,870 --> 00:00:17,150
장염과 같은 걸 한번 진행하고자 해요

6
00:00:17,150 --> 00:00:19,790
여러분께 작은 부탁 하나를 드릴텐데요

7
00:00:19,790 --> 00:00:21,370
여기 오신 모든 분들

8
00:00:21,370 --> 00:00:26,530
이렇게 한 손 한번 이렇게 모두손을들어 주시겠어요

9
00:00:26,530 --> 00:00:29,750
네 감사합니다 차 여기 내리시면 돼요

10
00:00:29,750 --> 00:00:31,460
저 계속 손들어 지고 계셔야 되는데

11
00:00:31,460 --> 00:00:34,770
여기서 나는 온라인으로 뉴스를 보지 않는다

12
00:00:34,770 --> 00:00:37,030
손 내려 주세요 네

13
00:00:37,030 --> 00:00:39,330
많은 분들에게 손에 들어주고 계시는데요

14
00:00:39,330 --> 00:00:42,520
두 번째로 이번에는 나는 온라인 뉴스는 보는데

15
00:00:42,520 --> 00:00:43,930
댓글은 고지 않는다

16
00:00:43,930 --> 00:00:46,660
하시는 분들 손 내려 주세요

17
00:00:46,660 --> 00:00:50,180
네 아직도 굉장히 많은 분들이 손을 들어주고 계세요

18
00:00:50,180 --> 00:00:52,840
주위를 둘러보시면 굉장히 많은 분들이 손에 들고

19
00:00:52,840 --> 00:00:53,950
보실 수 있을 텐데요

20
00:00:53,950 --> 00:00:55,640
네 저도 여러분과 같이

21
00:00:55,640 --> 00:00:59,140
사실 계속 손에 들고 있는 우주소녀 내려 주셔도 됩니다

22
00:00:59,140 --> 00:01:04,740
감사합니다 우리 이문정 굉장히 익숙하실 거예요

23
00:01:04,740 --> 00:01:09,180
대한민국은 민주공화국이다 라는 걸로 시작하는 대한민국의 헌법

24
00:01:09,180 --> 00:01:10,880
제 2차 부분인데요

25
00:01:10,880 --> 00:01:13,010
헌법에 가장 처음에 나오기도 하고

26
00:01:13,010 --> 00:01:15,930
우리나라의 김가네 가장 잘 설명하는

27
00:01:15,930 --> 00:01:17,600
문장 있기도 합니다

28
00:01:17,600 --> 00:01:21,760
그런데 여기에서 한 주 미드 뉴스룸 에는 이런 말이 나와요

29
00:01:21,760 --> 00:01:24,770
theft auto import name IS IT

30
00:01:24,770 --> 00:01:26,620
now

31
00:01:26,620 --> 00:01:28,350
연락처 이란 말이 나오는데

32
00:01:28,350 --> 00:01:31,850
이게 한국어로는 민주주의에서 가장 중요한 거는

33
00:01:31,850 --> 00:01:36,270
정보를 잘 전달 받은 유권자다 라는 뜻이에요

34
00:01:36,270 --> 00:01:40,240
근데 그 유권자는 바로 우리 민족의 가장 중요한 건

35
00:01:40,240 --> 00:01:42,450
유권자가 정보를 잘 전달 받는 건데

36
00:01:42,450 --> 00:01:45,190
그러면 우리는 정보를 어디서 갖고 있냐

37
00:01:45,190 --> 00:01:47,130
라는 생각을 해보는 거지

38
00:01:47,130 --> 00:01:49,630
우리는 온라인에서 기사를 보고

39
00:01:49,630 --> 00:01:52,960
그 기사를 비판적으로 바라보는 갖고 있어요

40
00:01:52,960 --> 00:01:56,130
계속 이상하게 자체보다는 댓글이

41
00:01:56,130 --> 00:01:57,820
그래도 사람들이 쓰는 거니까

42
00:01:57,820 --> 00:01:59,210
좀 더 때 묻지 않고

43
00:01:59,210 --> 00:02:01,390
그리고 사람들이 쓰는 그 소스를 통해서

44
00:02:01,390 --> 00:02:04,860
새로운 정보를 원천으로서 동작을 하기도 하는데요

45
00:02:04,860 --> 00:02:07,250
최근에 우리가 이 문장

46
00:02:07,250 --> 00:02:10,690
에 대해 물음표를 내리기 시작했어요

47
00:02:10,690 --> 00:02:12,140
정말 댓글이 덜 때

48
00:02:12,140 --> 00:02:15,550
묻은 새로 정보의 원천으로서 쓸모가 있느냐

49
00:02:15,550 --> 00:02:17,540
라는 질문이 봐봐

50
00:02:17,540 --> 00:02:20,260
이런 사회적 상황을 보여주는 게 네이버

51
00:02:20,260 --> 00:02:21,430
웹툰에서 등장을 해요

52
00:02:21,430 --> 00:02:25,370
이게 작년 8권에서 인트로 때 사용했던 장면이 계단 네이버랩

53
00:02:25,370 --> 00:02:27,320
월요웹툰 꿈의 기업 중에서

54
00:02:27,320 --> 00:02:30,110
어떤 기업가가 다른 기업 인수 하려고 하는데

55
00:02:30,110 --> 00:02:31,570
부정적인 기사가 올라오니까

56
00:02:31,570 --> 00:02:32,810
그거를 대처를 할 때

57
00:02:32,810 --> 00:02:35,690
기사를 내리라고 언론사의 압력을 넣는 대신

58
00:02:35,690 --> 00:02:37,590
이런 말을 합니다

59
00:02:37,590 --> 00:02:40,400
시민들은 본문보다 댓글에서 믿는 편이니까

60
00:02:40,400 --> 00:02:43,390
댓글을 조작하다 라는 말이 나와요

61
00:02:43,390 --> 00:02:47,100
이런 것처럼 우리가 본문보다 댓글에서 믿고 있는

62
00:02:47,100 --> 00:02:50,240
그런 게 좀 더 사회적으로도 이슈가 되고 있지 않나

63
00:02:50,240 --> 00:02:53,220
댓글이 뭔가 정말 제대로 동작을 하니

64
00:02:53,220 --> 00:02:54,610
라는 의문이 가자

65
00:02:54,610 --> 00:02:58,300
그래서 우리가 보낸 인터넷에서의 그런 댓글들은 정말

66
00:02:58,300 --> 00:03:01,280
우리의 세상을 제대로 반영을 해 주고 있냐

67
00:03:01,280 --> 00:03:04,260
라는 게 가장 큰 질문입니다

68
00:03:04,260 --> 00:03:07,650
본격적으로 이번에도 간단하게 뭐라도 할 텐데요

69
00:03:07,650 --> 00:03:10,620
정치사회적인 내용이 약간 들어가 있을 수 있는데

70
00:03:10,620 --> 00:03:13,780
이번 내용은 정치사회적 내용을 바로 보자가 아니라

71
00:03:13,780 --> 00:03:16,650
이런 사회적인 데이터를 분석을 할 때

72
00:03:16,650 --> 00:03:18,560
어떤 식으로 접근을 해야 되는지

73
00:03:18,560 --> 00:03:22,050
그런 기술적인 접근방법에 대해서 이야기를 하는 거기 때문에

74
00:03:22,050 --> 00:03:23,840
제시된 내용이 발표

75
00:03:23,840 --> 00:03:25,840
그리고 팔콘의 입장과 대외정책

76
00:03:25,840 --> 00:03:30,220
반영하지 않음을 미리 알려 드립니다

77
00:03:30,220 --> 00:03:34,550
자 그러면은 우리가 시작을 하면서 소셜데이터 소셜댓글

78
00:03:34,550 --> 00:03:35,500
이런 얘기를 하는데

79
00:03:35,500 --> 00:03:36,910
이걸 왜 봐야 되는 야

80
00:03:36,910 --> 00:03:39,980
라는 질문에 대해서 먼저 답을 해야 돼요

81
00:03:39,980 --> 00:03:42,980
소셜 데이터를 본다는 거는 이렇게 생각을 해요

82
00:03:42,980 --> 00:03:47,720
우리 사회에서 나타나는 어떤 여러 현상들을 설명하는 거야

83
00:03:47,720 --> 00:03:49,390
수없이 루머들이 떠들고

84
00:03:49,390 --> 00:03:51,460
거기서 어떤 게 세팅

85
00:03:51,460 --> 00:03:54,640
얼마나 폴리티컬 바이어들이 나타나고 있는데

86
00:03:54,640 --> 00:03:57,840
그건 우리가 보낸 댓글들이 표본 추출 넣었어

87
00:03:57,840 --> 00:04:00,310
정말 우리 사회를 대표를 하고 있는지

88
00:04:00,310 --> 00:04:02,780
그런 거에 대해서 질문을 하는 거다

89
00:04:02,780 --> 00:04:05,060
한편 소셜 데이터를 결석하는 걸 통해서

90
00:04:05,060 --> 00:04:06,010
우리가 없는 거네

91
00:04:06,010 --> 00:04:07,290
우리 회사 신에 대해서

92
00:04:07,290 --> 00:04:09,250
우리 사회에 대해서 이해를 높이고

93
00:04:09,250 --> 00:04:11,710
우리 사회가 보다 성숙할 수 있도록 하는

94
00:04:11,710 --> 00:04:15,040
그런 발판으로 해주는 역할을 한다고 생각을 합니다

95
00:04:15,040 --> 00:04:16,310
가장 중요한 거네

96
00:04:16,310 --> 00:04:18,100
우리가 사용하는 우리 개발자 아닐까요

97
00:04:18,100 --> 00:04:18,850
우리가 사용하는 이런

98
00:04:18,850 --> 00:04:22,520
개발기술의 우리 사회에 기여할 수 있는 부분이라고

99
00:04:22,520 --> 00:04:24,770
생각을 합니다

100
00:04:24,770 --> 00:04:26,250
제가 보는 데이터 분석

101
00:04:26,250 --> 00:04:28,440
사회를 바라보는 또 하나의 눈이에요

102
00:04:28,440 --> 00:04:31,420
우리가 우리 눈으로만 보낸 게 아니라 훨씬 더 높고

103
00:04:31,420 --> 00:04:35,520
다양한 면에서 접근에 할 수 있다는 뜻이야

104
00:04:35,520 --> 00:04:39,820
최근에 제가 이 두 문장의 굉장히 인상 깊게 듣고 있어요

105
00:04:39,820 --> 00:04:41,630
100개는 사랑의 볼 수 있다

106
00:04:41,630 --> 00:04:44,040
하지만 100만 개는 사람이 직접 볼 수 없다

107
00:04:44,040 --> 00:04:48,060
그리고 또 다른 말은 사람이 할 수 있는 길이

108
00:04:48,060 --> 00:04:51,460
사람이 할 수 있는 일이면 이제 기계도 할 수 있다

109
00:04:51,460 --> 00:04:54,680
물론 데이터가 충분히 있을 때 한 정이수 아니야

110
00:04:54,680 --> 00:04:56,710
그래서 이제 머신러닝

111
00:04:56,710 --> 00:04:58,850
그리고 이런 게 나오기 시작하면서

112
00:04:58,850 --> 00:05:01,610
휴먼스코리아 케이스가 나오기도 하고

113
00:05:01,610 --> 00:05:04,350
데이터만 충분히 잘 되어 있다면

114
00:05:04,350 --> 00:05:06,160
어떤 일을 할 때 사람보다

115
00:05:06,160 --> 00:05:09,360
혹은 사람만큼 잘할 수 있다 라는 얘기인 거 사

116
00:05:09,360 --> 00:05:13,270
그래서 우리는 두 가지 접근방법에 볼 수 있습니다

117
00:05:13,270 --> 00:05:16,350
만약에 사람이 볼 수 있는 일이 다 하면

118
00:05:16,350 --> 00:05:20,290
보다 자동으로 사람이 일을 줄여 줄여 주는 방식으로 접근하거나

119
00:05:20,290 --> 00:05:21,690
혹은 사람이 볼 수 없는

120
00:05:21,690 --> 00:05:24,200
대규모 스케일이 라면은 사람이 볼 수 없었던

121
00:05:24,200 --> 00:05:26,580
새로운 것에 발견할 수 있도록 해 주거나

122
00:05:26,580 --> 00:05:32,150
라는 두 가지 접근방법이 그래서 제가 선택한 데이터는 뉴스

123
00:05:32,150 --> 00:05:36,820
그리고 댓글 이렇게 두 가지 데이터야 생각보다 뉴스

124
00:05:36,820 --> 00:05:38,450
그리고 댓글에서는 굉장히

125
00:05:38,450 --> 00:05:40,310
다양한 정보를 얻을 수 있는데요

126
00:05:40,310 --> 00:05:43,580
기산리 1시로 도면은 이기사의 부분인데요

127
00:05:43,580 --> 00:05:48,470
얼른 기사제목 기사가 작성된 시각을 비롯해서

128
00:05:48,470 --> 00:05:50,940
그 기사 아래 있는 독자들의 감성

129
00:05:50,940 --> 00:05:54,410
그리고 추천수 이런 것도 볼 수 있고요

130
00:05:54,410 --> 00:05:57,620
하면 댓글에 경우에 좀 더 다양하게 데이터가 있는데

131
00:05:57,620 --> 00:06:02,150
댓글 했으니 댓글이 누가 작성 작성자 댓글을 작성한 시각

132
00:06:02,150 --> 00:06:05,020
댓글에 내용 공간 수비 공감수

133
00:06:05,020 --> 00:06:07,740
그리고 댓글수 그리고 그 내용까지

134
00:06:07,740 --> 00:06:11,460
굉장히 많은 데이터를 갖고 있는 걸 볼 수가 있어요

135
00:06:11,460 --> 00:06:16,950
그러면은 이런 데이터들을 어떻게 보느냐 하나 있어요

136
00:06:16,950 --> 00:06:18,700
사실 로컬에서 우리가 말하는

137
00:06:18,700 --> 00:06:21,120
웹 크롤링 이라는 기술의 사용을 하면은

138
00:06:21,120 --> 00:06:22,300
차를 가져올 수 있어요

139
00:06:22,300 --> 00:06:25,390
사실 그렇게 어마어마하게 문제가 되지 않았는데

140
00:06:25,390 --> 00:06:26,820
우리가 대규모 스케일로

141
00:06:26,820 --> 00:06:28,990
그리고 자동으로 돌리려고 하면은 우리가 하루

142
00:06:28,990 --> 00:06:31,080
종일 몇 보 뱉어낼 수는 없기 때문에

143
00:06:31,080 --> 00:06:33,660
그 대신에 서버에서 동작을 하게 되었고

144
00:06:33,660 --> 00:06:36,370
저는 그 서버에서 돌리는 방법 중에 하나로

145
00:06:36,370 --> 00:06:38,320
aws 클라우드 상했습니다

146
00:06:38,320 --> 00:06:42,500
그중에서도 특히 서버리스란 방식을 사용을 했는데요

147
00:06:42,500 --> 00:06:46,690
aws 서버리스 서비스와 S3 사용을 해서

148
00:06:46,690 --> 00:06:50,430
이제 그 데이터를 저장을 했습니다

149
00:06:50,430 --> 00:06:53,300
그래서 2018년 작년 발표에서 진행했던 방법은

150
00:06:53,300 --> 00:06:54,100
이화 같은데요

151
00:06:54,100 --> 00:06:58,030
그 기사 목록을 쭉 넣으면은 이제 자동으로

152
00:06:58,030 --> 00:07:01,190
저 aws 서버에서 저장을 해 주는 방식으로

153
00:07:01,190 --> 00:07:02,170
진행을 했어요

154
00:07:02,170 --> 00:07:06,850
근데 올해는 보다 자동으로 돌리기 위해서 많은 부분이 출발했는데요

155
00:07:06,850 --> 00:07:08,360
우리 진행하고자 있던 프로젝트

156
00:07:08,360 --> 00:07:12,230
네 메일 모든댓글보기 보기 위해 저장 있어요

157
00:07:12,230 --> 00:07:14,260
그리고 그런 얘기 쇼 때문에 두 개

158
00:07:14,260 --> 00:07:16,960
크게 크게 두 가지 종류로 진행을 했어요

159
00:07:16,960 --> 00:07:21,250
첫 번째는 100대 많은 랭킹뉴스 에 해당하는 뉴스를

160
00:07:21,250 --> 00:07:25,380
일별데이터 가장 마지막에 있는 종가 데이터

161
00:07:25,380 --> 00:07:28,750
그래 모두 모두 일간 마지막 정리 데이터를 보았고요

162
00:07:28,750 --> 00:07:31,640
또한 안에 주식 가격에서 10분 단위로 보낸 것처럼

163
00:07:31,640 --> 00:07:37,010
매일 10분마다 네이버랭킹뉴스 있는 댓글 모든 방식으로

164
00:07:37,010 --> 00:07:38,720
이렇게 두 가지로 진행을 했어요

165
00:07:38,720 --> 00:07:40,960
그래서 매일 자동으로 돌아야 되겠다

166
00:07:40,960 --> 00:07:42,710
클라우드와 그저 큐레

167
00:07:42,710 --> 00:07:44,670
사용하는 방식으로 굉장히 다양하게

168
00:07:44,670 --> 00:07:48,190
자동으로 수집을 하도록 진행을 했습니다

169
00:07:48,190 --> 00:07:50,490
제가 뭘로 데이터에 안엔 로

170
00:07:50,490 --> 00:07:53,880
데이터는 제이슨파일 때문에 줄이고

171
00:07:53,880 --> 00:07:55,850
보다 쉽게 하기 위해서

172
00:07:55,850 --> 00:07:59,430
간단하게 화폐라는 파일로 변환하는 걸 진행을 했고요

173
00:07:59,430 --> 00:08:05,860
이것도 aws 서버 리스트 aws 글루 했습니다

174
00:08:05,860 --> 00:08:09,760
그래서 결과적으로 모임 데이터는 저정도 양인데요

175
00:08:09,760 --> 00:08:13,060
하루에 한 번씩 뭐 보낸 일정에 종가

176
00:08:13,060 --> 00:08:16,260
데이터 같은 경우에는 약 50개가 바이트가 압축되어

177
00:08:16,260 --> 00:08:18,380
10개가 정도로 모여 있고요

178
00:08:18,380 --> 00:08:22,010
그리고 10분 타인을 모으는 댓글 데이터 경우에는 지금

179
00:08:22,010 --> 00:08:25,620
원본 데이터의 분량의 제가 추적을 할 수 있고

180
00:08:25,620 --> 00:08:27,090
그 용량이 한 개 때문에

181
00:08:27,090 --> 00:08:29,900
일주일마다 지은 자동으로 지우는 걸 제가 돌려 놔서

182
00:08:29,900 --> 00:08:32,660
결과적으로 압축된 데이터는 현재까지 282

183
00:08:32,660 --> 00:08:34,800
기가바이트 뭐야 있습니다

184
00:08:34,800 --> 00:08:39,010
그래서 원본데이터 예약하기 테라 정도

185
00:08:39,010 --> 00:08:40,710
어차피 이런 식으로 데이터를 뭐 하고

186
00:08:40,710 --> 00:08:43,310
나면은 있어 데이터를 분석을 해야 되는데요

187
00:08:43,310 --> 00:08:46,420
이런 결과를 하기 위해서는 세 가지 접근방법 있어요

188
00:08:46,420 --> 00:08:49,980
통계분석 머신러닝 딥러닝 이렇게 세 가지 방법인데요

189
00:08:49,980 --> 00:08:53,640
가장 기본적인 해야 되는 게 통해서 견적은 방법이요

190
00:08:53,640 --> 00:08:56,930
과정을 통해서 데이터가 도대체 어떻게 생겼는지

191
00:08:56,930 --> 00:08:59,590
그런 방식으로 어떤 종계 존재하는지

192
00:08:59,590 --> 00:09:04,110
어떤 모양을 뛰고 있는 지를 알아봐야 한편

193
00:09:04,110 --> 00:09:06,170
머신러닝 같은 경우엔 이제 아까

194
00:09:06,170 --> 00:09:09,260
통 기적의 접근방법이 기존의 데이터가 어떻게 생겼는지

195
00:09:09,260 --> 00:09:10,650
설명하기 위한 그러면은

196
00:09:10,650 --> 00:09:13,360
머신러닝 같은 경우에는 이렇게 지금까지 해 놨으니까

197
00:09:13,360 --> 00:09:16,450
앞으로 어떡할 건지 예측을 하는 거래 만드는 거야

198
00:09:16,450 --> 00:09:18,240
물론 머신러닝 데이터

199
00:09:18,240 --> 00:09:21,670
굉장히 다양한 데이터를 넣을 수 있지만

200
00:09:21,670 --> 00:09:25,380
어쨌든 머신러닝 가 경기서적 모두 스위처

201
00:09:25,380 --> 00:09:27,890
익스트랙션 이라는 어떤 데이터를 봐서

202
00:09:27,890 --> 00:09:30,020
어떤 항목을 봐서 그런 식으로

203
00:09:30,020 --> 00:09:34,910
우리가 적금 가설에 어찌 이런 부분이 굉장히 중요해요

204
00:09:34,910 --> 00:09:36,960
모든 데이터를 넣어서 볼 건지

205
00:09:36,960 --> 00:09:39,220
아니면 일부만 선택적 으로 볼 건지

206
00:09:39,220 --> 00:09:41,730
그런 식으로 선택을 하는 것도 필요하고요

207
00:09:41,730 --> 00:09:45,390
이제 마지막으로 딥러닝 같은 경우에는 데이터를 넣어서 유미야

208
00:09:45,390 --> 00:09:48,320
시철의 자동으로 핫스팟 만드는 방법 있어

209
00:09:48,320 --> 00:09:51,690
특히 우리가 연구를 하는 이런 소셜데이터 에서

210
00:09:51,690 --> 00:09:53,640
핵심적인 내용으로 분 중에 하나가

211
00:09:53,640 --> 00:09:56,660
바로 댓글에 본문 같이 텍스트 보고 있는데

212
00:09:56,660 --> 00:09:59,870
이런 택시 때 같은 되지 않은 데이터

213
00:09:59,870 --> 00:10:01,760
같은 경우에는 통계적 접점방식

214
00:10:01,760 --> 00:10:04,000
그러는 굉장히 접근하게 걸어

215
00:10:04,000 --> 00:10:07,930
딥러닝 같은 걸 통해서 이 텍스트 자체가 하나의 회사로써

216
00:10:07,930 --> 00:10:11,810
동작을 할 수 있도록 만들어 줄 수가 있습니다

217
00:10:11,810 --> 00:10:16,080
앞서 세상에 슬라이드에서 통계 그림 통계적 접근방법

218
00:10:16,080 --> 00:10:19,240
머신러닝 딥러닝 이렇게 세 가지를 이야기를 했는데요

219
00:10:19,240 --> 00:10:21,880
그래서 제가 계속 공통적으로 말씀해 드렸던 게

220
00:10:21,880 --> 00:10:23,840
피처를 이야기를 했어요

221
00:10:23,840 --> 00:10:25,940
그러면은 우리가 가진 데이터에서는

222
00:10:25,940 --> 00:10:28,030
어떤 시철의 사용할 수 있는 야

223
00:10:28,030 --> 00:10:29,700
이제부터 그걸 알아 볼게요

224
00:10:29,700 --> 00:10:31,090
휠체어를 선정 가려면

225
00:10:31,090 --> 00:10:35,260
우리 데이터가 도대체 어떻게 생겼는지 알아야 합니다

226
00:10:35,260 --> 00:10:37,200
우리가 가진 데이터 종류는 크게

227
00:10:37,200 --> 00:10:39,070
4종류로 나눠 볼 수 있어요

228
00:10:39,070 --> 00:10:43,150
첫 번째는 숫자형 데이터야 편 가능한 데이터 인데요

229
00:10:43,150 --> 00:10:44,090
좋아요 싫어요

230
00:10:44,090 --> 00:10:45,380
수업 대구에서

231
00:10:45,380 --> 00:10:47,290
그리고 댓글에 단순히

232
00:10:47,290 --> 00:10:49,780
그리고 댓글에 랭킹 베스트댓글 있으니

233
00:10:49,780 --> 00:10:53,200
그리고 공감의 비율 같은 게 숫자로 표현한 가능하니까

234
00:10:53,200 --> 00:10:55,710
데이터 백업을 수 있

235
00:10:55,710 --> 00:10:57,870
그리고 시간이 들어간 타임시리즈

236
00:10:57,870 --> 00:10:59,890
데이터 같은 경우에는 시간 관계 되거나

237
00:10:59,890 --> 00:11:03,330
순서와 관계된 데이터야 댓글 언제 썼는지

238
00:11:03,330 --> 00:11:06,480
기사가 7시간 대비해서 얼마나 빨리 썼는지

239
00:11:06,480 --> 00:11:09,120
혹은 짧은 시간 내에 얼마나 많이 쓰고 있는지

240
00:11:09,120 --> 00:11:11,150
혹은 하루에 댓글 얼마나 많이 사는지

241
00:11:11,150 --> 00:11:14,620
이런 시간이 관련된 데이터 과자

242
00:11:14,620 --> 00:11:16,180
그리고 세 번째는 텍스트

243
00:11:16,180 --> 00:11:20,770
그 자체로 데이터가 되는 게 있어요 이 경우에는 자연어처리

244
00:11:20,770 --> 00:11:23,260
nlp 같은 이야기가 들어가야 되겠다

245
00:11:23,260 --> 00:11:26,190
만도 갈게 상승하게 데이터 종류 중에서

246
00:11:26,190 --> 00:11:27,720
가장 다르게 힘들지만

247
00:11:27,720 --> 00:11:29,000
그래도 가장 중요한 정보를

248
00:11:29,000 --> 00:11:31,250
정말 많이 담고 있는 부분이기 때문에

249
00:11:31,250 --> 00:11:33,710
놓치면 굉장히 곤란한 부분입니다

250
00:11:33,710 --> 00:11:36,810
그게 마지막으로 유저데이터 경우에는 정확하게

251
00:11:36,810 --> 00:11:37,930
저 사람이 누구인지

252
00:11:37,930 --> 00:11:40,140
현실에 누군가와 맵핑을 할 수 없어요

253
00:11:40,140 --> 00:11:43,570
하지만 이 사람이 쓴 거를 시간순으로 추적을 하거나

254
00:11:43,570 --> 00:11:46,490
하는 방식을 통해서 사용을 할 수가 있잖아

255
00:11:46,490 --> 00:11:49,940
근데 사실 문제가 최근에 하나가 생겼어요

256
00:11:49,940 --> 00:11:51,200
바로 2019

257
00:11:51,200 --> 00:11:54,630
7월중순부터 네이버에서 유저를 쓴 사람이 누구인지

258
00:11:54,630 --> 00:11:57,120
식별하는 방법이 완전히 사라졌어요

259
00:11:57,120 --> 00:11:59,400
그 이전에 데이터에 대해서 네가 갖고 있는데

260
00:11:59,400 --> 00:12:02,180
바로 한 달 전부터 네이버에서 이거를 유저

261
00:12:02,180 --> 00:12:06,430
데이터를 그리고 수 없게 바뀌었습니다

262
00:12:06,430 --> 00:12:09,400
아무튼 그 이전에 데이터를 살펴보게 되면은 간단하게

263
00:12:09,400 --> 00:12:11,370
데이터 청양 부터 설명해 드릴게요

264
00:12:11,370 --> 00:12:15,170
제가 뭐 어떤 데이터가 네이버 뉴스에 들어가서 랭킹뉴스

265
00:12:15,170 --> 00:12:16,810
꾀많은 섹시한데

266
00:12:16,810 --> 00:12:18,980
그 100개만 랭킹 순서

267
00:12:18,980 --> 00:12:22,000
섹션별로 30개 기사가 내일 생성해 돼요

268
00:12:22,000 --> 00:12:22,690
그래서 정치

269
00:12:22,690 --> 00:12:25,120
경제 사회 등등 총 7가지 섹션

270
00:12:25,120 --> 00:12:27,910
여덟 개 주면 포토세션을 재밌게 때문에 일곱 개

271
00:12:27,910 --> 00:12:30,140
섹션 내에 있는 30개 기사

272
00:12:30,140 --> 00:12:33,790
MX200 10개를 가져오게 됩니다

273
00:12:33,790 --> 00:12:36,960
제가 문예관 데이터는 댓글 약 5천만 개 이상

274
00:12:36,960 --> 00:12:39,630
그리고 유조선의 170만명 이상으로

275
00:12:39,630 --> 00:12:42,240
하루에 20만 건 택배 데이터가 있고요

276
00:12:42,240 --> 00:12:44,000
닷모드 네이버에 있는

277
00:12:44,000 --> 00:12:45,450
모든 뉴스에 대해서 를 가져온 게

278
00:12:45,450 --> 00:12:47,660
아니 댓글 많은 랭킹 안에 들어가

279
00:12:47,660 --> 00:12:51,770
뉴스에 100개만 가져왔기 때문에 이 전체의 전체를 대표

280
00:12:51,770 --> 00:12:55,440
하지 않을 수 있다는 단점은 있습니다

281
00:12:55,440 --> 00:12:58,720
그래서 언론사 별로 얼마 남았는지 간단하게 왔어요

282
00:12:58,720 --> 00:13:02,870
저 제일 왼쪽 그래프 파란색 제일 위에 있는 그래프가 001

283
00:13:02,870 --> 00:13:07,210
연합뉴스 연합뉴스가 뉴스도 정말 가장 많이 내고

284
00:13:07,210 --> 00:13:10,300
그에 따라서 댓글도 굉장히 많은 걸 볼 수 있고요

285
00:13:10,300 --> 00:13:14,720
중앙일보 조선일보 등등이 입고 있는 걸 볼 수가 있어

286
00:13:14,720 --> 00:13:16,810
한편 이제 앞에서 데이터를 중에

287
00:13:16,810 --> 00:13:20,160
데이터를 여러 가지의 소개를 드렸는데요 이 데이터 중에서

288
00:13:20,160 --> 00:13:21,520
어떤 게 의미가 있는지는

289
00:13:21,520 --> 00:13:23,240
다시 한번 생각을 해 봐야 돼요

290
00:13:23,240 --> 00:13:25,390
예를 들어서 한 가지가 아니라

291
00:13:25,390 --> 00:13:27,730
여러 가지 종류의 노래 같이 볼 때

292
00:13:27,730 --> 00:13:29,700
생기는 피처 드렸어요

293
00:13:29,700 --> 00:13:32,420
베스트 댓글 같은 경우에는 랭킹을 세웠는데

294
00:13:32,420 --> 00:13:35,590
랭킹이 기사 별로 댓글을 묶어서

295
00:13:35,590 --> 00:13:39,770
거기서 좋아요를 많이 받은 순서대로 정렬해주는 방법을 통해서

296
00:13:39,770 --> 00:13:43,870
얼른 경우에 뼈 유저가 댓글 다는 속도 같은 경우에

297
00:13:43,870 --> 00:13:45,410
유저가 그 한 사람

298
00:13:45,410 --> 00:13:47,960
하루에 한 사람이 댓글을 모두 모아서

299
00:13:47,960 --> 00:13:49,580
시간순서대로 정렬 한 다음에

300
00:13:49,580 --> 00:13:52,500
그 댓글을 사이에 시간에 계산을 해 줘야 돼요

301
00:13:52,500 --> 00:13:54,890
이런 식으로 그 데이터를 존재하지만

302
00:13:54,890 --> 00:13:58,500
그거를 한 번 새로운 데이터가 새로운 필터로서

303
00:13:58,500 --> 00:14:01,200
동작을 할 수 있게 됩니다

304
00:14:01,200 --> 00:14:03,180
물론 이런 데이터는 수치적인 데이터

305
00:14:03,180 --> 00:14:05,160
굉장히 다르게 가시는데

306
00:14:05,160 --> 00:14:07,370
텍스트데이터 같은 경우는 좀 까다로워요

307
00:14:07,370 --> 00:14:08,780
모델 학습 할 수 있도록

308
00:14:08,780 --> 00:14:11,670
컴퓨터가 이해하는 숫자형식으로 바꿔 주네

309
00:14:11,670 --> 00:14:14,340
작업이 필요하기

310
00:14:14,340 --> 00:14:17,530
그 외에도 책자에는 굉장히 다양한 색상이 있어요

311
00:14:17,530 --> 00:14:20,160
그 댓글에 단어를 살펴보는 것뿐만 아니라

312
00:14:20,160 --> 00:14:23,400
댓글 1 hour 이 포함 되어 있는가 링크가 있는가

313
00:14:23,400 --> 00:14:25,120
혹은 한 사람 기준으로 했을 때

314
00:14:25,120 --> 00:14:28,660
그 한 사람이 많아 다양한 단어를 사용하고 있는 것

315
00:14:28,660 --> 00:14:31,320
혹은 유저가 얼마나 긴 댓글을 쓰는 거

316
00:14:31,320 --> 00:14:32,870
계속 텍스트내용 뿐만이 아니라

317
00:14:32,870 --> 00:14:37,690
그 자체로서 더 다양한 필터들을 뽑아 줄 수가 있어요

318
00:14:37,690 --> 00:14:39,840
이렇게 돼 대해서 여러가지 생각을 하고

319
00:14:39,840 --> 00:14:41,740
나면은 가설에 세워 봐야 돼요

320
00:14:41,740 --> 00:14:45,410
어떤 패턴 전에 볼 수 있을지 말이죠

321
00:14:45,410 --> 00:14:47,380
프로젝트를 진행하는 거 있어서

322
00:14:47,380 --> 00:14:50,710
이번 프로젝트는 굉장히 중요한 게 그라운드 트러스

323
00:14:50,710 --> 00:14:53,040
그러니까 실제로 저 유저들이

324
00:14:53,040 --> 00:14:55,970
혹은 저 댓글이 어떤 어떤 유저들이 죄에

325
00:14:55,970 --> 00:14:57,380
대한 정보가 필요해요

326
00:14:57,380 --> 00:15:01,350
그런데 제가 수집한 데이터는 사실 그게 없어요

327
00:15:01,350 --> 00:15:04,160
왜냐면 제가 수집한 데이터에서 네이버가 이유

328
00:15:04,160 --> 00:15:07,520
저는 이런 이런 유소다 라고 알려 주지도 않고

329
00:15:07,520 --> 00:15:08,630
유저가 현실이죠

330
00:15:08,630 --> 00:15:10,820
연결될 수 있는 방법도 전혀 없기 때문에

331
00:15:10,820 --> 00:15:12,780
그거는 알 수가 없어요

332
00:15:12,780 --> 00:15:13,920
그래서 어떤 모델

333
00:15:13,920 --> 00:15:16,530
좋은 데이터분석 모델의 만든다고 하더라도

334
00:15:16,530 --> 00:15:20,520
명시적으로 테스트 하는 게 사실상 불가능한 따라서

335
00:15:20,520 --> 00:15:23,160
여러가지 방법을 사용을 해서 아웃라이어

336
00:15:23,160 --> 00:15:25,070
그러니까 일반적인 유저들이 이런 식으로

337
00:15:25,070 --> 00:15:28,280
군포 있다면은 여기 혼자 돈 떨어져 있는 유저를 찾네

338
00:15:28,280 --> 00:15:30,190
그런 방식으로 진행을 해야 되는 거죠

339
00:15:30,190 --> 00:15:34,120
혹은 어떻게 이제 우리가 직접 라벨을 붙여서 이 사람

340
00:15:34,120 --> 00:15:35,560
어떤 사람이 다 호근이 댓글

341
00:15:35,560 --> 00:15:39,490
어떤 댓글이다 라고 적어 주면 작업이 필요해요

342
00:15:39,490 --> 00:15:41,060
따라서 무엇이 정상이고

343
00:15:41,060 --> 00:15:42,400
무엇이 비정상이다

344
00:15:42,400 --> 00:15:44,470
댓글을 찾는 거라기보다는

345
00:15:44,470 --> 00:15:47,000
그거보다 조금 더 쉬운 이슈로

346
00:15:47,000 --> 00:15:48,950
좀 더 극단적인 댓글들을 타짜

347
00:15:48,950 --> 00:15:51,360
라는 방식으로 방향을 선회하게 됐어요

348
00:15:51,360 --> 00:15:54,880
그래서 찾게 된 것이 다음과 같이 수량 내용

349
00:15:54,880 --> 00:15:56,770
그리고 정치적인 경계 들어가

350
00:15:56,770 --> 00:16:01,380
나는 그 외에 여러 가지 아웃라이어 들의 찾는 거야

351
00:16:01,380 --> 00:16:04,250
노래 찾는 거는 일정이 아까 말씀드렸던 것처럼

352
00:16:04,250 --> 00:16:05,850
그래프가 이렇게 있다고 할 때

353
00:16:05,850 --> 00:16:07,110
갑자기 혼자서 톡 하고

354
00:16:07,110 --> 00:16:09,760
튀는 이런 친구들의 찾는 거라고 볼 수가 있어요

355
00:16:09,760 --> 00:16:12,940
그래서 어떤 피처를 X 축 Y 축

356
00:16:12,940 --> 00:16:16,550
이런 식으로 자꾸 사람들이 쭉 세웠을 때

357
00:16:16,550 --> 00:16:18,540
어떤 제가 톡 하고 친다는 이유

358
00:16:18,540 --> 00:16:20,830
저는 아무나 여다 라고 생각을 해

359
00:16:20,830 --> 00:16:22,250
줄 수가 있는 것이다

360
00:16:22,250 --> 00:16:24,020
그리고 이거 한 게 이제 폴리티컬

361
00:16:24,020 --> 00:16:26,250
정치적으로 얼마나 되어 있는지

362
00:16:26,250 --> 00:16:29,710
그런 거 있어도 연구를 진행하고 있어

363
00:16:29,710 --> 00:16:32,550
이제부터 네 지금까지 어떻게 삐처리 잡고 피처리

364
00:16:32,550 --> 00:16:35,380
어떤 식으로 세울 수 있는지에 대해서 설명을 해드렸는데요

365
00:16:35,380 --> 00:16:37,900
그럼 이런 거 휠체어로 축을 세우고 나서

366
00:16:37,900 --> 00:16:39,350
아웃라인 애들이 어떻게 있는지

367
00:16:39,350 --> 00:16:42,090
한번 살펴 보도록 할게요

368
00:16:42,090 --> 00:16:44,360
제가 세웠던 아이디어는 여러 가지가 있는데요

369
00:16:44,360 --> 00:16:46,150
첫 번째 아이디어를 댓글에

370
00:16:46,150 --> 00:16:48,750
url 을 많이 가져다 쓰는 경우

371
00:16:48,750 --> 00:16:52,510
혹은 이제 편견을 문자열 길이가 긴 경우

372
00:16:52,510 --> 00:16:55,420
댓글 꽉꽉 채워서 쓰는 경우가 있겠죠

373
00:16:55,420 --> 00:16:59,760
그리고 유저별로 다양한 워딩을 사용하지 않는 영어

374
00:16:59,760 --> 00:17:03,470
그리고 댓글을 몰아서 쓰거나 뭐 일상적으로 댓글이 서버나

375
00:17:03,470 --> 00:17:06,240
혹은 이제 얼마나 댓글이 빨리 가는지

376
00:17:06,240 --> 00:17:09,080
이런 것들을 분석해보기로 했어요

377
00:17:09,080 --> 00:17:11,060
계속 마지막으로 댓글

378
00:17:11,060 --> 00:17:14,480
빨리 가는 경우에는 빨리 단단한 은정이가 굉장히 뭐 해서

379
00:17:14,480 --> 00:17:16,430
두 가지로 좀 나눠서 생각을 해봤는데요

380
00:17:16,430 --> 00:17:19,300
하나는 뉴스가 올라오자마자 댓글을 다는 경우

381
00:17:19,300 --> 00:17:21,460
혹은 사람이 되어 있고

382
00:17:21,460 --> 00:17:25,060
그 다음은 직후에 바로 댓글을 다는 이렇게

383
00:17:25,060 --> 00:17:27,690
두 가지로 생각을 해 봤어요

384
00:17:27,690 --> 00:17:29,450
그래서 이러한 댓글들을

385
00:17:29,450 --> 00:17:33,410
파이썬과 약간의 노가다를 통해서 열어 특징 갈아 봤고

386
00:17:33,410 --> 00:17:37,100
이제 결과를 알아보려고해요

387
00:17:37,100 --> 00:17:39,460
우선 2월에 붙이고 다니는 사람들

388
00:17:39,460 --> 00:17:41,020
왜 경우예요

389
00:17:41,020 --> 00:17:42,340
댓글에서는 잘 생각해

390
00:17:42,340 --> 00:17:45,720
보시면은 http 링크를 갖다 붙여도 클릭도 안 되고

391
00:17:45,720 --> 00:17:47,740
터치를 한다고 해서 아무런 일도 일어나지 않아요

392
00:17:47,740 --> 00:17:51,710
직접 복사를 인터넷창에 갖다 붙여야 만 거기로 들어가 있어

393
00:17:51,710 --> 00:17:55,060
굉장히 많은 여자 인게이지먼트를 요구하는 방식인데

394
00:17:55,060 --> 00:17:59,480
그럼에도 불구하고 6월에 고치는 사람이 있다는 거잖아

395
00:17:59,480 --> 00:18:01,240
그럼 요대로 얼마나 많이 자꾸 대답

396
00:18:01,240 --> 00:18:03,220
꽃 달고 있냐 라고 해 보니까

397
00:18:03,220 --> 00:18:05,660
6월에 타는 비율이 평균적으로

398
00:18:05,660 --> 00:18:10,560
0% 에서 100% 까지 찾아 봤을 때 0% 가 너무 많아요

399
00:18:10,560 --> 00:18:11,830
0퍼센트가 지금 하늘에 떠 있고

400
00:18:11,830 --> 00:18:13,530
있어서 나타나지 않아서

401
00:18:13,530 --> 00:18:18,080
1% 이상으로 나타낸 매트가 바로 오른쪽에 있는 1% 부터

402
00:18:18,080 --> 00:18:21,750
100% 까지 그래핀 여기선 안 봐도

403
00:18:21,750 --> 00:18:24,080
저 가장 오른쪽 100% 에 가까운 게

404
00:18:24,080 --> 00:18:25,480
누가 봐도 몰라요

405
00:18:25,480 --> 00:18:28,730
달라고 나타내니 모습이 보입니다

406
00:18:28,730 --> 00:18:33,160
세수를 댓글은 전체댓글 중에서

407
00:18:33,160 --> 00:18:35,260
약 4만 개 정도가 달려있구요

408
00:18:35,260 --> 00:18:39,010
전체댓글 중에서 0.18% 에 해당합니다

409
00:18:39,010 --> 00:18:41,050
6월 비율이 1% 이상

410
00:18:41,050 --> 00:18:43,920
유저들 같은 경우는 1만 명 정도가 있고

411
00:18:43,920 --> 00:18:47,020
한 번이라도 6월에 가 짜서 쓰는 경우도 1만명

412
00:18:47,020 --> 00:18:49,540
조금 넘습니다

413
00:18:49,540 --> 00:18:51,350
이제 댓글 중에서 6월에

414
00:18:51,350 --> 00:18:55,790
댓글 비율이 6월에 댓글이 단수가 이제 부모가 되고

415
00:18:55,790 --> 00:18:59,530
6월에 댓글이 분자가 될 경우에 2월 8일 계정으로

416
00:18:59,530 --> 00:19:04,780
유저가 댓글을 계시록을 찍어 보면은 많은 사람들이 많이 그런지

417
00:19:04,780 --> 00:19:06,520
약간 전형적인 로그스케일

418
00:19:06,520 --> 00:19:09,950
그 패턴이 보여요 내용을 살펴보면

419
00:19:09,950 --> 00:19:11,440
저 이제 QR 코드를 찍어 보시면

420
00:19:11,440 --> 00:19:13,990
실제 어떤 댓글이 있는지도 보실 수 있는데

421
00:19:13,990 --> 00:19:15,350
이런 청와대 청원

422
00:19:15,350 --> 00:19:16,780
그 6월에 가져와서 창원에

423
00:19:16,780 --> 00:19:20,570
해달 라고 하는 요청이 굉장히 많은 편이고요

424
00:19:20,570 --> 00:19:21,820
그리고 특정 기사

425
00:19:21,820 --> 00:19:25,270
혹은 매체 그런 리다이렉션

426
00:19:25,270 --> 00:19:28,790
여기로 들어가 봐라 라고 하는 요구대로 굉장히 많아요

427
00:19:28,790 --> 00:19:30,190
복권 이렇게 말하는 거

428
00:19:30,190 --> 00:19:32,820
이런 데 사실 팩트는 이렇다라고 팩트체크

429
00:19:32,820 --> 00:19:36,350
성 2월의 가져 오는 경우도 있고요

430
00:19:36,350 --> 00:19:37,910
그러면은 이제 댓글에

431
00:19:37,910 --> 00:19:39,320
길게 다니는 사람들은

432
00:19:39,320 --> 00:19:41,590
어떤 사람 있는지 살펴보도록 할게요

433
00:19:41,590 --> 00:19:44,050
서지우 재테크 있을 때 채소 교체 하는 것도 괜찮은데

434
00:19:44,050 --> 00:19:46,690
300짜리 꽉꽉 채워서 쓴다

435
00:19:46,690 --> 00:19:48,960
진짜 어려운 거 같아요

436
00:19:48,960 --> 00:19:52,380
네이버에서 하셔야 댓글을 달 수 있는 최대길이는 저게 300자

437
00:19:52,380 --> 00:19:53,230
제한이 있어요

438
00:19:53,230 --> 00:19:56,040
그래서 300 했으면은 맥스를 다 쓴 거잖아

439
00:19:56,040 --> 00:19:59,670
그래서 그 기내에서 유저들이 얼마 유저별

440
00:19:59,670 --> 00:20:03,790
유저별로 얼마나 평균 문자를 길이가 김치를 살펴봤어요

441
00:20:03,790 --> 00:20:07,810
평균 문자 길이를 살펴 본 건데요

442
00:20:07,810 --> 00:20:10,290
50 글자로 인해 50글자 이내로

443
00:20:10,290 --> 00:20:14,020
평균 작성하는 게 뭔가 60% 가 너 맞고

444
00:20:14,020 --> 00:20:17,620
이하로 할 경우에는 87퍼센트가 넘었습니다

445
00:20:17,620 --> 00:20:19,160
여기 그래프도 잘 보시면

446
00:20:19,160 --> 00:20:21,030
저 오른쪽 끝에 혼자서

447
00:20:21,030 --> 00:20:24,680
올라가 있는 케이스를 보실 수가 있어요

448
00:20:24,680 --> 00:20:29,080
우측 아래 부분에 대해서 살펴보면은 평균 길이 250 이상으로

449
00:20:29,080 --> 00:20:30,950
확대안 그래프 인데요

450
00:20:30,950 --> 00:20:32,680
250으로 봐도 290 에서

451
00:20:32,680 --> 00:20:35,430
302화 같은 것을 볼 수가 있어요

452
00:20:35,430 --> 00:20:39,710
저 케이스도 있어요 여기 QR 코드 보실 수가 있구요

453
00:20:39,710 --> 00:20:41,360
근데 이런 유저들이 어떤데

454
00:20:41,360 --> 00:20:46,010
글래스고 살펴보면은 정치적 내용이 굉장히 긴

455
00:20:46,010 --> 00:20:46,950
댓글을 쓰거나

456
00:20:46,950 --> 00:20:49,980
혹은 비슷한 내용을 굉장히 자주 다는

457
00:20:49,980 --> 00:20:52,840
그런 경우도 보여요

458
00:20:52,840 --> 00:20:55,190
근데 이런 긴 댓글을 다는 유저들은 그 얼마나

459
00:20:55,190 --> 00:20:57,100
많은 댓글 쓰고 있나 라고 살펴

460
00:20:57,100 --> 00:20:58,440
벌써 그래서 댓글

461
00:20:58,440 --> 00:21:03,430
평균 기회가 290 이상인 유저들의 댓글 개수를 찾아보니까

462
00:21:03,430 --> 00:21:05,920
14000개 해당하는 댓글을 달고 있었고

463
00:21:05,920 --> 00:21:09,600
유조선의 오천명 안쪽에 해당 했습니다

464
00:21:09,600 --> 00:21:10,740
그래 프로그램 갔을때

465
00:21:10,740 --> 00:21:15,570
오른쪽에 아울렛 해당하는 불량이 이 정도면 사는 거다

466
00:21:15,570 --> 00:21:17,290
또 다른 방법으로 살펴 본 것은

467
00:21:17,290 --> 00:21:20,380
바로 비슷한 날에 하는 올라왔어요

468
00:21:20,380 --> 00:21:24,460
사용자들이 일반 댓글달때 매번 새로운 타이핑해서 담백원

469
00:21:24,460 --> 00:21:25,570
새롭게 살텐데

470
00:21:25,570 --> 00:21:28,210
똑같은 말 혹은 계속 비슷한 말을 하고 있다면은

471
00:21:28,210 --> 00:21:30,940
뭔가 위도가 있지 않을까 라고 생각을 한 거죠

472
00:21:30,940 --> 00:21:32,290
그리고 우리가 만약에

473
00:21:32,290 --> 00:21:33,540
직접 댓글을 단다는

474
00:21:33,540 --> 00:21:35,650
항상 동일한 말을 하고 있지 않기 때문에

475
00:21:35,650 --> 00:21:38,050
좀 더 다양한 기능을 사용하고 있을 것

476
00:21:38,050 --> 00:21:40,750
아는 가설에 세웠습니다

477
00:21:40,750 --> 00:21:42,770
첫 번째 방법은 유저별로 사용한뒤

478
00:21:42,770 --> 00:21:45,000
단어 목록에 모아 본 거예요

479
00:21:45,000 --> 00:21:50,270
그래서 2019년 6월 첫 주 데이터를 기준으로 살펴볼 때

480
00:21:50,270 --> 00:21:53,190
그 토크나이저 사용을 해서 단어를 잘라서 사용을 했고

481
00:21:53,190 --> 00:21:54,050
싸이키런 의 TF-idf

482
00:21:54,050 --> 00:21:57,980
벡터의 사용을 했는데 이 과정을 통해서 결과적으로 나오는

483
00:21:57,980 --> 00:22:00,600
거는 한 사람이 댓글을 쪽하고 쓰고

484
00:22:00,600 --> 00:22:02,610
그럼 그거 일자별로 이

485
00:22:02,610 --> 00:22:06,380
사람이 쓴 단어들의 토핑들이 뽑아내는 거야 단호박

486
00:22:06,380 --> 00:22:08,780
결과적으로 나오게 하는 거다

487
00:22:08,780 --> 00:22:10,610
물론 생각보다 좀 오래 걸리고

488
00:22:10,610 --> 00:22:12,740
제가 한주 한주 침 안 해서 그래

489
00:22:12,740 --> 00:22:15,020
앞으로 그런 이유가 이게 한 달에 채우고

490
00:22:15,020 --> 00:22:18,910
2년 치러 돌리면 시간이 어마어마하게 오래걸리더라구요

491
00:22:18,910 --> 00:22:22,520
7조 사용자들을 케이스로 나타내 보면 에 이게 사용자 유저아이디

492
00:22:22,520 --> 00:22:25,610
꼭 오른쪽에 그 사용자가 사용한 단어 드려요

493
00:22:25,610 --> 00:22:27,800
그래서 그 사용자가 어떤 단어들을 위주로

494
00:22:27,800 --> 00:22:29,700
사용을 했는지 볼 수 있는데

495
00:22:29,700 --> 00:22:30,970
사용자들에게 사용한다

496
00:22:30,970 --> 00:22:34,660
널 패턴에 통해서 이상자가 어떤 특성에 사용

497
00:22:34,660 --> 00:22:36,630
나는 거래 추측해 볼 수도 있어요

498
00:22:36,630 --> 00:22:39,250
근데 그건 제가 해 버리는 게 아니라고요

499
00:22:39,250 --> 00:22:41,100
단어를 사용을 하는데

500
00:22:41,100 --> 00:22:43,750
그러면 실제로 이 사람이 쓴 댓글이 계속 도대체

501
00:22:43,750 --> 00:22:46,560
몇 개 아니야 이 두 개를 같이 보자는 맞아

502
00:22:46,560 --> 00:22:47,740
댓글은 많이 쓰는데

503
00:22:47,740 --> 00:22:50,560
토픽은 개수는 진짜 적어요

504
00:22:50,560 --> 00:22:54,160
그러면은 응 아니야 라고 가설을 하시면 거다

505
00:22:54,160 --> 00:22:55,660
그래서 토픽 개스

506
00:22:55,660 --> 00:23:00,450
나누기 댓글 수입 유리 적은 찾고자 했어요

507
00:23:00,450 --> 00:23:02,500
근데 실제로 결과를 살펴보면

508
00:23:02,500 --> 00:23:04,350
사용 해서 542 올려 있어요

509
00:23:04,350 --> 00:23:07,550
일방적인 주장들도 몰려 있고

510
00:23:07,550 --> 00:23:08,350
한 편이라도 뛰기

511
00:23:08,350 --> 00:23:11,680
굉장히 적게 나오는 경우가 너무 많았기 때문에 이 방법은

512
00:23:11,680 --> 00:23:12,480
적절하지 않다

513
00:23:12,480 --> 00:23:13,700
새로운 방법을 필요하다

514
00:23:13,700 --> 00:23:17,210
생각 계속 비슷한 문장에

515
00:23:17,210 --> 00:23:20,760
차는 유저를 조금 다른 방식으로 찾아보고자 있는데요

516
00:23:20,760 --> 00:23:25,360
이번에는 유저별로 일단이 혹은 1단지에서 같은

517
00:23:25,360 --> 00:23:26,540
혹은 비슷한 문자

518
00:23:26,540 --> 00:23:29,450
메세 경우를 살펴보면 방식을 선택을 했어요

519
00:23:29,450 --> 00:23:34,050
즉 유저가 사이에 댓글에 텍스트 사이에

520
00:23:34,050 --> 00:23:36,350
유사도를 비열한 건데요

521
00:23:36,350 --> 00:23:38,070
이와 같이 비슷한 문장에 사는 것도

522
00:23:38,070 --> 00:23:39,620
저희가 세 가지 여러 가지

523
00:23:39,620 --> 00:23:41,840
방법이 있을 굉장히 다양한 방법이 있는데

524
00:23:41,840 --> 00:23:45,470
첫 번째는 완전히 그 두 댓글이 같은지를 비교를 하는 거야

525
00:23:45,470 --> 00:23:48,160
굉장히 쉬어요 같은 집이 그만 하면 되니까요

526
00:23:48,160 --> 00:23:50,510
가장 빠르고 편하고 좋은데

527
00:23:50,510 --> 00:23:53,180
문제는 한글자라도 달라지면 찾을 수 없게 된다

528
00:23:53,180 --> 00:23:57,130
네 아주 치명적인 단점이 있어서 이 방법은 제외했습니다

529
00:23:57,130 --> 00:23:58,820
두 번째 방법은 2글자로

530
00:23:58,820 --> 00:24:03,790
얼마나 바꾸면 나는 얼마나 글자로 바꾸면 2

531
00:24:03,790 --> 00:24:07,810
댓글이 같아 전달해 확인해 보는 방식인데요 이 방식도 역시

532
00:24:07,810 --> 00:24:11,080
계산 굉장히 많기 때문에 시간이 굉장히 오래 걸려요

533
00:24:11,080 --> 00:24:13,250
그래서 이 방식 제외했습니다

534
00:24:13,250 --> 00:24:14,780
제가 사용하는 방법은

535
00:24:14,780 --> 00:24:17,630
실제로 얼마나 비슷한 터널을 갔냐

536
00:24:17,630 --> 00:24:19,490
나는 걸로 사용을 했는데요

537
00:24:19,490 --> 00:24:22,140
사람들이 사용하니까 댓글을 특근 단위로

538
00:24:22,140 --> 00:24:23,620
단위로 잘라 주고

539
00:24:23,620 --> 00:24:26,760
그 간호사에 유사도 비교를 작가들이 찬스

540
00:24:26,760 --> 00:24:29,260
혹은 블루스 통해서 비교를 해 주고

541
00:24:29,260 --> 00:24:31,770
또 다른 방식으로 는 뭘 또 임베딩

542
00:24:31,770 --> 00:24:33,770
그리고 그들을 통해서

543
00:24:33,770 --> 00:24:36,950
댓글 문장이 나타내는 벡터를 얼마나 유사한지

544
00:24:36,950 --> 00:24:40,400
비교해보는 방식을 사용하였습니다

545
00:24:40,400 --> 00:24:42,410
여기 비슷한 말을 쓰는 유저들의 그랬고요

546
00:24:42,410 --> 00:24:44,110
살펴보면 다음과 같은 데요

547
00:24:44,110 --> 00:24:46,940
이거는 코엔에프 용의 메카의 사용을 해서

548
00:24:46,940 --> 00:24:50,290
단어를 잘라서 유사도를 비교한 결과 입니다

549
00:24:50,290 --> 00:24:51,950
실제로 내용을 살펴보면

550
00:24:51,950 --> 00:24:54,330
위아래가 완전히 동일한 내용을 가져다가

551
00:24:54,330 --> 00:24:56,380
사용하는 유저 데도 있고

552
00:24:56,380 --> 00:24:58,550
복은 일부단어 다음과 같이

553
00:24:58,550 --> 00:25:01,120
바꿔서 사용하는 케이스도 있습니다

554
00:25:01,120 --> 00:25:04,610
보시면 에 지금 7일 꽃과 같이 일부단어 만 개

555
00:25:04,610 --> 00:25:08,760
자동적으로 바꿔서 사용하는 케이스를 볼 수가 있다

556
00:25:08,760 --> 00:25:10,050
한편 이제 캐릭터 단위로

557
00:25:10,050 --> 00:25:12,610
블루스코어 계산하는 방법도 있는데요

558
00:25:12,610 --> 00:25:16,310
이런 유사도 단지에서도 이 두 개 문장을 비교해 봤을 때

559
00:25:16,310 --> 00:25:18,270
저 바로 침부분 다르고

560
00:25:18,270 --> 00:25:22,750
나머지 부분은 모두 동일한 결과를 볼 수가 있습니다

561
00:25:22,750 --> 00:25:25,240
그리고 앞서 환급 일정에

562
00:25:25,240 --> 00:25:28,140
프레젠테이션도 언니라고 부르는 방식을 통해서

563
00:25:28,140 --> 00:25:29,610
문장을 임베딩 하고 나서

564
00:25:29,610 --> 00:25:33,100
그 두 문장에 코사인 시뮬레이터를 계산해 가면은 2

565
00:25:33,100 --> 00:25:34,760
문자 메시지를 단어가 다르더라도

566
00:25:34,760 --> 00:25:36,850
얼마나 비슷한지를 확인해 볼 수가 있어

567
00:25:36,850 --> 00:25:39,850
단트 문장이 의미가 얼마나 비싼지 찾을 수 있는데

568
00:25:39,850 --> 00:25:42,550
그것도 다음과 같은 방식으로 나타납니다

569
00:25:42,550 --> 00:25:45,950
그래서 좀 완전히 문장의 글자가 같진 않지만

570
00:25:45,950 --> 00:25:48,770
비슷한 문장들을 같기도 하고요

571
00:25:48,770 --> 00:25:52,450
한편 앞산 분석들은 이제 하루에 한 유적

572
00:25:52,450 --> 00:25:55,140
댓글만 기준으로 살펴 본 건데요

573
00:25:55,140 --> 00:25:58,660
1유저 가 아니라 전체 댓글에 대상으로 살펴보면

574
00:25:58,660 --> 00:26:02,440
어떻게 난 다 같이 한번 살펴 보았습니다

575
00:26:02,440 --> 00:26:08,730
다른 계정 같지 않아 유서가 같은 혹은 비슷한 댓글 쓴 케이스인데요

576
00:26:08,730 --> 00:26:10,500
실제로 확인해 보면은

577
00:26:10,500 --> 00:26:15,070
하루에도 몇 백년 의사가 잡히는 것을 볼 수가 있어요

578
00:26:15,070 --> 00:26:17,590
K3 하나 살펴보면 위아래 유정아

579
00:26:17,590 --> 00:26:19,840
유정아 내게 분명히 다른 데

580
00:26:19,840 --> 00:26:22,320
저 별표 되어 있는 글자를 제외한 나머지

581
00:26:22,320 --> 00:26:25,340
댓글이 내용이 완전히 동일한 것을 볼 수가 있어요

582
00:26:25,340 --> 00:26:27,840
작년 케이스스터디 에서는 완전

583
00:26:27,840 --> 00:26:30,600
다닐 유저를 기준으로 동일한 거만 비교했는데

584
00:26:30,600 --> 00:26:32,190
이번에는 하루다

585
00:26:32,190 --> 00:26:35,740
유저 모두 돼 모드로 비교를 해서 결과를 가져 와서

586
00:26:35,740 --> 00:26:39,840
결과적으로 어떤 유저들이 서로 서로 비슷한 내용을 쓰고 있는지

587
00:26:39,840 --> 00:26:41,630
살펴볼 수 있게 되었어요

588
00:26:41,630 --> 00:26:45,460
그러면은 유저들간의 내용을 쓰네 이런 게 나왔잖아

589
00:26:45,460 --> 00:26:48,290
그러면 뭘 해야 될까요

590
00:26:48,290 --> 00:26:49,790
네트워크를 들어봐야겠다

591
00:26:49,790 --> 00:26:52,640
비슷한 말을 하는 유저들의 모아 봤으니까

592
00:26:52,640 --> 00:26:53,510
해당 유저들이 얼마나

593
00:26:53,510 --> 00:26:58,070
얽혀 있는지도 확인을 해 봐야 돼요 이 연결된 거래

594
00:26:58,070 --> 00:27:00,500
한번 연결이 되면 카운트 이라고

595
00:27:00,500 --> 00:27:03,460
이게 열 번 이상 연결된 경우 이 네트워크에 나타나도록

596
00:27:03,460 --> 00:27:05,110
그려 봤는데요

597
00:27:05,110 --> 00:27:06,850
실제로 그러면은 이희진

598
00:27:06,850 --> 00:27:10,890
중간에 가장 모여 있는 병원 같이 하나가 있는데요

599
00:27:10,890 --> 00:27:16,100
어떤 여자 된 거 같아서

600
00:27:16,100 --> 00:27:19,050
예측하기 쉽지 않은 사신의 저 중앙에 몰려 있는

601
00:27:19,050 --> 00:27:22,020
그러면 강다니엘 영광이 그룹이 왔어요

602
00:27:22,020 --> 00:27:24,060
강다니엘이 잘되기를 너무 원하니까

603
00:27:24,060 --> 00:27:27,270
팬들이 비슷한 말을 하게 되니까 그게 자동으로 걸린 거야

604
00:27:27,270 --> 00:27:29,700
강다니엘 잘 되길 바래요 응원합니다

605
00:27:29,700 --> 00:27:31,410
이런 새끼들이 걸렸고요

606
00:27:31,410 --> 00:27:33,910
자세한 내용은 사실 이거 왜 도전 담았는데

607
00:27:33,910 --> 00:27:35,420
QR 코드에 들어가 보시면

608
00:27:35,420 --> 00:27:43,300
직접 어떤 점이 있는지 확인해 보실 수 있습니다

609
00:27:43,300 --> 00:27:45,350
그래서 비슷한 말을 하는 유저

610
00:27:45,350 --> 00:27:49,220
그것도 그것도 외에도 다른 애들도 있었잖아

611
00:27:49,220 --> 00:27:53,910
이번에는 손인웅 보다 빠른 아웃라이어를 찾아 왔습니다

612
00:27:53,910 --> 00:27:56,160
제가 정리하는 거 나까지 2가죽케이스 였어요

613
00:27:56,160 --> 00:28:00,240
뉴스라고 올라오자마자 택배 계단 유저가 댓글을 달고 나서

614
00:28:00,240 --> 00:28:01,790
그 체크 댓글이 굉장히 빠르게

615
00:28:01,790 --> 00:28:05,030
달리는 이 두가지 케이스를 봤는데요 이

616
00:28:05,030 --> 00:28:05,890
두 가지 캐슬 봤을 때

617
00:28:05,890 --> 00:28:08,020
첫 번째 케이스는 뉴스가 올라오자마자

618
00:28:08,020 --> 00:28:08,870
댓글을 다는 거야

619
00:28:08,870 --> 00:28:11,370
뉴스가 아침에 올라오는시간 보통 새벽

620
00:28:11,370 --> 00:28:14,720
여섯시 삼십분 에서 오십분 사이에 많이 올라오는데

621
00:28:14,720 --> 00:28:17,490
있대 사용자들이 댓글에 바로 난다

622
00:28:17,490 --> 00:28:20,840
새벽 아침에 일어나서 저 제 입장에서 쉽지 않았어요

623
00:28:20,840 --> 00:28:22,910
맨날 전에 굉장히 늦게 일어나는 편이기 때문에

624
00:28:22,910 --> 00:28:24,640
싶지 않았는데

625
00:28:24,640 --> 00:28:26,480
아무튼 이거래 1시간

626
00:28:26,480 --> 00:28:28,960
댓글이 기사가 올라 오고 나서

627
00:28:28,960 --> 00:28:30,810
댓글이 올라오기까지 1시간 이내에

628
00:28:30,810 --> 00:28:33,080
유저들을 3세 봤어요

629
00:28:33,080 --> 00:28:35,550
그랬더니 실제로 그렇게 예상처럼

630
00:28:35,550 --> 00:28:38,880
엄청나게 튀는 그래프는 나타나지 않더라고요

631
00:28:38,880 --> 00:28:41,290
그래서 무슨 하게 빨리 댓글이 된다

632
00:28:41,290 --> 00:28:44,260
라는 거는 큰 정보가 되지 않았습니다

633
00:28:44,260 --> 00:28:45,440
유저가 앵초 이내에

634
00:28:45,440 --> 00:28:48,750
댓글을 다는 케이스를 살펴 보기로 했잖아

635
00:28:48,750 --> 00:28:50,550
근데 사실 제가 한번 실험해 봤는데

636
00:28:50,550 --> 00:28:53,060
댓글을 달고 바로 댓글을 달려고 하니까 아

637
00:28:53,060 --> 00:28:56,220
댓글과 답글로 60초 이내 한 번씩 달 수 있어요

638
00:28:56,220 --> 00:28:57,700
경고창을 띄워 주더라고요

639
00:28:57,700 --> 00:29:00,020
실제로 60초가 지나야만 새댓글

640
00:29:00,020 --> 00:29:02,110
그리고 답들이 다이스 있고요

641
00:29:02,110 --> 00:29:06,310
타임 데이터를 계산해서 댓글 첫 번째 두 번째 세 번째 네

642
00:29:06,310 --> 00:29:10,070
그리고 이 댓글 사이의 간격 계산을 해 봤어요

643
00:29:10,070 --> 00:29:14,130
10분 이내 안 됐거든요 얼마 남았나 찍어 보니까

644
00:29:14,130 --> 00:29:16,860
실제로 여기 60초가 끝나자마자

645
00:29:16,860 --> 00:29:18,200
댓글 다는 케이스가 은근히

646
00:29:18,200 --> 00:29:20,540
많은 거를 볼 수가 있었어요

647
00:29:20,540 --> 00:29:22,320
실제로 이유 저같은 경우에는

648
00:29:22,320 --> 00:29:26,920
댓글 사이의 간격이 딱 60초로 나오는 거야

649
00:29:26,920 --> 00:29:29,600
자 이번에는 좀 더 다른 접근 방법인데요

650
00:29:29,600 --> 00:29:33,130
대세 순위가 어떻게 바뀌냐 입니다

651
00:29:33,130 --> 00:29:34,680
배대지 어떻게 만들어지는지

652
00:29:34,680 --> 00:29:37,290
그리고 한 번씩 한번 배 되시면 영원히 배대신

653
00:29:37,290 --> 00:29:40,630
그리고 댓글에 순위가 어떻게 바뀌는지 알고 싶은 사실

654
00:29:40,630 --> 00:29:42,970
첫 번째 질문은 제가 답할 수가 없는 거고요

655
00:29:42,970 --> 00:29:44,420
두 번째인가 세 번째 문제

656
00:29:44,420 --> 00:29:47,020
대해서 확인해 보기로 했습니다

657
00:29:47,020 --> 00:29:49,920
제가 사용한 데이터는 댓글 많은 기사를 오전

658
00:29:49,920 --> 00:29:54,640
일곱시 부터 밤 12시까지 매 10분 간격으로 보험 데이터분야

659
00:29:54,640 --> 00:29:58,910
기사가 랭킹 많은 이라는 랭킹 뉴스에 들어오는 순간부터 시작해서

660
00:29:58,910 --> 00:30:02,680
10분 간격으로 모두 데이터를 가져온 거

661
00:30:02,680 --> 00:30:04,600
어떻게 있어요

662
00:30:04,600 --> 00:30:06,600
그래서 이런 데이터를 가지고 나는 좋아요

663
00:30:06,600 --> 00:30:08,220
수가 얼마나 어떻게 변해

664
00:30:08,220 --> 00:30:09,910
어떤 댓글이 생겼다가 사라졌는지

665
00:30:09,910 --> 00:30:12,700
이런 거를 모두 확인해 볼 수가 있어요

666
00:30:12,700 --> 00:30:15,900
실제로 하루치 데이터를 4시로 한번 그려 놓은 건데요

667
00:30:15,900 --> 00:30:17,990
오전 일곱시 이십분 부터 시작해서

668
00:30:17,990 --> 00:30:20,060
명령 시까지 그래프가 그려집니다

669
00:30:20,060 --> 00:30:22,520
그리고 1시간마다 이게 잘 자서 내려가니

670
00:30:22,520 --> 00:30:23,240
경우가 있는데

671
00:30:23,240 --> 00:30:26,170
네이버랭킹 랭킹뉴스 가 업데이트되면서

672
00:30:26,170 --> 00:30:29,520
그 전날에 있던 그 댓글이 사라지고 하는 방식으로

673
00:30:29,520 --> 00:30:32,370
숫자가 줄어들면서 기사가 업데이트가 되야

674
00:30:32,370 --> 00:30:34,140
댓글에 수가 한번 줄어들었다가

675
00:30:34,140 --> 00:30:38,590
다시 올해는 이런 모습이 반복된 이거

676
00:30:38,590 --> 00:30:41,940
베스트 댓글이 변하는 모습을 한번 살펴 봤어

677
00:30:41,940 --> 00:30:45,350
가장 기본적으로 배대스 니가 안 바뀝니다

678
00:30:45,350 --> 00:30:46,850
거의 안 막혀요

679
00:30:46,850 --> 00:30:49,010
그런데 초반부에는 이런 식으로

680
00:30:49,010 --> 00:30:55,270
약간 분위기가 변하는 경우도 있어요

681
00:30:55,270 --> 00:30:57,160
한번 살펴봤더니 이런 식으로

682
00:30:57,160 --> 00:31:00,840
정말 승희가 매우 치열하게 바뀌는 케이스에서

683
00:31:00,840 --> 00:31:05,120
저 하늘 그래프가 하나가 올라갔다가 밑으로 내려가고

684
00:31:05,120 --> 00:31:06,910
베스트넷 그래서 사라짐

685
00:31:06,910 --> 00:31:10,150
계속 저 댓글의 도대체 뭐 하는 날인가 살펴봤더니

686
00:31:10,150 --> 00:31:12,890
저런 식으로 어떤 팬 관련된 내용이었는데

687
00:31:12,890 --> 00:31:16,260
응원하지 않는다 라는 이었어

688
00:31:16,260 --> 00:31:21,520
한편 이런 케이스 말고 이런 케이스도 있었어요

689
00:31:21,520 --> 00:31:23,880
일본 관련한 내용이었는데요

690
00:31:23,880 --> 00:31:26,300
일본 이수에서 처음에 10개

691
00:31:26,300 --> 00:31:31,540
베스트 댓글이 전부 전부 비판적인 댓글이었다 가 일곱시 올라왔으니

692
00:31:31,540 --> 00:31:33,950
그랬다가 10시가 지나면서

693
00:31:33,950 --> 00:31:35,780
1등부터 5등까지 그대로인데

694
00:31:35,780 --> 00:31:38,260
6장부터 10등까지 전에 댓글이 전구

695
00:31:38,260 --> 00:31:40,150
옹호하는 댓글로 베스트밸리

696
00:31:40,150 --> 00:31:42,160
바뀐 것을 볼 수가 있었어요

697
00:31:42,160 --> 00:31:45,160
근데 이런 과정을 제가 잊어 댓글들에 직접 보고

698
00:31:45,160 --> 00:31:46,930
아 이건 친화적 인 거 같아

699
00:31:46,930 --> 00:31:48,880
저건 정보 비판적인 거 같아 라고

700
00:31:48,880 --> 00:31:51,790
사회적으로 해서 그렇게 때문에 생기는 이렇게 판단

701
00:31:51,790 --> 00:31:52,840
인데요

702
00:31:52,840 --> 00:31:55,780
이런 케이스를 직접 제가 보는 게 아니라

703
00:31:55,780 --> 00:31:58,550
좀 더 자동으로 보려는 다른 게 필요해

704
00:31:58,550 --> 00:32:01,600
바로 자동화된 풀릴까요

705
00:32:01,600 --> 00:32:05,130
그때 제가 바로 딥러닝에 사용햇습니다

706
00:32:05,130 --> 00:32:08,260
댓글에서 나타나는 정치적 편향성을 살펴보기 위해서

707
00:32:08,260 --> 00:32:09,910
여러 가지 방법을 사용할 했고

708
00:32:09,910 --> 00:32:11,980
가설에 여러 개 세워 놨어요

709
00:32:11,980 --> 00:32:14,470
키워드 방법으로 찾아보는 문맥상

710
00:32:14,470 --> 00:32:17,780
특정정당 의 질주 하거나 혹은 정책에 쉽지 않은 것

711
00:32:17,780 --> 00:32:20,690
결국 이건 그 내용을 보고 나서 도순 지진 본지

712
00:32:20,690 --> 00:32:22,000
혹은 특정정당 혹은

713
00:32:22,000 --> 00:32:25,680
정책에 지지하는지 아닌지를 살펴봐야 돼요

714
00:32:25,680 --> 00:32:29,540
김란영 을 이용해서 텍스트 시철을 뽑았는데

715
00:32:29,540 --> 00:32:32,910
한편 이제 우리가 모두 다 알고 있어 알고 있을 시

716
00:32:32,910 --> 00:32:35,980
라벨링된 데이터가 필요 해요 이 댓글을 보고

717
00:32:35,980 --> 00:32:37,510
댓글은 누구 편이다

718
00:32:37,510 --> 00:32:39,900
나는 그런 게 필요한 거 사 한편

719
00:32:39,900 --> 00:32:41,690
라벨링을 하는 과정에 있어서

720
00:32:41,690 --> 00:32:43,640
하루에 20만 댓글이 올라오는데

721
00:32:43,640 --> 00:32:47,020
이거 제가 직접 마블링 하고 있다 당연히 불가능해요

722
00:32:47,020 --> 00:32:49,140
따라서 좀 더 적은 데이터를 가지고

723
00:32:49,140 --> 00:32:53,470
좀 더 높은 효율을 끌어들이기 위해서 여러 가지 가설에 세워봤습니다

724
00:32:53,470 --> 00:32:55,370
댓글이 있을 좋아요가 많으니까

725
00:32:55,370 --> 00:32:59,910
유저들 공감을 많이 많이 받은 거고 이 기사에 대해서 어떠니

726
00:32:59,910 --> 00:33:03,160
댓글이 굉장히 좋은 100% TV 를 가지고 있다

727
00:33:03,160 --> 00:33:04,340
라는 생각을 했어

728
00:33:04,340 --> 00:33:06,650
그래서 2019년 7월 기준으로

729
00:33:06,650 --> 00:33:09,950
베스트 댓글 잡아서 50000개 데이터를 살펴봤어요

730
00:33:09,950 --> 00:33:11,110
근데 여전히 오만

731
00:33:11,110 --> 00:33:13,790
개는 직접 라벨링 할게 너무 많은데 이 타자

732
00:33:13,790 --> 00:33:16,070
칠 줄을 남에게 한번 진행을 해 봤는데

733
00:33:16,070 --> 00:33:18,280
하루에 2,000개 정도는 할 수 있고

734
00:33:18,280 --> 00:33:21,270
그 날 저녁에는 정말 제 머리가 많이 아파서 라고요

735
00:33:21,270 --> 00:33:24,740
그리곤 만기는 한달 이라고 적어놨지만

736
00:33:24,740 --> 00:33:27,260
사실에 몇 달 걸릴 것

737
00:33:27,260 --> 00:33:29,120
그래서 어쩐다고 빠르고

738
00:33:29,120 --> 00:33:31,620
편한 날 위해서 조금 부정확하다

739
00:33:31,620 --> 00:33:33,290
나도 그리고 빠르고 그래

740
00:33:33,290 --> 00:33:34,690
비슷한 거를 추천해 주는

741
00:33:34,690 --> 00:33:38,670
퇴근 시스템을 개발해 보자 라고 생각을 했어요

742
00:33:38,670 --> 00:33:39,790
처음으로 생각한 건데

743
00:33:39,790 --> 00:33:43,310
라벨링 없이 할 수 있는 방법은 없나 해서

744
00:33:43,310 --> 00:33:45,230
조금 부정아 카드라도 대충

745
00:33:45,230 --> 00:33:47,220
라벨링 하는 거를 생각을 해 봤어요

746
00:33:47,220 --> 00:33:49,070
가설이 제가 새로운 건 이 사람은

747
00:33:49,070 --> 00:33:51,360
잘 바뀌지 않을 거 같아 였어요

748
00:33:51,360 --> 00:33:52,510
한 사람의 정체

749
00:33:52,510 --> 00:33:55,620
그렇게 내가 극단적으로 밖에서 아닌 거 같다

750
00:33:55,620 --> 00:33:57,090
여러 댓글이 보수

751
00:33:57,090 --> 00:33:59,810
혹은 진보로 라벨링된 사람의 댓글이

752
00:33:59,810 --> 00:34:01,640
그러면은 그 사람은 약간 보수

753
00:34:01,640 --> 00:34:06,120
친화적 혹은 진보 친화적 정당 친화적 인 게 아닐까

754
00:34:06,120 --> 00:34:10,250
가설에서 우리가 열어 댓글 달게

755
00:34:10,250 --> 00:34:12,230
때문에 노이즈가 굉장히 많을 거라고

756
00:34:12,230 --> 00:34:14,200
생각을 할 수 있어요

757
00:34:14,200 --> 00:34:15,430
그래서 베이스라인 모델로

758
00:34:15,430 --> 00:34:19,870
사색이 직접 라면 한 개 더 네 한 가지를 진행을 해 봤어요

759
00:34:19,870 --> 00:34:21,850
굉장히 심한 커뮤니티들이 있잖아요

760
00:34:21,850 --> 00:34:25,090
계속 거기에 있는 정치 글들을 가져와 정치

761
00:34:25,090 --> 00:34:27,140
섹시하네 제목을 가져와서

762
00:34:27,140 --> 00:34:29,870
그금 데이터를 트레이닝 시켜 놨어요

763
00:34:29,870 --> 00:34:35,000
데이터셋은 정치적 성향이 심한 곳에서 제목 3만 개

764
00:34:35,000 --> 00:34:37,500
2만 7천 개 정도의 가져왔고

765
00:34:37,500 --> 00:34:39,810
그래서 어쨌든 그래서 못 해 쓰는 거니까

766
00:34:39,810 --> 00:34:42,820
최신 모델 서버 차에서 벨트를 가져서 봤어요

767
00:34:42,820 --> 00:34:44,080
성능이 근데 너무 잘

768
00:34:44,080 --> 00:34:48,370
나오는 거예요 Trail 90구경

769
00:34:48,370 --> 00:34:50,820
그리고 밸리데이션 2교시가 0.88 이었어요

770
00:34:50,820 --> 00:34:52,970
세상에 이렇게 수고하고

771
00:34:52,970 --> 00:34:55,900
높으면 당연히 안 좋은 일이 일어나고 있다는 뜻이다

772
00:34:55,900 --> 00:34:58,500
체제의 댓글 데이터에 적용해봤습니다

773
00:34:58,500 --> 00:35:00,890
안 좋아요 정말 성능이 안 좋게 나옵니다

774
00:35:00,890 --> 00:35:03,410
모든 거를 보스로 생각 생각하고 있어요

775
00:35:03,410 --> 00:35:06,860
사실 제목 스타일이나 댓글 스타일이랑 굉장히 달라요

776
00:35:06,860 --> 00:35:08,430
우리가 기사 생각만 해 봐도

777
00:35:08,430 --> 00:35:11,350
제목은 김미정 이펙트만 간결하게 들어가 있는데

778
00:35:11,350 --> 00:35:14,570
댓글은 우리가 굉장히 많은 다른 오타 데도 있고

779
00:35:14,570 --> 00:35:15,910
이런 특성이 있기 때문에

780
00:35:15,910 --> 00:35:19,420
그런 거 해서 많이 차이가 나타나고 있다

781
00:35:19,420 --> 00:35:21,710
그래서 다른 방식으로 손으로 할 수밖에 없었어요

782
00:35:21,710 --> 00:35:25,470
라벨링 최대한 줄여서 해 보자

783
00:35:25,470 --> 00:35:27,810
아까 전에 세웠던 가서 온라인에서 사람성향

784
00:35:27,810 --> 00:35:29,120
그렇게 사회 바뀌지 않을 거다

785
00:35:29,120 --> 00:35:30,430
페르소나 그대로 일 거다

786
00:35:30,430 --> 00:35:31,860
나는 수영 가자

787
00:35:31,860 --> 00:35:35,520
그래서 앱 명 이상이 유저들의 라벨링을 하고 있어

788
00:35:35,520 --> 00:35:38,640
둘이 데이터를 끄라고 끌어와 보자 라고 한 거죠

789
00:35:38,640 --> 00:35:40,520
그리고 아웃라인의 몇 번 이상 되면

790
00:35:40,520 --> 00:35:43,000
제 데이터도 같이 확인해 보고요

791
00:35:43,000 --> 00:35:44,960
그리고 모델에는 잡히지 않았잖아

792
00:35:44,960 --> 00:35:46,250
기존에 탐지된 유조아

793
00:35:46,250 --> 00:35:48,430
비슷한 패턴에 보이는 K3 있을까

794
00:35:48,430 --> 00:35:49,790
라는 생각도 해 봤고요

795
00:35:49,790 --> 00:35:53,610
이런 방식을 통해서는 굉장히 제가 실제로 봤던 데이터에 비해서

796
00:35:53,610 --> 00:35:58,520
굉장히 다양한 데이터를 데이터 앰플리파이어의 해 줄 수 있어

797
00:35:58,520 --> 00:36:00,230
6일 제가 라벨링 한 거래

798
00:36:00,230 --> 00:36:03,020
그룹 방에서 목록에 한번 세워 놓은 건데요

799
00:36:03,020 --> 00:36:04,260
저 빨간색으로 되어 있네

800
00:36:04,260 --> 00:36:06,350
제일 첫 번째로 저같은 경우는 제가 라벨링

801
00:36:06,350 --> 00:36:10,000
한 2500개 댓글 데에서 일하고

802
00:36:10,000 --> 00:36:14,600
라벨링된 댓글이 무료 달려 있었어요

803
00:36:14,600 --> 00:36:17,900
그래서 이유 저같은 경우는 미니 이래 가까우니까

804
00:36:17,900 --> 00:36:19,830
좀 더 보수적이라 가깝지 않을까

805
00:36:19,830 --> 00:36:21,210
사실에 이것도 추정입니다

806
00:36:21,210 --> 00:36:22,790
추정에 완전 추석인데

807
00:36:22,790 --> 00:36:25,980
그리고 일이 가까우면 보수의 가까울 거 같고

808
00:36:25,980 --> 00:36:29,500
-1 갈 거면 이사하는 진보의 가까울 것 같다 라고

809
00:36:29,500 --> 00:36:33,310
생각을 가설에 세우는 맞아 순전히 가설입니다

810
00:36:33,310 --> 00:36:35,000
실제로 저 파란색으로 되어 있는지

811
00:36:35,000 --> 00:36:36,390
저같은 경우는 -

812
00:36:36,390 --> 00:36:40,830
1만 6 나와 있는 K3VS 다닐 거야

813
00:36:40,830 --> 00:36:42,260
실제로 제가 2500개

814
00:36:42,260 --> 00:36:44,980
랜덤샘플링 에서 라벨링 해봤을때 구스 대진고

815
00:36:44,980 --> 00:36:48,850
비율이 약 7 대 3 정도였는데요 이 사람들이 과외쌤

816
00:36:48,850 --> 00:36:49,840
2019년 1월 1일

817
00:36:49,840 --> 00:36:53,320
자 데이터부터 모두 챙겨서 가져와 봐 댓글 단

818
00:36:53,320 --> 00:36:55,940
비율은 약 9대 이래 당했습니다

819
00:36:55,940 --> 00:36:58,220
증거의 댓글이 굉장히 적용 편이더라고요

820
00:36:58,220 --> 00:36:59,840
물론 제가 라벨링 돼 있는 게

821
00:36:59,840 --> 00:37:01,560
바이러스가 걸렸을 수도 있어요

822
00:37:01,560 --> 00:37:02,660
그래서 결과적으로 우리가 이거

823
00:37:02,660 --> 00:37:05,330
트레이닝 하려면은 언더샘플링 안 돼

824
00:37:05,330 --> 00:37:07,640
이때 29,000 교사실 순 없고

825
00:37:07,640 --> 00:37:10,230
수량이 적은 3,000개의 맞춰 내려서

826
00:37:10,230 --> 00:37:11,860
진행을 해야 돼요

827
00:37:11,860 --> 00:37:14,200
그래도 일단은 시작을 할 수 있는 데이터

828
00:37:14,200 --> 00:37:16,260
라는 점에서 의미는 있었어요

829
00:37:16,260 --> 00:37:19,050
그래서 신고 유저가 댓글이 적으니까 아

830
00:37:19,050 --> 00:37:21,720
그러면 진보 사는데 좀 더 찾아 보자

831
00:37:21,720 --> 00:37:24,820
그래 봤자 그래서 진보 뉴스랑

832
00:37:24,820 --> 00:37:28,540
그러면 보수뉴스 왜 댓글이 달리는 상형이 다를까

833
00:37:28,540 --> 00:37:30,720
이건 아직 진행 중인 연구 인데요

834
00:37:30,720 --> 00:37:33,500
보소 뉴스에 달리는 댓글이 대부분 고수라고

835
00:37:33,500 --> 00:37:36,300
이건 가설이 지금 저녁 증명되지 않은 부분인데요

836
00:37:36,300 --> 00:37:40,120
이런 가설을 1번 3번 아직 연구 진행 중인데

837
00:37:40,120 --> 00:37:42,870
결국은 필요한 거는 사실 보수 진보 클래식 봐요

838
00:37:42,870 --> 00:37:44,500
혹은 그 더 다양한 보수

839
00:37:44,500 --> 00:37:47,160
진보 중독은 장별로 되어 있는

840
00:37:47,160 --> 00:37:49,600
그런 클래시파이어 가 필요한 가자

841
00:37:49,600 --> 00:37:52,820
실제로 지금 뉴스에 댓글도 좀 더 라벨링하기 위해서

842
00:37:52,820 --> 00:37:54,120
현재까지 1만개 정도를

843
00:37:54,120 --> 00:37:57,820
추가적으로 라벨링을 진행을 하고 있고요

844
00:37:57,820 --> 00:37:58,940
그래서 일에 통해서 계곡

845
00:37:58,940 --> 00:37:59,970
알고자 하는 거는

846
00:37:59,970 --> 00:38:03,470
여자의 성향을 좀 더 자 있을 수 있는 방법이 없으니까

847
00:38:03,470 --> 00:38:05,400
나는 거예요

848
00:38:05,400 --> 00:38:08,650
유저를 태경 웹 서비스의 만들기를 했습니다

849
00:38:08,650 --> 00:38:12,720
제가 아까 전에 만들어 보여드렸던 아울라 여드레 찾는 금오랜드

850
00:38:12,720 --> 00:38:14,270
그것들의 매번 데이터에서

851
00:38:14,270 --> 00:38:15,640
제가 직접 게 파이썬

852
00:38:15,640 --> 00:38:18,800
주피터 코드를 돌리면서 확인하려는 굉장히 오래

853
00:38:18,800 --> 00:38:20,700
그리고 데이터베이스 쌓는다고 해도

854
00:38:20,700 --> 00:38:23,980
sql 번 가져다 쓰는 것도 일이겠죠

855
00:38:23,980 --> 00:38:27,480
그래서 웹에서 좀 더 인터렉티브하게 사용자들이 가져다가

856
00:38:27,480 --> 00:38:30,920
달 수 있는 시스템에 만들고자 생각을 했어요

857
00:38:30,920 --> 00:38:33,500
그래서 창고 앞 유의사항을 기초

858
00:38:33,500 --> 00:38:34,790
분석모델의 저장을 하고

859
00:38:34,790 --> 00:38:38,700
다른 데이터 분석 모드 를 초과할 수 있도록 설계를 한 다음에

860
00:38:38,700 --> 00:38:41,150
저 나와 있는 것처럼 택배 같은 방식으로

861
00:38:41,150 --> 00:38:43,420
이제 이 사용자는 어떤 사용자 달라고

862
00:38:43,420 --> 00:38:46,190
사용자들이 참여할 수 있는 형식으로 진행했고

863
00:38:46,190 --> 00:38:48,710
만약에 사용자들이 이 태블릿 알면 알수록

864
00:38:48,710 --> 00:38:50,880
이와 비슷한 유저의 패턴의 분석을 해서

865
00:38:50,880 --> 00:38:53,920
비슷한 유저들이 이런 유저들이 인데 이 유저들을 태경

866
00:38:53,920 --> 00:38:54,900
알겠어요 라고 하는

867
00:38:54,900 --> 00:38:58,620
추천시스템의 개발에 생각을 하고 있음

868
00:38:58,620 --> 00:38:59,100
계속 결과

869
00:38:59,100 --> 00:39:00,920
좀 이런 거네 사람들이

870
00:39:00,920 --> 00:39:03,130
시민들의 참여를 필요로 하는 거예요

871
00:39:03,130 --> 00:39:05,520
사람들이 참여할수록 정확도가 높아지고

872
00:39:05,520 --> 00:39:08,800
일정에 추천시스템 과 같은 개념인 것이다

873
00:39:08,800 --> 00:39:11,590
태그된 유저별로 클러스터링의 진행을 해 주고

874
00:39:11,590 --> 00:39:13,730
새로운 일정 이상이 되면

875
00:39:13,730 --> 00:39:15,070
새로운 모델을 학습하는

876
00:39:15,070 --> 00:39:17,000
이런 방식을 생각을 하고 있습니다

877
00:39:17,000 --> 00:39:20,900
왜냐하면 모델은 시간이 지나면 늘 그니까요

878
00:39:20,900 --> 00:39:22,800
저 이제 마지막으로 하는 말인데요

879
00:39:22,800 --> 00:39:26,080
우리가 보는 사회에는 결과적으로 우리가 볼 수 있는 범위

880
00:39:26,080 --> 00:39:27,580
내 사이예요

881
00:39:27,580 --> 00:39:29,890
필터버블 레이스가 아니다고 하더라도

882
00:39:29,890 --> 00:39:32,610
사람이 볼 수 있는 거는 제 1대 있어요

883
00:39:32,610 --> 00:39:34,240
따라서 사람이 하나

884
00:39:34,240 --> 00:39:38,470
보는 거 대신에 자동화된 작업으로 해결하는게 필요한다

885
00:39:38,470 --> 00:39:41,160
우리가 모두가 좀 더 신경을 쓸 수 있도록 하는

886
00:39:41,160 --> 00:39:43,450
환경 역시 데이터 분석을 하는 것

887
00:39:43,450 --> 00:39:45,440
그 이상으로도 필요하고요

888
00:39:45,440 --> 00:39:47,810
개발자가 아니 우리 같은 사람들이 아니라

889
00:39:47,810 --> 00:39:50,330
일반 시민들이 보고도 참여할 수 있도록 하는

890
00:39:50,330 --> 00:39:53,630
플러스는 안 되는 것도 필요합니다

891
00:39:53,630 --> 00:39:58,250
발표회 여기까지고요 들어 주셔서 하지만

892
00:39:58,250 --> 00:39:59,780
사실 발표는 끝나지 않았는데

893
00:39:59,780 --> 00:40:01,180
사실에 저에게 최근에

894
00:40:01,180 --> 00:40:04,050
굉장히 슬픈 이야기가 하나가 있었어요

895
00:40:04,050 --> 00:40:06,540
일단 크레딧으로 연결해 같이 진행해 주시면

896
00:40:06,540 --> 00:40:07,830
유튜브에 받은 교수님

897
00:40:07,830 --> 00:40:09,780
그리고 제 교수님 그리고

898
00:40:09,780 --> 00:40:13,630
카이스트 교수님은 감사의 말씀 드리고요

899
00:40:13,630 --> 00:40:17,100
근데 사실은 한 가지 개인적인 사소한 이신데요

900
00:40:17,100 --> 00:40:20,350
제가 저번 주 타이틀을 넣었는데

901
00:40:20,350 --> 00:40:23,640
서류 1차에서 떨어졌어요

902
00:40:23,640 --> 00:40:27,700
왜 그래 행복하게 연구하는 nff 소셜데이터

903
00:40:27,700 --> 00:40:30,990
연관 앱을 추천해 봤습니다

904
00:40:30,990 --> 00:40:33,580
제가 편히 여기까지가 들어 주셔서 정말 감사합니다
