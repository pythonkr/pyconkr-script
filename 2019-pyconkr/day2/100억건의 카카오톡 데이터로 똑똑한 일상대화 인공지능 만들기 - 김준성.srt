1
00:00:00,000 --> 00:00:02,950
안녕하세요 오늘 발표를 하게 된 스케줄을 머신러닝엔지니어

2
00:00:02,950 --> 00:00:09,940
김준성 이라고 합니다

3
00:00:09,940 --> 00:00:12,680
오늘은 백악관 카카오톡 데이터로 똑똑하니

4
00:00:12,680 --> 00:00:15,650
상대원 인공지능만들기 이라는 주제로 재미있는 주제로

5
00:00:15,650 --> 00:00:19,010
여러분들께 발표를 드리려고 합니다

6
00:00:19,010 --> 00:00:20,890
저는 지금까지 mlb

7
00:00:20,890 --> 00:00:21,860
그리고 태화 분야에서

8
00:00:21,860 --> 00:00:24,110
연구개발을 2년 동안 진행을 했고

9
00:00:24,110 --> 00:00:26,740
미스터빈 아틀라스랩 그다음에 네이버 클로바

10
00:00:26,740 --> 00:00:30,230
인턴십을 거쳐서 지금은 핑퐁 이라는 집에서 귀엽고

11
00:00:30,230 --> 00:00:32,150
그리고 사람 같은 인공지능은 만들기에

12
00:00:32,150 --> 00:00:34,400
여러가지 연안개발 하고 있습니다

13
00:00:34,400 --> 00:00:37,960
약간 조금 디엠 아이 로 설명을 드리면 되게 있으니깐

14
00:00:37,960 --> 00:00:40,700
파이토치를 굉장히 좋아해서 관리한다면

15
00:00:40,700 --> 00:00:42,790
오픈소스 프로젝트를 진행하고 있어서

16
00:00:42,790 --> 00:00:45,000
자기 기타 의지가 보시면 저 파이트

17
00:00:45,000 --> 00:00:47,460
차 관련된 다양한 주제들에

18
00:00:47,460 --> 00:00:50,790
프로젝트를 보실 수 있을 것 같습니다

19
00:00:50,790 --> 00:00:53,620
먼저 오늘 발표 있듯이 일상대화

20
00:00:53,620 --> 00:00:56,750
인공지능에 대해서 다루게 될 거 같은 오늘 발표회

21
00:00:56,750 --> 00:00:58,270
본론으로 들어갈게 앞서서

22
00:00:58,270 --> 00:01:01,630
앞으로 계속 언급하게 내일 상대가 인공지능이 무엇인지

23
00:01:01,630 --> 00:01:04,170
그리고 상대가 인공지능 기술의 왜 어렵고

24
00:01:04,170 --> 00:01:05,840
그리고 오늘 어떤 문제를 풀게 될지

25
00:01:05,840 --> 00:01:09,390
여러분들께 설명을 먼저 드리도록 하겠습니다

26
00:01:09,390 --> 00:01:13,360
먼저 우리가 요즘 주위에서 자주 볼 수 있는 구글 어시스턴트야

27
00:01:13,360 --> 00:01:16,380
아니면 클로바 처럼 AI 인공 지능을 한번 볼까요

28
00:01:16,380 --> 00:01:20,350
우리는 세계 날씨 알려 줘 배송 일자 변경 해 줘

29
00:01:20,350 --> 00:01:24,900
질문이나 명령을 통해서 사람들이 해야 할 일들을 대신하고

30
00:01:24,900 --> 00:01:27,820
이런 형태의 인공지능은 이제 기술 기능

31
00:01:27,820 --> 00:01:30,950
대화 인공지능이라고 이야기를 하는데요

32
00:01:30,950 --> 00:01:33,790
그와 반대로 일상대화 인공지능은 클로바

33
00:01:33,790 --> 00:01:36,850
나 구글 어시스턴트한테 뭐 뭐 해 줘

34
00:01:36,850 --> 00:01:37,270
알려 줘

35
00:01:37,270 --> 00:01:40,340
사람 명령이나 질문을 하는 인공지능이 아니라

36
00:01:40,340 --> 00:01:43,020
친구처럼 되게 자유로운 대화를 나눌 수 있는 사람

37
00:01:43,020 --> 00:01:45,080
같은 인공지능은 이야기합니다

38
00:01:45,080 --> 00:01:46,590
맞지 인공지능 고양이

39
00:01:46,590 --> 00:01:49,810
저기 도라에몽이랑 친구가 엄마한테 혼내기도 하고

40
00:01:49,810 --> 00:01:54,660
말도 걸고 위로도 하고 얘기를 들어주는 거 어

41
00:01:54,660 --> 00:01:58,500
그러면 기능 대화 상대가 기능

42
00:01:58,500 --> 00:02:02,060
기술적 난이도에 없어서 기능 대화 인공지능을 만드는데

43
00:02:02,060 --> 00:02:04,340
그런 어떤 노력을 하고 얼마나 어려울까요

44
00:02:04,340 --> 00:02:07,370
기능 대화는 해당분야에 관련 명령이나

45
00:02:07,370 --> 00:02:09,470
아니면 질문에만 동작 하기 때문에

46
00:02:09,470 --> 00:02:12,100
사용자가 어떤 어떤 질문을 할지

47
00:02:12,100 --> 00:02:14,370
예상되는 범위가 어느정도 한정적입니다

48
00:02:14,370 --> 00:02:17,180
그렇기 때문에 개발자들은 해당 분야에 대한 최적화

49
00:02:17,180 --> 00:02:18,200
되어 있는 책

50
00:02:18,200 --> 00:02:20,930
보다 구체적인 시나리오를 만들

51
00:02:20,930 --> 00:02:24,270
앞으로 필요한 데이터 역시 실제 고객 상담 데이터나

52
00:02:24,270 --> 00:02:27,920
아니면 모르겠으면 인터넷에서 검색해서

53
00:02:27,920 --> 00:02:28,740
결과를 알려 드립니다

54
00:02:28,740 --> 00:02:30,570
이렇게 됐다 하는 경우도 있잖아요

55
00:02:30,570 --> 00:02:32,310
그래서 되게 어느정도

56
00:02:32,310 --> 00:02:35,260
어느 정도 사용자의 질문에 대해서 예측이 가능하고

57
00:02:35,260 --> 00:02:39,180
또 사용자가 질문할 범위가 굉장히 작습니다

58
00:02:39,180 --> 00:02:41,430
그에 반해 상대가 인공지능은 정말

59
00:02:41,430 --> 00:02:42,990
정말 훨씬 더 어려워요

60
00:02:42,990 --> 00:02:46,090
그 이유는 사람들이 어떤 말을 할 수가 없기 때문에

61
00:02:46,090 --> 00:02:46,830
인데요

62
00:02:46,830 --> 00:02:50,170
사람은 상황이랑 감정 시간

63
00:02:50,170 --> 00:02:53,160
그리고 대화 어떤 어떤 감정이 나경원에

64
00:02:53,160 --> 00:02:56,280
따라서 대화에 몸매 굉장히 많이 달라지고

65
00:02:56,280 --> 00:02:59,120
또 일하면 무한한 문맥에 대한 답변 역시

66
00:02:59,120 --> 00:03:01,560
무한한 경우의 수를 갖겠습니다

67
00:03:01,560 --> 00:03:05,800
일상대화 인공지능은 인공지능에서 시나리오를 안 되거나

68
00:03:05,800 --> 00:03:07,490
아니면 간단한 모델 만들어서

69
00:03:07,490 --> 00:03:11,300
학습하는 방식으로는 절대 이 문제를 풀 수가 없어요

70
00:03:11,300 --> 00:03:14,710
이런 어려움 때문에 지금까지 일상대화 차이연구

71
00:03:14,710 --> 00:03:18,890
돼지고기는 대해서 굉장히 연두 되지 못해 활발하게 연구개발이나

72
00:03:18,890 --> 00:03:21,720
아니면 실제 서비스로 사용되는 차례대로

73
00:03:21,720 --> 00:03:26,140
많이 나오지 않는 문제점을 문제점이 있었습니다

74
00:03:26,140 --> 00:03:29,470
그럼 이 문제를 풀 수 있는 유일한 방법은 뭘까요

75
00:03:29,470 --> 00:03:32,280
바로 사람처럼 깊은 이해와

76
00:03:32,280 --> 00:03:33,600
추론능력을 가질 수 있는

77
00:03:33,600 --> 00:03:36,590
딥러닝 모델을 사람처럼 만드는 방법입니다

78
00:03:36,590 --> 00:03:39,370
일상 대화해서 는 모델을 다양한 경험을 통해

79
00:03:39,370 --> 00:03:40,780
사람처럼 이해하고

80
00:03:40,780 --> 00:03:43,010
또 사람을 방에서 잘 대답할 수 있도록

81
00:03:43,010 --> 00:03:44,350
만들어 줘야 하는데

82
00:03:44,350 --> 00:03:45,980
마치 어린 아이들이 유치원에서

83
00:03:45,980 --> 00:03:48,690
친구들과 대화를 하면서 되게 다양한 경험을 하고

84
00:03:48,690 --> 00:03:51,360
또 그 과정에서 어떻게 더 대화를 하는 것이 좋은 것인지

85
00:03:51,360 --> 00:03:53,470
배우는 과장처럼 딥러닝 역시

86
00:03:53,470 --> 00:03:54,780
다양한 경험과 또

87
00:03:54,780 --> 00:03:58,590
좋은 학습 방법을 통해 대화란 게 무엇이고

88
00:03:58,590 --> 00:04:01,010
또 어떻게 내가 대화를 하는 게 잘 하는 것이고

89
00:04:01,010 --> 00:04:05,140
나는 그런 추상적인 개념을 정말 딥하게 배워야 되는 문제로

90
00:04:05,140 --> 00:04:07,690
이걸 풀어 주는 것밖에 방법이 없습니다

91
00:04:07,690 --> 00:04:09,040
근데 이제 이런 일

92
00:04:09,040 --> 00:04:11,470
상대가 인공 지능이 연구되지 못했던 물론

93
00:04:11,470 --> 00:04:15,620
이런 난이도도 또 하나의 이유는 데이터가 없어요

94
00:04:15,620 --> 00:04:17,730
외부에서 연구용으로 공개되거나

95
00:04:17,730 --> 00:04:21,600
아니면 실제 기업용으로 사용되는 연구 데이터가

96
00:04:21,600 --> 00:04:25,570
사용자가 막 조금 시간과 돈을 들여서 누구 시켜서

97
00:04:25,570 --> 00:04:26,630
막 레이블링 하거나

98
00:04:26,630 --> 00:04:29,270
아니면 실제대화 데이터를 인위적으로 만들어서

99
00:04:29,270 --> 00:04:30,010
학습을 시켜야 되는데

100
00:04:30,010 --> 00:04:31,930
그러다 보면 엄청나게

101
00:04:31,930 --> 00:04:34,280
다양한 경우의 수를 다 파악할 수는 없잖아요

102
00:04:34,280 --> 00:04:37,670
어떻게 때문에 그런 데이터가 부족한 역시 1상자

103
00:04:37,670 --> 00:04:43,100
인공지능에서 인공지능 2차연구 되지 못했던 메인 뉴스

104
00:04:43,100 --> 00:04:46,510
하지만 제가 있는 핑퐁 팀에게는 약 한국어의 대박 번에

105
00:04:46,510 --> 00:04:48,640
카톡 데이터 일본어의 2억원의 정도에

106
00:04:48,640 --> 00:04:50,340
라인 데이터를 보여 하고 있어요

107
00:04:50,340 --> 00:04:54,900
우리는 이 정도의 데이터양을 사람이 일평생 다 입지도 못하고

108
00:04:54,900 --> 00:04:58,130
많은 대여 페어데이터 인데요

109
00:04:58,130 --> 00:05:00,970
이렇게 사람들이 실제로 나는 대량의 데이터가 있다면

110
00:05:00,970 --> 00:05:02,680
사람이 언어를 학습할때

111
00:05:02,680 --> 00:05:06,340
필요로 하는 수양관에 경험을 대체할 수 있는 건 당연하고

112
00:05:06,340 --> 00:05:08,910
저희가 데이터가 단순히 몇천명

113
00:05:08,910 --> 00:05:10,020
몇백명의 데이터가 아니라

114
00:05:10,020 --> 00:05:12,690
몇십만명의 데이터를 뭔 고기 때문에

115
00:05:12,690 --> 00:05:15,400
정말 다양한 사람의 경험과 사고방식

116
00:05:15,400 --> 00:05:18,740
대화방식 아니 문제들을 학습할 수 있어서

117
00:05:18,740 --> 00:05:20,620
인공지능이 진짜 사람처럼 이해하는데

118
00:05:20,620 --> 00:05:25,000
정말 많은 도움을 줄 수 있는 데이터를 갖고 있습니다

119
00:05:25,000 --> 00:05:26,720
자 그러면 데이터도 있겠다

120
00:05:26,720 --> 00:05:29,530
본격적으로 어떻게 인공지능이 대화를 할 수 있는지

121
00:05:29,530 --> 00:05:31,120
한번 알아보도록 하겠습니다

122
00:05:31,120 --> 00:05:33,500
이번 3천에 키포인트는 어떻게

123
00:05:33,500 --> 00:05:37,950
그대와 의미와 문맥을 이해할 수 있는 모델을 만드는 것이네

124
00:05:37,950 --> 00:05:39,910
앞으로 계속 나올 단어라서

125
00:05:39,910 --> 00:05:42,410
제가 한번 설명해드리면 매출액이 언더스탠딩

126
00:05:42,410 --> 00:05:43,270
이라고 줄일 수 있고

127
00:05:43,270 --> 00:05:47,830
좀 더 줄여서 nlu 모델이라고 얘기를 합니다

128
00:05:47,830 --> 00:05:50,510
혹시 열 살짜리 아이가 수능

129
00:05:50,510 --> 00:05:53,050
국어 문제를 푸는 걸 보신적 있으신가요

130
00:05:53,050 --> 00:05:55,850
천재 방송에도 나을 수도 있겠지만

131
00:05:55,850 --> 00:05:57,510
10살 정도 되는 어린 아이가 수능

132
00:05:57,510 --> 00:06:00,180
국어 문제를 푸는 데는 굉장히 어렵습니다

133
00:06:00,180 --> 00:06:03,930
물론 수능 문제를 푸는 게 없어서 이기도 하지만

134
00:06:03,930 --> 00:06:07,140
근본적으로는 언어에 대한 이해도가 낮기 때문이다

135
00:06:07,140 --> 00:06:09,620
아직은 다양한 글이나 아니면 다양한 경험

136
00:06:09,620 --> 00:06:14,540
문맥에 대한 다양한 베리어스 들을 경험해 보지 못했기 때문에

137
00:06:14,540 --> 00:06:17,720
자연스럽게 어려운 언어로 쓰여져있는 수능국어문제

138
00:06:17,720 --> 00:06:20,290
당연히 풀기가 어려웠습니다

139
00:06:20,290 --> 00:06:24,040
그렇기 때문에 언어의 이런 것처럼 사람도 언어 이해도가 없다면

140
00:06:24,040 --> 00:06:25,650
어떤 문제를 풀지 못하는 것처럼

141
00:06:25,650 --> 00:06:28,240
인공지능이 없이 언어에 대한 이해가 없다면

142
00:06:28,240 --> 00:06:31,030
그 문제를 풀 김팔수 있더라도 잘 풀지

143
00:06:31,030 --> 00:06:33,700
저것도 깊이 있는 이해를 할 수 없게 되어

144
00:06:33,700 --> 00:06:34,830
그래서 뭐 생각인 거 사는 거

145
00:06:34,830 --> 00:06:36,540
굉장히 유사하기 때문에

146
00:06:36,540 --> 00:06:40,300
여러 연구를 통해서 언어에 대한 이해를 먼저 학습하고

147
00:06:40,300 --> 00:06:41,760
그 이후에 실전문제를

148
00:06:41,760 --> 00:06:42,780
풀었어요

149
00:06:42,780 --> 00:06:46,460
바로 단순히 문제를 풀도록 학습 했을 때는 했을 때

150
00:06:46,460 --> 00:06:47,330
언어에 대한 이해를

151
00:06:47,330 --> 00:06:48,750
먼저 한 모델이 훨씬 더

152
00:06:48,750 --> 00:06:53,090
좋은 성능을 가는 걸 볼 수 있었습니다

153
00:06:53,090 --> 00:06:56,980
그러면 이제 이제 카카오톡 데이터 대화 데이터를 바꿔서

154
00:06:56,980 --> 00:06:58,890
어떻게 저희가 학습을 할 수 있을까요

155
00:06:58,890 --> 00:07:00,480
먼저 저희도 역시

156
00:07:00,480 --> 00:07:03,670
머신러닝의 언어의 이해도를 최고로 끌어올릴 수 있는 모델

157
00:07:03,670 --> 00:07:05,170
먼저 학습을 하게 됩니다

158
00:07:05,170 --> 00:07:06,710
대법관의 대화 데이터를 이용해서

159
00:07:06,710 --> 00:07:09,270
언어에 대한 경험을 최대한 모델이 이해할 수 있도록

160
00:07:09,270 --> 00:07:11,010
하고

161
00:07:11,010 --> 00:07:12,480
그 이후에 이렇게 학습 어

162
00:07:12,480 --> 00:07:15,320
너 이해 모델 모델 을 이용해서

163
00:07:15,320 --> 00:07:17,360
실제 응용된 문제를 풀게 됩니다

164
00:07:17,360 --> 00:07:20,330
우리 대화 시스템에서는 어떻게 대답할 수 있을지

165
00:07:20,330 --> 00:07:22,510
나는 주제가 되겠죠

166
00:07:22,510 --> 00:07:25,190
이렇게 오늘은 이 두 가지가 어떻게 이루어지고

167
00:07:25,190 --> 00:07:26,260
또 각각의 모델 부족

168
00:07:26,260 --> 00:07:30,050
어떻고 어떻게 학습되어 있는지를 알려 드리려고 하는데

169
00:07:30,050 --> 00:07:33,340
먼저 그러면 어떻게 언어를 이해하는 학습하는 모델

170
00:07:33,340 --> 00:07:35,750
언어를 학습하고 이해하는 모델 만들 수 있을지

171
00:07:35,750 --> 00:07:38,850
여러분들께 알려 드리려고 합니다

172
00:07:38,850 --> 00:07:40,620
지금까지 그러면 분

173
00:07:40,620 --> 00:07:43,480
nlu 모델을 먼저 한번 살펴 보려고 하는데요

174
00:07:43,480 --> 00:07:45,170
여러분들도 잘 하실 수도 있고

175
00:07:45,170 --> 00:07:49,070
모르실 수도 있을 것 같은데 가장 유명하고

176
00:07:49,070 --> 00:07:51,200
또 여러분들이 잘 아실 수 있는 내일 못 자면

177
00:07:51,200 --> 00:07:53,370
하나의 단어에 대해서 하나의 배터리

178
00:07:53,370 --> 00:07:56,990
뿜는 워드투백 이라는 라이브러리를 잘 아실 것 같아

179
00:07:56,990 --> 00:08:00,830
어디 있어 내가 주변 단어들을 위치를 학습을 해서

180
00:08:00,830 --> 00:08:03,520
각각의 단어의 의미를 학습하는 방법으로

181
00:08:03,520 --> 00:08:06,700
이제 언어에 대해서 이해를 하게 되는데요 이 모델은

182
00:08:06,700 --> 00:08:08,940
진심이라는 라이브러리를 통해서

183
00:08:08,940 --> 00:08:11,670
많은 사람들에게 사용을 되고 되고 있었고

184
00:08:11,670 --> 00:08:14,560
또 머신러닝 지식이 없어서 개발자분들 더 쉽게 이해하고

185
00:08:14,560 --> 00:08:16,020
또 사용할 수 있었기 때문에

186
00:08:16,020 --> 00:08:20,230
다양한 분야에서 많은 응용이 이루어졌습니다

187
00:08:20,230 --> 00:08:21,790
그리고 이 워드투백 을 이용해서

188
00:08:21,790 --> 00:08:24,770
그런 어떤 한 문장에 대한 의미를 치료할 때

189
00:08:24,770 --> 00:08:26,920
각각 단어밖에 출연을 못 하기 때문에

190
00:08:26,920 --> 00:08:28,580
단어에 대한 벡터를 뽑고

191
00:08:28,580 --> 00:08:30,380
그게 단어에 대한 백터의 평균 그래서

192
00:08:30,380 --> 00:08:35,300
그 문장이 의미를 이해하는 방식으로 진행하였습니다

193
00:08:35,300 --> 00:08:37,960
이제 그 1층 102호 나온 논문이나

194
00:08:37,960 --> 00:08:40,400
아니면 영국에서 가장 대표적으로 올 수 있는데

195
00:08:40,400 --> 00:08:41,250
뭐 인데요

196
00:08:41,250 --> 00:08:44,320
알면은 문장단위 몇 퍼센트 스테이션 이라고 해요

197
00:08:44,320 --> 00:08:48,540
그래서 어제 다 단어별로 의미를 파악한다고 하면

198
00:08:48,540 --> 00:08:51,720
뭐 같은 경우는 그 문장에 대해서 어떤 의미인지

199
00:08:51,720 --> 00:08:57,350
또 어떤 단순히 각 다날 배터리 평균 하는 게 아니라

200
00:08:57,350 --> 00:08:58,560
lstm 구조를 이용해서

201
00:08:58,560 --> 00:09:01,520
앞뒤가 네 단어 관계를 반영하는 모델이 있습니다

202
00:09:01,520 --> 00:09:04,110
이렇게 하면 단순히 단어의 의미 뿐만 아니라

203
00:09:04,110 --> 00:09:05,890
앞뒤 간의 관계

204
00:09:05,890 --> 00:09:07,880
그리고 문맥을 반영할 수 있게 되어서

205
00:09:07,880 --> 00:09:08,950
월드벳 보다 훨씬 더

206
00:09:08,950 --> 00:09:10,390
좋은 의미를 파악할 수 있는

207
00:09:10,390 --> 00:09:13,090
모델을 만들 수 있겠습니다

208
00:09:13,090 --> 00:09:16,600
하지만 이렇게 소개해 드린 두 모델 역시 어

209
00:09:16,600 --> 00:09:17,620
우리가 갖고 있는 대화

210
00:09:17,620 --> 00:09:20,880
데이터를 사용하기에는 굉장히 부족한 부분이 많았습니다

211
00:09:20,880 --> 00:09:22,990
첫 번째로는 이렇게 부족한 부분이

212
00:09:22,990 --> 00:09:26,540
첫 번째로는 문장에 대한 깊은 이해를 하지 못해요

213
00:09:26,540 --> 00:09:28,450
그러니깐 동명동 이랬으면

214
00:09:28,450 --> 00:09:30,570
동일한 문장을 갖고 있는

215
00:09:30,570 --> 00:09:31,610
동일한 의미를 갖고 있는

216
00:09:31,610 --> 00:09:35,300
문장 두 개가 있다고 가정했을때 의미가 갔다

217
00:09:35,300 --> 00:09:38,100
오라고 출연하려면 벡터가 비슷해야 돼요

218
00:09:38,100 --> 00:09:41,460
근데 여기서 만약에 체언이나 아니면 용원 명산

219
00:09:41,460 --> 00:09:44,900
아니면 조금 동사가 조금씩 바뀌면 완전히 되게

220
00:09:44,900 --> 00:09:47,620
다른 의미의 공장으로 변화되는 것처럼

221
00:09:47,620 --> 00:09:52,320
되게 용원이 나체 원에 민감해지는 문제

222
00:09:52,320 --> 00:09:55,640
두 번째로는 이 아델 문장이 길이가 길어질수록

223
00:09:55,640 --> 00:09:58,920
이해도가 굉장히 급격하게 떨어 져

224
00:09:58,920 --> 00:10:03,840
세번째로는 저희는 이제 대화라는 전체적인 블로그니까

225
00:10:03,840 --> 00:10:07,790
문장을 이해하는 게 아니라 문장이 어떻게 연결되고

226
00:10:07,790 --> 00:10:11,320
어떤 대화 흐름을 갖고 있는지 의미로 파악해야 되는데

227
00:10:11,320 --> 00:10:12,290
지금까지 설명되었다

228
00:10:12,290 --> 00:10:14,850
내 1월 티백은 그런 다이얼로그에

229
00:10:14,850 --> 00:10:17,860
블로그를 이해할 수 있는 모델은 아닙니다

230
00:10:17,860 --> 00:10:21,650
그렇기 때문에 이런 문맥을 이해할 수 있는 기능은

231
00:10:21,650 --> 00:10:22,890
전혀 들어가 있지 않기 때문에

232
00:10:22,890 --> 00:10:25,320
대화 시스템에 바로 적용하기는 굉장히 어렵습니다

233
00:10:25,320 --> 00:10:27,910
그래서 저희는 이 세 가지가

234
00:10:27,910 --> 00:10:30,060
기존의 nlu 모델의 가장 큰 문제점이라고

235
00:10:30,060 --> 00:10:35,160
정리를 하고 이 문제를 해결할 수 있는 모델 찾다가

236
00:10:35,160 --> 00:10:37,950
2017년도에 2018년도 10월에 나온

237
00:10:37,950 --> 00:10:41,390
새로운 논문을 평가를 받게 됩니다

238
00:10:41,390 --> 00:10:45,800
2017년도에 구글은 단어를 병렬적으로 처리할 수 있는 트랜스포머

239
00:10:45,800 --> 00:10:47,460
라는 구절이 만들었는데요

240
00:10:47,460 --> 00:10:49,100
모델을 통해서 기계번역

241
00:10:49,100 --> 00:10:51,780
테스트해서 굉장히 높은 성능을 보여 줬어요

242
00:10:51,780 --> 00:10:56,470
그리고 정확하게 1년뒤인 2018년 10월에

243
00:10:56,470 --> 00:11:00,740
2구조 를 기반으로 하는 다이렉트로 도쿄스테이션 플랫포머

244
00:11:00,740 --> 00:11:02,340
나는 기술을 공개했습니다

245
00:11:02,340 --> 00:11:04,350
근데 모델이 너무 길다

246
00:11:04,350 --> 00:11:06,640
사람들은 보통 이 모델을 파트라고 줄여서

247
00:11:06,640 --> 00:11:07,940
이야기를 합니다

248
00:11:07,940 --> 00:11:12,910
모델은 단어의 전 후 맨날 보면서 문맥을 파악하고

249
00:11:12,910 --> 00:11:16,610
단어의 의미를 학습 할 수 있도록 만들어진 모델부 줘

250
00:11:16,610 --> 00:11:18,890
그래서 이런 셀프어텐션 이라는 기법을 이용해서

251
00:11:18,890 --> 00:11:22,160
팍 단어가 어떤 단어의 영향을 주는지

252
00:11:22,160 --> 00:11:24,000
이해를 하게 되는데요

253
00:11:24,000 --> 00:11:27,710
공개된 모델 웹에있는 뭐 위키피디아 나 아니요

254
00:11:27,710 --> 00:11:29,640
공개된 아니면 뭐

255
00:11:29,640 --> 00:11:31,960
자막 데이터들은 이용해서 전체

256
00:11:31,960 --> 00:11:33,860
다양한 텍스트들을 모았고

257
00:11:33,860 --> 00:11:36,720
다양한 경험 에 대해서 학습할 수 있는 구조로

258
00:11:36,720 --> 00:11:39,180
모델을 만들게 되었습니다

259
00:11:39,180 --> 00:11:41,480
근데 제가 이렇게 갑자기 뜬금없이 배터리 사용

260
00:11:41,480 --> 00:11:43,820
크게 드린 이유는 제발

261
00:11:43,820 --> 00:11:47,150
엄청나게 뛰어난 성능 때문이래요

262
00:11:47,150 --> 00:11:51,150
어떻게 같은 경우는 뛰어난 모델구조 학습 방법을 이용해서

263
00:11:51,150 --> 00:11:53,890
총 11개의 테스트에서 한 번에 소타

264
00:11:53,890 --> 00:11:57,480
그 책 최고성능의 기록하는 결과를 얻었습니다

265
00:11:57,480 --> 00:12:00,000
심지어 그냥 조금 오른손이 아니라

266
00:12:00,000 --> 00:12:03,150
이전 모델에 비해 굉장히 크게 점수가 올라서

267
00:12:03,150 --> 00:12:06,000
nlp 게임체인저 라고 불리불리 기도하죠

268
00:12:06,000 --> 00:12:08,560
더 소름돋는 단순히 선생이 오는 거 보면

269
00:12:08,560 --> 00:12:10,330
아니 질의 응답 하는 테스트

270
00:12:10,330 --> 00:12:14,640
커다란 계속해서 사람보다 더 높은 점수를 기록하게 되어도

271
00:12:14,640 --> 00:12:17,180
화제가 되기도 했습니다

272
00:12:17,180 --> 00:12:19,960
그러면 이렇게 좋은 nlu 모델이 있는데

273
00:12:19,960 --> 00:12:21,430
우리도 한번 써 볼 수 있지 않을까

274
00:12:21,430 --> 00:12:22,910
당연히 우리는 에피에서

275
00:12:22,910 --> 00:12:24,570
굉장히 많은 연구를 하고 있는데

276
00:12:24,570 --> 00:12:26,870
버튼을 대화체 학습시켜 보지 않는다면

277
00:12:26,870 --> 00:12:31,110
뭔가 굉장히 큰 거 하나 남겨 두는 느낌이었어요

278
00:12:31,110 --> 00:12:33,500
그리고 좀 더 이론적으로 생각해봤을때 것들을

279
00:12:33,500 --> 00:12:35,600
우리가 대화체 nlu 모델로

280
00:12:35,600 --> 00:12:38,050
사용하게된 얼른 2.3 너무나 많았어요

281
00:12:38,050 --> 00:12:40,430
기존에 있는 문제들도 다 해결 해 볼 수 있었고

282
00:12:40,430 --> 00:12:42,910
또 대화시스템 시스템에 슬로우로 이야기해도

283
00:12:42,910 --> 00:12:44,870
굉장히 적합한 모델 구조여서

284
00:12:44,870 --> 00:12:48,770
어 이 모델을 안 해보고 이유를 찾을 수가 없어

285
00:12:48,770 --> 00:12:52,360
그래서 저희 역시 대화체를 위한 버트

286
00:12:52,360 --> 00:12:54,190
다이얼 로버트 라는 이름을 지어서

287
00:12:54,190 --> 00:12:56,630
대화체 적합한 이제

288
00:12:56,630 --> 00:12:59,450
인식 모델을 만들 수 있게 되었습니다

289
00:12:59,450 --> 00:13:02,400
그러면 이제 앞으로 어떻게 이다연 로버트를 학습

290
00:13:02,400 --> 00:13:05,420
상지 소개해 드리려고 하는 방금은 굉장히 간단합니다

291
00:13:05,420 --> 00:13:08,310
총 두 가지 학습방법의 동시에 이용하는데요

292
00:13:08,310 --> 00:13:12,420
첫 번째는 전체 단어에서 15% 랜덤하게 삭제 시키고

293
00:13:12,420 --> 00:13:13,530
그 단어를 맞추는 거야

294
00:13:13,530 --> 00:13:15,290
얘는 이렇게 하잖아

295
00:13:15,290 --> 00:13:17,170
그러면 이제 대화가 있는 것 중에

296
00:13:17,170 --> 00:13:18,900
단어가 삭제 되잖아요

297
00:13:18,900 --> 00:13:21,130
그러면 여기다 사람한테 저기

298
00:13:21,130 --> 00:13:25,150
저기 빈칸에 무슨 단어가 들어갈까 라고 물어보는 거야

299
00:13:25,150 --> 00:13:27,640
계속 그리고 교육 과정 계속 무한 반복해

300
00:13:27,640 --> 00:13:29,630
그러다 보니 이 단어를 맞출때마다

301
00:13:29,630 --> 00:13:32,950
리워드를 주고 또 틀릴때마다 너 틀렸어 라고

302
00:13:32,950 --> 00:13:37,770
또 감정을 주면 머신러닝이 알아서 전체적인 컨택트 버스데이

303
00:13:37,770 --> 00:13:39,730
단어에는 어떤 게 들어가는 받겠다

304
00:13:39,730 --> 00:13:41,630
그러면 단어를 학습하는 과정에서

305
00:13:41,630 --> 00:13:46,780
자연스럽게 언어에 대한 이해를 학습을 약간 수능 수능

306
00:13:46,780 --> 00:13:49,430
문제 에서 빈칸이 빈칸에

307
00:13:49,430 --> 00:13:51,660
어떤 문제가 들어 어떤 단어가 들어갈 걸 맞추는

308
00:13:51,660 --> 00:13:53,890
그걸 계속 반복적으로 학습한다고 생각하시면

309
00:13:53,890 --> 00:13:54,990
될 거 같아요

310
00:13:54,990 --> 00:13:56,630
그러면 두 번째로 어떻게

311
00:13:56,630 --> 00:13:59,420
이제 문맥을 학습을 한상범 인데요

312
00:13:59,420 --> 00:14:01,910
앞에서는 단어에 대해서 찾아

313
00:14:01,910 --> 00:14:04,190
이번엔 문장에 대해서 맞추는 거야

314
00:14:04,190 --> 00:14:08,020
현대문명 해서 이렇게 이번 트와이스에서 새로 나온 신곡 없어

315
00:14:08,020 --> 00:14:09,700
당연히 봤지 이거 진짜 대박이다

316
00:14:09,700 --> 00:14:13,030
그러니까 이번 노래 최고야 진짜라는 대화 하고 있는 과정에서

317
00:14:13,030 --> 00:14:16,320
다음 문장을 어떤 게 나올 적에 착한 건데요

318
00:14:16,320 --> 00:14:18,640
예를 들면 먹은 거 어머니께 말씀 드렸어요

319
00:14:18,640 --> 00:14:22,380
나는 문장이라면 약간 갑분싸 라고 하죠

320
00:14:22,380 --> 00:14:24,410
약간 말이 안되는 문제 나온 거야

321
00:14:24,410 --> 00:14:27,330
그래서 이제 이런 거는 영어로 틀렸다고

322
00:14:27,330 --> 00:14:29,380
이제 예측을 하도록 안 돼

323
00:14:29,380 --> 00:14:31,390
예를 들면 그래서 나 이번 앨범 3일 보라고

324
00:14:31,390 --> 00:14:34,690
이렇게 자연스러운 문장이 나오게 되면은 못 내게 맞는 대답

325
00:14:34,690 --> 00:14:36,740
일로 예측을 하게 학습을 시킵니다

326
00:14:36,740 --> 00:14:37,570
이렇게 하게 되면

327
00:14:37,570 --> 00:14:41,210
자연스럽게 연속된 대화에서 다음 문장이 뭐가 나올지

328
00:14:41,210 --> 00:14:43,490
컨텍스트 라운지 문맥이 본지 대화해서

329
00:14:43,490 --> 00:14:45,580
어떤 사람을 가져가야 하는지를 자연스럽게

330
00:14:45,580 --> 00:14:46,940
학습시킬 수가 있어요

331
00:14:46,940 --> 00:14:50,140
그래서 이렇게 아까 말했던 단어를

332
00:14:50,140 --> 00:14:51,580
빙판에 단어를 맞추는 방법

333
00:14:51,580 --> 00:14:53,260
거 문맥을 학습 시키는 방법

334
00:14:53,260 --> 00:14:56,500
동시학습 시켜서 대화가 어떤 시스템을 이루어지는지

335
00:14:56,500 --> 00:15:00,570
어떤 구조로 이해해 하는지를 평가 평가하고

336
00:15:00,570 --> 00:15:04,200
또 학습할 수 있는 모델 만들 수 있게 되었습니다

337
00:15:04,200 --> 00:15:07,410
하지만 이렇게 두 가지 부족 만으로는 기업이전

338
00:15:07,410 --> 00:15:11,060
저희가 만들려고 하는 대화 최적화되지 않았어요

339
00:15:11,060 --> 00:15:12,510
오리지널 버티고 저는

340
00:15:12,510 --> 00:15:14,950
아까 설명드렸던 구조가 있다고 한다면

341
00:15:14,950 --> 00:15:16,840
그 밑에 하나를 더 추가 해 줘야 되는데요

342
00:15:16,840 --> 00:15:20,010
저희가 추가한 내용은 어떤 대화가 있으면

343
00:15:20,010 --> 00:15:23,590
그 대화를 각각 연결해서 황태지 라고하자

344
00:15:23,590 --> 00:15:26,690
문장 붙여 가지고 이제 어떻게 되는데

345
00:15:26,690 --> 00:15:29,190
이렇게 임수로 너는 단어들을 9분할 수가 없었어요

346
00:15:29,190 --> 00:15:32,170
그러니깐 이게 몇 번째 판 에서 나오는 대왕 이미지

347
00:15:32,170 --> 00:15:35,330
누가 얘기하는 대화 인지를 알 수 있는 정보가 없었기 때문에

348
00:15:35,330 --> 00:15:38,910
기존 대화시스템 그냥 바로 오리지널 포트를 적용하긴 어려워

349
00:15:38,910 --> 00:15:42,770
연탄 임베딩 이라는 메세지를 출발해서 버튼을 다 여로세트

350
00:15:42,770 --> 00:15:45,690
몇 개 최적화 시켰습니다

351
00:15:45,690 --> 00:15:47,370
이해는 구글의 구글에서

352
00:15:47,370 --> 00:15:50,690
이제 공식적으로 적용한 더 트랩 4를 조금 터닝

353
00:15:50,690 --> 00:15:53,350
배당을 추가를 해서 버튼을 모델을 학습

354
00:15:53,350 --> 00:15:56,500
1탄 학습활동 텐서플로를 텐서플로를 이용했어요

355
00:15:56,500 --> 00:15:59,020
텐서플로를 이용한 가장 큰 이유는 물론

356
00:15:59,020 --> 00:16:00,860
공식맵 보이기도 하지만

357
00:16:00,860 --> 00:16:02,140
구글에 있는 tpu 를 사용해서

358
00:16:02,140 --> 00:16:04,730
굉장히 빠르게 약속을 지킬 수 있다는 건데요

359
00:16:04,730 --> 00:16:07,680
논문에서도 역시 피해를 이용해서 굉장히 빠르게

360
00:16:07,680 --> 00:16:08,850
학습을 하는 것을 보여 줘서

361
00:16:08,850 --> 00:16:11,940
저희 역시 시간이 시간이 걸리잖아요

362
00:16:11,940 --> 00:16:13,970
그래서 저희도 굉장히 빠른 학습을 위해서

363
00:16:13,970 --> 00:16:15,360
투표에서 약 18일 정도

364
00:16:15,360 --> 00:16:21,250
전체 카톡 데이터 한 10억 원 정도 필터링해서 학습을 진행해

365
00:16:21,250 --> 00:16:22,150
이렇게 학습 했을 때

366
00:16:22,150 --> 00:16:23,850
두 가지 결과를 볼 수 있었는데요

367
00:16:23,850 --> 00:16:26,860
첫 번째는 이제 마스크도 남기지 모델에서는 53%

368
00:16:26,860 --> 00:16:29,440
아까 빈칸에 맞추는 법 53%

369
00:16:29,440 --> 00:16:32,530
약간 정 떨어진 거 아니야 이렇게 생각할 수도 있지만

370
00:16:32,530 --> 00:16:36,920
사랑하는 빈 칸에 뚫고 그걸 맞춰 보라고 하세요

371
00:16:36,920 --> 00:16:38,530
그걸 다 100% 완벽하게

372
00:16:38,530 --> 00:16:39,840
마칠 수 있는 사람이 있을까요

373
00:16:39,840 --> 00:16:43,010
똑같이 기계도 반 정도 맞추면 진짜 잘 맞추는 사람

374
00:16:43,010 --> 00:16:45,280
더 사실 단정도 맞추기 굉장히 어렵거든요

375
00:16:45,280 --> 00:16:48,140
그래서 어 보시면 굉장히 빠르게 수렴하고

376
00:16:48,140 --> 00:16:51,270
그러면 이후에는 계속 성령이 오래된 거 볼 수 있는데

377
00:16:51,270 --> 00:16:52,780
이게 약간 언더피팅 상태요

378
00:16:52,780 --> 00:16:54,190
아직 다 처리되지 않은 상태로

379
00:16:54,190 --> 00:16:55,680
계속 카톡 할 수 있는데

380
00:16:55,680 --> 00:16:58,910
비약적인 성능향상이 없어서 일단 중지를 한 상태고

381
00:16:58,910 --> 00:17:03,870
두 번째로 센 스펠릭스 문맥이 테스크 대해서는 88%

382
00:17:03,870 --> 00:17:07,460
정도의 성능 갖는 모델을 만드셨습니다

383
00:17:07,460 --> 00:17:09,590
그럼 이렇게 이해시킨 모델을 받고

384
00:17:09,590 --> 00:17:11,420
진짜 잘 할 수 있을까

385
00:17:11,420 --> 00:17:12,660
얼마나 응용할 수 있을까요

386
00:17:12,660 --> 00:17:14,390
평가를 해 봤는데요

387
00:17:14,390 --> 00:17:17,540
기존의 이제 저희가 버튼 없이 그러니까 언어에 대한 이해

388
00:17:17,540 --> 00:17:20,300
학습 애모 를 이용해서

389
00:17:20,300 --> 00:17:23,350
미리 조금 박스로 한 이후에 오늘 테스트를 풀었을 때

390
00:17:23,350 --> 00:17:26,030
와 시댁 저희가 만든 것들을 비교했을 때

391
00:17:26,030 --> 00:17:27,730
굉장히 큰 차이가 났어요

392
00:17:27,730 --> 00:17:29,570
저희가 내부적으로 사용하고 있는 너

393
00:17:29,570 --> 00:17:31,180
너 내가 얼마나 될 수 있는지

394
00:17:31,180 --> 00:17:33,680
평가할 수 있는 세 가지 테스크 아닌데요

395
00:17:33,680 --> 00:17:36,450
두문장을 주고 2문단 의미가 유사한지

396
00:17:36,450 --> 00:17:41,030
또 어떤 답변을 줬을 때 이 답변이 유효하고 또 적절한지

397
00:17:41,030 --> 00:17:43,340
또 이 질문에 대한 의견은 무엇인지

398
00:17:43,340 --> 00:17:46,690
구별하는 3가지 모델 대해서 버트랑 베이스라인의 봤을 때

399
00:17:46,690 --> 00:17:51,400
거의 한 첫 번째 모델 같은 경우는 8%

400
00:17:51,400 --> 00:17:52,160
정도의 높은 성능

401
00:17:52,160 --> 00:17:53,460
향상 있었고

402
00:17:53,460 --> 00:17:54,920
그 이후에도 계속 85%

403
00:17:54,920 --> 00:18:01,280
한 80% 정도 되면은 86바 정도 되고 뭐 한 80

404
00:18:01,280 --> 00:18:04,430
80 정도 되는데 한 80% 정도로

405
00:18:04,430 --> 00:18:07,380
원래는 이런 성능향상은 볼 수 있었습니다

406
00:18:07,380 --> 00:18:08,840
이렇게 저희가 되게 이해도

407
00:18:08,840 --> 00:18:11,010
높은 언어모델을 만들 수 있었고

408
00:18:11,010 --> 00:18:13,520
그럼 이걸 가지고 대답을 해야 되잖아요

409
00:18:13,520 --> 00:18:15,170
어 나 많이 해 가지고는 의미가 없어요

410
00:18:15,170 --> 00:18:18,280
이걸 가지고 대답을 해 실제로 인공 지능 많다고

411
00:18:18,280 --> 00:18:19,910
그래서 이제 어떻게

412
00:18:19,910 --> 00:18:21,470
그러면 이 언어모델 갖고 와서

413
00:18:21,470 --> 00:18:24,480
이해할 수 있을지를 소개를 해 드리려고 하는데요

414
00:18:24,480 --> 00:18:26,140
이제 뛰어난 내라고 무기로 가졌으니

415
00:18:26,140 --> 00:18:29,010
말을 해 보라고 가르쳐 봅시다

416
00:18:29,010 --> 00:18:32,340
어 저희가 아까 설명드렸던 것 중에

417
00:18:32,340 --> 00:18:34,660
제일 상대와는 어떤 질문이든

418
00:18:34,660 --> 00:18:36,410
올 수 있을지 예상할 수 없다고 했잖아요

419
00:18:36,410 --> 00:18:40,630
그렇게 일단 제가 아는 모든 거 들어올 수 있는 커리

420
00:18:40,630 --> 00:18:46,660
스페이스 예상되는 질문에 스페이스가 진짜 엄청나게 무수히

421
00:18:46,660 --> 00:18:48,130
그래서 우리는 무수히

422
00:18:48,130 --> 00:18:50,950
많은 걸 터틀 을 이용해서 언어를 이해시키고

423
00:18:50,950 --> 00:18:53,130
너는 이해를 통해서 특정한 백도

424
00:18:53,130 --> 00:18:56,000
어떤 이의 문맥은 뭐고 이 문장은 뭐

425
00:18:56,000 --> 00:18:59,410
고를 이제 추론할 수 있는 못 만들었어요

426
00:18:59,410 --> 00:19:02,710
근데 문제는 뭐냐면 답변도 무관하다는 거예요

427
00:19:02,710 --> 00:19:04,440
어 나만 못 하는 게 아니라

428
00:19:04,440 --> 00:19:07,160
답변도 무안에서 그러면 이렇게 이해한 거

429
00:19:07,160 --> 00:19:09,260
가지고 무한한 답변을 만들어야 되나

430
00:19:09,260 --> 00:19:12,740
그러면 만약에 답변이 무한한 상태로 가정하고

431
00:19:12,740 --> 00:19:17,240
모델을 만들게 되면 제너레이션 생성모델 만들기 해야 되는데

432
00:19:17,240 --> 00:19:19,980
챗봇이 직접 생성하는 말을 사용자에게 전달하고

433
00:19:19,980 --> 00:19:20,930
될 텐데

434
00:19:20,930 --> 00:19:22,420
우리 스스로도 챗봇이 사실

435
00:19:22,420 --> 00:19:24,850
무슨 말을 할지 예측할 수 없잖아요

436
00:19:24,850 --> 00:19:27,020
만약에 그러면 이 모델 구글이나

437
00:19:27,020 --> 00:19:30,590
아니면 다른 클로바 같은 큰 기업의 우리가 같이 공동으로

438
00:19:30,590 --> 00:19:32,270
한번 하게 된다면 클로바가

439
00:19:32,270 --> 00:19:33,820
막 이상한 말을 할 수도 있고

440
00:19:33,820 --> 00:19:36,470
우리가 생각하지 못했던 말 들을 수 있을 거야

441
00:19:36,470 --> 00:19:40,130
그런 거 이제 바로 신뢰성이 부족하거나

442
00:19:40,130 --> 00:19:41,570
아니면 불확실성

443
00:19:41,570 --> 00:19:43,760
어떤 답변할 수 있을지 결정할 수 없네

444
00:19:43,760 --> 00:19:46,280
그러면 문제점이 있습니다

445
00:19:46,280 --> 00:19:47,910
그래서 저희는 이 답변을

446
00:19:47,910 --> 00:19:50,020
단순히 제너레이션을 푸는 게 아니라

447
00:19:50,020 --> 00:19:51,820
통제가능한 답변을 만들기 위해서

448
00:19:51,820 --> 00:19:56,260
무한 계단 편을 축소시키는 전략 만나게 되었어요

449
00:19:56,260 --> 00:19:58,810
그러면 여러분들께서는 이런 유한개의 답변을

450
00:19:58,810 --> 00:20:01,010
어떻게 적절한 대답을 하지

451
00:20:01,010 --> 00:20:01,910
어떻게 똑똑한 인공

452
00:20:01,910 --> 00:20:04,300
지능 만들지 라고 생각하실 수 있을 것 같은데요

453
00:20:04,300 --> 00:20:08,080
맞습니다 그게 바로 우리의 핵심문제 본질이 야

454
00:20:08,080 --> 00:20:10,870
어떻게 유한개 답변을 가지고

455
00:20:10,870 --> 00:20:13,990
실제로 많은 퍼레이드를 커버할 수 있는지를

456
00:20:13,990 --> 00:20:16,010
저희는 그걸 계속 높여야 되면

457
00:20:16,010 --> 00:20:19,080
우리가 파이썬에서 테스트 코드를 짜서 테스트 꽃

458
00:20:19,080 --> 00:20:20,760
적절한 테스트 코드를 이용해서

459
00:20:20,760 --> 00:20:23,370
많은 테스트커버리지 높이기 위해 노력하는 것처럼

460
00:20:23,370 --> 00:20:26,120
저희 역시 이왕 게 답변이 얼마나 많은 무 하나

461
00:20:26,120 --> 00:20:28,070
스페이스에서 영역을 찾을 수 있는 얼마나

462
00:20:28,070 --> 00:20:30,940
많은 질문들을 커버할 수 있는지를 향상시킨 게

463
00:20:30,940 --> 00:20:33,500
가장 큰 부장입니다

464
00:20:33,500 --> 00:20:38,720
그러면 이렇게 답변을 한 개로 만드는 과정

465
00:20:38,720 --> 00:20:39,770
답변에 어떤 걸

466
00:20:39,770 --> 00:20:41,980
선택하는 제가 굉장히 중요할 것 같은데요

467
00:20:41,980 --> 00:20:45,160
가장 간단한 방법은 진짜 실제 데이터 사용 자제

468
00:20:45,160 --> 00:20:46,910
어떤 말을 하는지 알아 보는 거야

469
00:20:46,910 --> 00:20:48,610
없다는 말을 들을 사용자가 많이 하고

470
00:20:48,610 --> 00:20:51,400
어떤 말들 어떤 말대로 꺼버리는

471
00:20:51,400 --> 00:20:54,410
높일 수 있는지를 알아보는 방법인데요

472
00:20:54,410 --> 00:20:58,020
그래서 이제 뭐 그루트가 아무것도 이렇게 맨날 얘기만 하자

473
00:20:58,020 --> 00:21:00,060
이것처럼 사용자들도 그러면

474
00:21:00,060 --> 00:21:02,000
어느 정도 하는 말이 정해져 있지 않을까

475
00:21:02,000 --> 00:21:04,770
제가 스스로 하는 카톡을 봐도 물론

476
00:21:04,770 --> 00:21:07,970
다양한 문자 허리에 대응되는 문장을 쓸 때도 있지

477
00:21:07,970 --> 00:21:10,510
나랑 비슷한 문장을 쓸 때가 굉장히 많거든요

478
00:21:10,510 --> 00:21:12,170
그래서 저희 역시도 어

479
00:21:12,170 --> 00:21:15,290
그럼 카카오톡 데이터에서 군포를 비교를 해 보자 라고 해서

480
00:21:15,290 --> 00:21:17,900
전체대화 데이터에 분포를 조사를 해 봤어요

481
00:21:17,900 --> 00:21:23,260
그래서 대화 메시지를 못 봐서 비너스 기준으로 이제 DB

482
00:21:23,260 --> 00:21:24,410
손해보 악보 그다음에

483
00:21:24,410 --> 00:21:27,830
상위랭킹 에 있는 말들이 진짜 우리가 예상했던 것처럼

484
00:21:27,830 --> 00:21:30,130
리액션에 가까운 말 들었어요 알겠어요

485
00:21:30,130 --> 00:21:33,160
많이 먹었어 맛있게 먹어 사랑해 괜찮아

486
00:21:33,160 --> 00:21:35,900
나도 나도 신기해 연식에 간단하고

487
00:21:35,900 --> 00:21:40,690
되게 사용자들이 많이 쓰는 답변드려 벌 수 있었는데요

488
00:21:40,690 --> 00:21:44,290
이런 탑 만 개 정도의 문장이 전체 8천만 게 메시지

489
00:21:44,290 --> 00:21:47,060
8천만 걔는 내가 이제 임의로 샘플링 한다는데요

490
00:21:47,060 --> 00:21:49,930
천막에 메시지 중에서 20% 를 찾아 했어요

491
00:21:49,930 --> 00:21:52,150
근데 20% 를 찾아 한다는 말이

492
00:21:52,150 --> 00:21:54,120
전체 허리에 무조건 20% 를

493
00:21:54,120 --> 00:21:56,290
절대적으로 커버 한다는 이야기가 아니라

494
00:21:56,290 --> 00:21:58,700
만약에 우리가 이 모델을 가지고

495
00:21:58,700 --> 00:22:02,340
내가 만들게 되면 네가 이해하는 모델로 만들 수 있는

496
00:22:02,340 --> 00:22:06,400
그러면 단순히 무조건 리액션 답변만 예측하면

497
00:22:06,400 --> 00:22:07,760
우리가 할 수 있는

498
00:22:07,760 --> 00:22:09,840
모든 답변에 대해서 커버를 할 수 있다는 거야

499
00:22:09,840 --> 00:22:12,030
그러면 커버리지를 20분만 아니라 거의 패

500
00:22:12,030 --> 00:22:13,660
아니면 3배 이상의 높은

501
00:22:13,660 --> 00:22:15,730
커버리지에 더 탈 수도 있어요

502
00:22:15,730 --> 00:22:18,740
그래서 우리는 많은 대화를 이용

503
00:22:18,740 --> 00:22:20,210
해서 처리를 하게 됩니다

504
00:22:20,210 --> 00:22:21,680
대화에서 리액션은 되게

505
00:22:21,680 --> 00:22:24,660
다양한 상황에서 굉장히 유용하게 사용할 되는데요

506
00:22:24,660 --> 00:22:28,300
적절한 반응과 공감은 대화를 상대방이 대화를 유도하고

507
00:22:28,300 --> 00:22:30,660
또 애착관계를 형성하게 됩니다

508
00:22:30,660 --> 00:22:33,130
대화해서 상대방의 말에 공감하고

509
00:22:33,130 --> 00:22:35,070
또 인스턴트 하게 대응하기에는

510
00:22:35,070 --> 00:22:37,740
굉장히 넥센이 유용한 방법이기 때문에

511
00:22:37,740 --> 00:22:39,860
다양한 상황에서 사용될 수 있고요

512
00:22:39,860 --> 00:22:43,020
또한 적절한 받는 거 공감은 상대방에 대화를 하고

513
00:22:43,020 --> 00:22:44,770
또 애착 형성 합니다

514
00:22:44,770 --> 00:22:46,620
그래서 이제 뭐 이런 말이 있잖아

515
00:22:46,620 --> 00:22:48,470
내 것만 잘해도 남자친구랑 여자친구

516
00:22:48,470 --> 00:22:52,110
이쁨받는 대화를 할 수 있다 라는 말이 있었어

517
00:22:52,110 --> 00:22:54,190
그래서 이제 그러면 진짜 사람처럼

518
00:22:54,190 --> 00:22:56,540
리액션을 잘 하는 못 만들게 되면

519
00:22:56,540 --> 00:22:59,300
전체 비너스에서 타 번개가 20% 를 찾아 줘

520
00:22:59,300 --> 00:23:01,480
보다 더 높은 커버리지를 만들 수 있지 않을까

521
00:23:01,480 --> 00:23:03,070
라는 가설세우기 되었어요

522
00:23:03,070 --> 00:23:06,690
그래서 리액션을 잘해서 사람의 대화를 계속 유도에 나간다면

523
00:23:06,690 --> 00:23:09,250
자연스럽게 사람 같은 모습을 보여줄 수 있고

524
00:23:09,250 --> 00:23:12,090
또 더 대화를 길게 나갈 수 있다고 생각하고 있어요

525
00:23:12,090 --> 00:23:12,840
그래서 우리가 아까

526
00:23:12,840 --> 00:23:16,860
봤던 이 문제를 유한개 답변에 정하는 문제를

527
00:23:16,860 --> 00:23:18,360
리액션 모델의 통해서

528
00:23:18,360 --> 00:23:24,220
리액션이란 은유한 게 답변을 선택하는 모델로 바꾸겠습니다

529
00:23:24,220 --> 00:23:26,850
자 그러면 이제 실제로 모델 한번 만들어 봐

530
00:23:26,850 --> 00:23:28,090
아까 우리가 뽑았다

531
00:23:28,090 --> 00:23:28,920
상의만 계정 대로

532
00:23:28,920 --> 00:23:30,990
답변 중에서 중복되는 거 조금 제거하고

533
00:23:30,990 --> 00:23:33,730
또 약간 비싼 것도 있기는 묻고 해서

534
00:23:33,730 --> 00:23:36,950
2천 개 정도의 리액션 클래스로 이제 다시 줄이겠습니다

535
00:23:36,950 --> 00:23:39,040
이런 쌍 프레슬리 이후에

536
00:23:39,040 --> 00:23:41,410
앞에 있는 문맥을 인풋으로 주고

537
00:23:41,410 --> 00:23:45,240
그렇게 보시는 것처럼 되게 다양한 문맥들을 문맥을 주고

538
00:23:45,240 --> 00:23:48,110
그 다음에 나올 exo 에 대해서 예측하는 방식으로

539
00:23:48,110 --> 00:23:52,120
데이터셋을 구성을 해서 리액션 학습데이터셋 안 돼 근데

540
00:23:52,120 --> 00:23:53,050
이제 저희가 갖고 있는데

541
00:23:53,050 --> 00:23:55,550
받게 데이터에 장점은 되게

542
00:23:55,550 --> 00:23:56,910
다양한 사람들의 이야기 하잖아요

543
00:23:56,910 --> 00:23:59,320
그래서 되게 다양한 상황과 문제를 나올 수 있어요

544
00:23:59,320 --> 00:24:01,670
그래서 그런 컨텍스트를 잘 이해하고

545
00:24:01,670 --> 00:24:04,360
또 사람들의 다양한 문맥들을 이해할 수 있네

546
00:24:04,360 --> 00:24:06,870
모델들 만들게 됩니다

547
00:24:06,870 --> 00:24:08,840
실제 모델 학습 할 때는

548
00:24:08,840 --> 00:24:11,090
굉장히 많은 구조가 바뀔 것 같지만

549
00:24:11,090 --> 00:24:13,920
단순한 모델 하나를 붙여서

550
00:24:13,920 --> 00:24:15,600
모델을 만들 수 있게 되는데요

551
00:24:15,600 --> 00:24:19,990
기존에 우리가 아까 있던 L1L 버트 모델 이용 해서

552
00:24:19,990 --> 00:24:21,670
그 뒤에 이제 넥슨

553
00:24:21,670 --> 00:24:22,990
플레이 스테이션 할 수 있는

554
00:24:22,990 --> 00:24:24,640
레이어를 하나만 더 붙여야 됩니다

555
00:24:24,640 --> 00:24:26,070
이렇게 하면 모델변경

556
00:24:26,070 --> 00:24:28,900
많은 변경 없이도 단순하게

557
00:24:28,900 --> 00:24:32,460
모델을 변경할 수 있게 됐고요

558
00:24:32,460 --> 00:24:33,990
이렇게 변경한 모델을

559
00:24:33,990 --> 00:24:36,970
기존에는 블로거를 이용해서

560
00:24:36,970 --> 00:24:39,160
이제 버터를 학습을 시키게 되었잖아요

561
00:24:39,160 --> 00:24:41,990
근데 저희가 학습 하게 되면 되게 다양한 실험이나

562
00:24:41,990 --> 00:24:44,360
아니면 여러 가지 변수가 많은 실험을 해봐야 돼요

563
00:24:44,360 --> 00:24:47,940
근데 그러게 텐서플로우가 저희는 적합하다고 생각하지 않아

564
00:24:47,940 --> 00:24:49,010
거긴 페이스 파이터

565
00:24:49,010 --> 00:24:51,050
트랜스포머란 드라이브를 이용해서

566
00:24:51,050 --> 00:24:54,030
텐서플로 에 있는 웨이트를 파이토치로 가져와서

567
00:24:54,030 --> 00:24:55,200
학습 확인했고

568
00:24:55,200 --> 00:24:58,470
4시간 모델의 과정을 진행하게 되었습니다

569
00:24:58,470 --> 00:25:00,870
이때 학습할 때는 주식 P200

570
00:25:00,870 --> 00:25:05,140
gpu 를 멀티스퀘어 연결해서 학습 하겠습니다

571
00:25:05,140 --> 00:25:08,420
그러면 이제 설명은 다 끝났고요

572
00:25:08,420 --> 00:25:10,750
실제로 맥스모델 얼마나 잘하나

573
00:25:10,750 --> 00:25:15,620
궁금해하실 것 가면 얼마나 잘 안 자면 알아보더라

574
00:25:15,620 --> 00:25:17,520
일단 첫 번째로는 액션보다는 되게

575
00:25:17,520 --> 00:25:19,490
다양한 상황에 대처할 수 있어요

576
00:25:19,490 --> 00:25:21,440
기존 도시인이라면 비품은 가지고

577
00:25:21,440 --> 00:25:22,660
이런 상황에서 이렇게 대답해

578
00:25:22,660 --> 00:25:25,230
이런 상황에서 이렇게 대답해 를 다 일일이 만들어졌다면

579
00:25:25,230 --> 00:25:27,740
1층보다는 알아서 어떤 얘기를 해야지

580
00:25:27,740 --> 00:25:29,680
잘 판별에 여기에서 뭐 보시는 거

581
00:25:29,680 --> 00:25:32,880
같은 다양한 상황에 대처할 수 있고

582
00:25:32,880 --> 00:25:34,590
또 우리가 인간적으로 생각하는

583
00:25:34,590 --> 00:25:36,620
사회적 개념에 대해서 이해를 하고 있어요

584
00:25:36,620 --> 00:25:38,720
오늘 월요일이다 그건 알아요

585
00:25:38,720 --> 00:25:40,930
이렇게 되게 강하게 얘기를 하지 마

586
00:25:40,930 --> 00:25:42,450
오늘 금요일이라고 하면 좋아요

587
00:25:42,450 --> 00:25:44,230
아니면 이제 밑에 있는 지금

588
00:25:44,230 --> 00:25:45,630
답변들 생겼다는데 못잊나요

589
00:25:45,630 --> 00:25:46,630
아니면 와 즐거워요

590
00:25:46,630 --> 00:25:49,710
이런 식의 사회적 이해를 하고 있는 모델 만들

591
00:25:49,710 --> 00:25:51,650
수 있게 됩니다

592
00:25:51,650 --> 00:25:55,130
또한 단순히 어떤 상황이나 아니면 이해하는 것 뿐만 아니라

593
00:25:55,130 --> 00:25:56,330
긴 문장도 잘 이해하고

594
00:25:56,330 --> 00:25:58,700
그리고 구체적인 답변도 꽤 많이 해요

595
00:25:58,700 --> 00:26:00,080
애들은 어제 엄청 늦게 잤더니

596
00:26:00,080 --> 00:26:01,730
늦게 와서 아침도 못 먹고 나왔어

597
00:26:01,730 --> 00:26:02,800
애들 몇 시에 시간 돼요

598
00:26:02,800 --> 00:26:04,060
아니면 술 많이 먹었어요

599
00:26:04,060 --> 00:26:05,460
대해서 많이 많이 먹었어

600
00:26:05,460 --> 00:26:07,170
이렇게 구체적으로 물어보는데

601
00:26:07,170 --> 00:26:10,690
되게 액션에도 클래스가 되게 다양하기 때문에 구체적인 답변이나

602
00:26:10,690 --> 00:26:13,870
아니면 긴 문장 에 대해서도 구체적인 답변을 낼 수 있는

603
00:26:13,870 --> 00:26:15,850
그런 특성을 보이고 있습니다

604
00:26:15,850 --> 00:26:16,800
그리고 자기가 아까

605
00:26:16,800 --> 00:26:20,030
한 가지 더 강조했던 부분 중 하나는 이해할 수 있다

606
00:26:20,030 --> 00:26:20,850
하는데요

607
00:26:20,850 --> 00:26:23,960
어 저희가 만든 이렉션 보다는 지금 허리를 하나를 보여드렸죠

608
00:26:23,960 --> 00:26:26,610
만 여러 개 거리를 보여 드리려고 해요

609
00:26:26,610 --> 00:26:28,880
이런 상황에서 우울해 무슨 일 있어요

610
00:26:28,880 --> 00:26:32,070
뭐 크리스마스인데 남았어 좋은 사람 만날 수 있을까요

611
00:26:32,070 --> 00:26:33,360
그럴까 그럴까 이런 식의

612
00:26:33,360 --> 00:26:37,380
뭔가 문맥을 파악할수있는 답변이 가능한데요

613
00:26:37,380 --> 00:26:41,990
그러면 그럴까 를 고정하고 문맥을 바꾸면 어떻게 될까요

614
00:26:41,990 --> 00:26:45,090
얘들아 신난다 신난다 무슨 일 있어요

615
00:26:45,090 --> 00:26:48,510
오늘 날씨가 너무 좋아 한강이 나도 가요 그럴까 같이 갈래요

616
00:26:48,510 --> 00:26:50,290
이런 것처럼 어디에 갈지

617
00:26:50,290 --> 00:26:54,020
어떤 것에 갈지 에 대한 문맥을 파악하고 상대방에게 갈까요

618
00:26:54,020 --> 00:26:55,020
라는 질문에 해서

619
00:26:55,020 --> 00:26:58,440
상대방에 대화를 유도하는 그런 전략을 보여주고 있습니다

620
00:26:58,440 --> 00:27:01,990
할 건 역시 제가 어저께 밤에 발표

621
00:27:01,990 --> 00:27:04,580
자료 만들어서 애한테 시도를 해 봐

622
00:27:04,580 --> 00:27:06,580
피곤하면 먼저 자요

623
00:27:06,580 --> 00:27:08,460
이따가 집에 가서 자면 되는

624
00:27:08,460 --> 00:27:12,480
그런 위로해주는 모습도 보여 줄 수 있었습니다

625
00:27:12,480 --> 00:27:15,610
이런 데 뭐 같은 경우는 저 이제 홈페이지에 들어가 보시면

626
00:27:15,610 --> 00:27:18,130
실제로 여러분들 실시간으로 해 보실 수 있고요

627
00:27:18,130 --> 00:27:20,050
그 외에 다양한 문맥들을 넣어 보시고

628
00:27:20,050 --> 00:27:21,330
또 답변을 어떻게 나오는지

629
00:27:21,330 --> 00:27:25,750
일을 오실 수 있기 때문에 되게 재밌을 것 같아요

630
00:27:25,750 --> 00:27:28,270
또한 단순히 리액션 모델만 가지고

631
00:27:28,270 --> 00:27:30,890
인공지능만들기 다 어려워 냐면

632
00:27:30,890 --> 00:27:33,080
인공지능은 되게 다양한 말을 해야 되잖아요

633
00:27:33,080 --> 00:27:36,980
근데 해보면 단순한 쪽은 약간

634
00:27:36,980 --> 00:27:40,180
간단한 말밖에 할 수 없기 때문에 좀 더 구체적인 답변이나

635
00:27:40,180 --> 00:27:42,820
아니면 특정 프로필에 대한 질문 돼

636
00:27:42,820 --> 00:27:44,930
이런 것들을 대답할 줄 알아야 돼요

637
00:27:44,930 --> 00:27:46,980
그렇게 렉스턴 모델 뿐만 아니라

638
00:27:46,980 --> 00:27:50,410
다른 모델들도 다 출발해서 제가 보여 드린 것은 페이스북

639
00:27:50,410 --> 00:27:53,340
메신저에서 지금 서비스를 하고 있고

640
00:27:53,340 --> 00:27:55,690
지금 제가 다 설명드리지 못 하겠지만

641
00:27:55,690 --> 00:27:58,720
이외에 모델들은 제가 네이버테크 발표했던 자료가 있어서

642
00:27:58,720 --> 00:28:00,470
아래 링크를 통해 보시면

643
00:28:00,470 --> 00:28:03,810
좀 더 도움이 되실 수 있을 것

644
00:28:03,810 --> 00:28:09,860
그래서 저희가 이제 앞으로 더 전에 나가야 되거든요

645
00:28:09,860 --> 00:28:12,920
gpt ppt 로 만든 인공

646
00:28:12,920 --> 00:28:15,720
지능 소설처럼 답변을 못 선택하는 게 아니라

647
00:28:15,720 --> 00:28:17,670
진짜 답변에 생성할 수 있는 모델

648
00:28:17,670 --> 00:28:18,910
같은 걸 만들어 보고 싶어요

649
00:28:18,910 --> 00:28:22,710
뭐 아니면 개인화 답변 사용자가 여친과 헤어진 상태인지

650
00:28:22,710 --> 00:28:24,850
안헤어지는 장생지 에 대해서 답변 달라질 수 있잖아

651
00:28:24,850 --> 00:28:27,680
이럴 때는 너 연애중이라고 물어봤을 때

652
00:28:27,680 --> 00:28:29,560
나 연애 중이야 라고 대답할 수 있고

653
00:28:29,560 --> 00:28:31,070
아닌 상태에서는 나 연애 중 아닌데

654
00:28:31,070 --> 00:28:32,540
이렇게 대답할 수 있어

655
00:28:32,540 --> 00:28:35,990
개인 하다 보면 또 아까 말씀드렸던 것처럼

656
00:28:35,990 --> 00:28:39,490
페르소나 사용자마다 문명이다 했기 때문에 사용

657
00:28:39,490 --> 00:28:44,390
알라딘의 캐릭터의 말투로 이용해서 답변에 만들어라

658
00:28:44,390 --> 00:28:46,540
이렇게 만들 수 있는 문제가 남아 돼

659
00:28:46,540 --> 00:28:50,320
그리고 더 지금보다 더 긴 문맥을 이해할 수 있고

660
00:28:50,320 --> 00:28:52,390
또 중간에 문맥에 바뀌면 빠르게 해체해서

661
00:28:52,390 --> 00:28:56,480
운명을 커트 할 수 있는 덕인 컨텍스트 못 해

662
00:28:56,480 --> 00:28:58,860
우리가 먼저 자 통관에 더 똑똑하고

663
00:28:58,860 --> 00:29:01,640
더 진짜 사람 같이 소름돋는 인공지능은 안 돼

664
00:29:01,640 --> 00:29:04,670
그냥 모든 것들을 앞으로 더 진행을 할 예정입니다

665
00:29:04,670 --> 00:29:06,030
그래서 우리랑 같이

666
00:29:06,030 --> 00:29:07,810
이런 문제를 풀고 싶은 분들은

667
00:29:07,810 --> 00:29:10,620
핑퐁 팀에 오시면 굉장히 좋을 거 같고

668
00:29:10,620 --> 00:29:12,020
또 뒤에 부스를 하고 있으니깐

669
00:29:12,020 --> 00:29:13,730
관심있으신 분들은 오셔서 많은데

670
00:29:13,730 --> 00:29:16,410
먹어라 또 여러 얘기를 해 보시면

671
00:29:16,410 --> 00:29:19,290
되게 좋은 걸 많이 얻어 가실 수 있을 것 같습니다

672
00:29:19,290 --> 00:29:22,400
이렇게 지도하겠습니다 감사합니다
