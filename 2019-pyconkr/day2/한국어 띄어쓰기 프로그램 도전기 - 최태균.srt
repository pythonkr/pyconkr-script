1
00:00:02,900 --> 00:00:08,280
네 안녕하세요 많은 자리가 이렇게 찾았네요

2
00:00:08,280 --> 00:00:10,380
이른 아침에 돌고 하고 일요일인데

3
00:00:10,380 --> 00:00:15,260
시간을 내주셔서 제 자리에 와 주셔서 너무 감사드립니다

4
00:00:15,260 --> 00:00:18,050
시작하게 앞서서 혹시

5
00:00:18,050 --> 00:00:20,620
여기서 제가 좀 질문을 좀 할 건데

6
00:00:20,620 --> 00:00:24,110
혹시 자연어 처리 에 대해서 좀 개발이나 연구를 하고 계시거나

7
00:00:24,110 --> 00:00:26,600
또는 머신러닝에 대해서 좀 배경

8
00:00:26,600 --> 00:00:31,110
아시는 분 계시는지 한 번만 손을 좀 들어 보실 수 있어

9
00:00:31,110 --> 00:00:34,910
네 네 상당히 많습니다

10
00:00:34,910 --> 00:00:36,660
제가 어떤 걸 기대하고

11
00:00:36,660 --> 00:00:38,270
많이 오셨는지 모르겠지만은

12
00:00:38,270 --> 00:00:41,050
제가 발표하고자 하는 거에 대해서 도전 빕니다

13
00:00:41,050 --> 00:00:45,020
해서 좀 되게 좀 쉬운데

14
00:00:45,020 --> 00:00:48,320
뭐 좀 되게 간단한 걸 왜 고급으로 두고 얘기했지

15
00:00:48,320 --> 00:00:50,720
뭐 이런 생각이 좀 늦을 수도 있겠지만

16
00:00:50,720 --> 00:00:54,740
은 어떻게 보면 좀 기본적인 개발에 대한 거

17
00:00:54,740 --> 00:00:56,620
들을 이야기를 풀고자 합니다

18
00:00:56,620 --> 00:01:02,510
그래서 그런 부분에 맞춰서 보여 주셨으면 좋겠고요

19
00:01:02,510 --> 00:01:04,250
안녕하세요 저는 최태균 이고

20
00:01:04,250 --> 00:01:06,620
그리고 자연어처리 개발자입니다

21
00:01:06,620 --> 00:01:09,440
제가 오늘 발표할 내용은 한국어

22
00:01:09,440 --> 00:01:12,900
띄어쓰기 프로그램도 전기입니다

23
00:01:12,900 --> 00:01:14,420
이번 발표회에서는 제가 한 달

24
00:01:14,420 --> 00:01:17,060
반 동안 띄어쓰기 프로그램 개발을 했는데

25
00:01:17,060 --> 00:01:19,380
이거에 대한 시도는 어땠고

26
00:01:19,380 --> 00:01:20,860
그리고 결과가 어떠한 있는지

27
00:01:20,860 --> 00:01:25,990
좀 공유하여 가지도록 이야기는 크게

28
00:01:25,990 --> 00:01:28,170
다섯 개로 나눠서 얘기를 합니다

29
00:01:28,170 --> 00:01:30,470
그래서 서론에서는 제 띄어쓰기

30
00:01:30,470 --> 00:01:33,290
프로그램이 왜 필요했는지

31
00:01:33,290 --> 00:01:37,340
그리고 한계가 어떤 것들이 있는지 이야기를 하고

32
00:01:37,340 --> 00:01:39,230
그런 다음에 띄어쓰기 프로그램

33
00:01:39,230 --> 00:01:41,610
구조는 어떤 식으로 설계를 했고

34
00:01:41,610 --> 00:01:45,420
그리고 모델 개발은 어떻게 꼭 결과가 어떻게 나왔는지

35
00:01:45,420 --> 00:01:46,240
그런 얘기를 하고

36
00:01:46,240 --> 00:01:51,600
마지막으로 한국어 버트를 먹을래 많이 나온 모델이다 보니까

37
00:01:51,600 --> 00:01:56,040
이런 모델을 활용했을 때 결과 어떻게 나오는지

38
00:01:56,040 --> 00:01:57,560
이제 마지막 변론 얘기하면서

39
00:01:57,560 --> 00:02:01,120
제 이야기 마무리 합니다

40
00:02:01,120 --> 00:02:05,540
30초부터 이야기를 시작해 보도록 하겠습니다

41
00:02:05,540 --> 00:02:06,970
자연어 처리 해서

42
00:02:06,970 --> 00:02:08,430
이제 띄어쓰기를 통해서

43
00:02:08,430 --> 00:02:13,310
이제 입력 텍스트를 가지고 토큰 다니는 나눠서 보는데

44
00:02:13,310 --> 00:02:15,020
이런 토큰 단위로 나는 것은

45
00:02:15,020 --> 00:02:19,590
이제 스페이스 단위로 쉽게 나눌 수가 있겠어

46
00:02:19,590 --> 00:02:22,340
한국어에서는 이런 부분을 가지고 하는데

47
00:02:22,340 --> 00:02:25,150
있어서 띄어쓰기가 큰 영향을 줍니다

48
00:02:25,150 --> 00:02:27,410
왜냐면은 텍스트 하나하나

49
00:02:27,410 --> 00:02:28,620
토큰 마더 에 대해서

50
00:02:28,620 --> 00:02:31,900
의문을 9분하는게 영향이 좀 가거든요

51
00:02:31,900 --> 00:02:36,340
그래서 좀 샘플 좀 보면서 하겠습니다

52
00:02:36,340 --> 00:02:37,900
띄어쓰기가 어떤 영향을 줄 수 있는지

53
00:02:37,900 --> 00:02:39,550
한번 좀 살펴보려는 거 같아요

54
00:02:39,550 --> 00:02:41,010
여기 예시로 아버지가

55
00:02:41,010 --> 00:02:43,700
방에 들어가신다 라고 되어 있는데

56
00:02:43,700 --> 00:02:46,070
이제 띄어쓰기가 맞다고 도 볼 수 있습니다

57
00:02:46,070 --> 00:02:50,060
근데 여러분들도 아시다시피 아버지 가방에 들어가신다

58
00:02:50,060 --> 00:02:52,300
라고도 이해할 수 있겠죠

59
00:02:52,300 --> 00:02:53,750
좀 몸매가 없이 띄어쓰기를

60
00:02:53,750 --> 00:02:55,420
좀 보다 보면은 의미를 좀

61
00:02:55,420 --> 00:02:57,330
명확하게 파악하지 못하는 점이 있고

62
00:02:57,330 --> 00:02:59,410
이러한 점이 자연어처리를 하는데

63
00:02:59,410 --> 00:03:04,130
있어서 어려움을 겪게 합니다

64
00:03:04,130 --> 00:03:06,610
제 형태소 분석 같은 경우가 띄어쓰기로 인해서

65
00:03:06,610 --> 00:03:08,860
좀 문제가 발생할 수 있는 케이스인데요

66
00:03:08,860 --> 00:03:12,230
여기 문장 예시를 보시면은 너무 기대 안 하고 갔나

67
00:03:12,230 --> 00:03:12,870
재밌게 봤다

68
00:03:12,870 --> 00:03:16,250
가까이 있는 요걸 코엔엘파이 okt 형태소

69
00:03:16,250 --> 00:03:18,380
분석기 를 통해서 결과를 보면은

70
00:03:18,380 --> 00:03:20,420
우리 기대에는 너무 기대 안 하고

71
00:03:20,420 --> 00:03:23,470
와 같은 방식으로 분석이 돼야 되는데

72
00:03:23,470 --> 00:03:26,210
여기서는 너무 기대 안

73
00:03:26,210 --> 00:03:29,580
나 같은 방식으로 형태소 분석 이 되어 있습니다

74
00:03:29,580 --> 00:03:32,910
제 이런 띄어쓰기 문제를 해결하고자

75
00:03:32,910 --> 00:03:35,670
프로그램들은 좀 나와서 높은 수도 있고요

76
00:03:35,670 --> 00:03:37,930
근데 대체로 미리 학습된

77
00:03:37,930 --> 00:03:41,220
알고리즘으로 구성이 되어 있습니다

78
00:03:41,220 --> 00:03:44,480
프로그램들은 좀 보면은 텍스트

79
00:03:44,480 --> 00:03:47,160
코퍼스에 크게 영향을 많이 받게 되는데

80
00:03:47,160 --> 00:03:50,180
그 코피어스 도민이 달라짐에 따라서

81
00:03:50,180 --> 00:03:53,610
띄어쓰기 성능들이 조금씩 달라질 수 있습니다

82
00:03:53,610 --> 00:03:55,210
대표적 사례로 오픈소스

83
00:03:55,210 --> 00:03:57,370
타이코 스페이스 년 걸려 안 돼요

84
00:03:57,370 --> 00:04:00,770
여기에 입력으로 너는 나의 원수야 라고 하는 제 구어체

85
00:04:00,770 --> 00:04:02,200
문장의 입력을 해 봤습니다

86
00:04:02,200 --> 00:04:04,930
물론 띄어쓰기는 안한 상태이긴 하지만

87
00:04:04,930 --> 00:04:08,500
이걸 8코스 피싱에 넣었을때는 너는 나의 의원

88
00:04:08,500 --> 00:04:10,220
수 이런 식으로 띄어쓰기가

89
00:04:10,220 --> 00:04:12,780
우리가 기대했던 것만큼 만족할 수 있는

90
00:04:12,780 --> 00:04:16,990
띄어 써야 되지 않은 결과를 볼 수가 있습니다

91
00:04:16,990 --> 00:04:17,850
이러한 과정을 보고

92
00:04:17,850 --> 00:04:20,510
저는 제가 수집한 데이터셋을 가지고

93
00:04:20,510 --> 00:04:23,320
띄어쓰기 알고리즘 만들 수 있는 프로그램을 생각해

94
00:04:23,320 --> 00:04:24,360
봤는데요

95
00:04:24,360 --> 00:04:26,830
여기서 이제 띄어쓰기 프로그램을 얘기할 건데

96
00:04:26,830 --> 00:04:29,230
주로 실행과 학습이

97
00:04:29,230 --> 00:04:33,760
주 에 대한 설계를 이야기할 먼저 띄어쓰기 프로그램

98
00:04:33,760 --> 00:04:35,350
실행 구조를 보겠습니다

99
00:04:35,350 --> 00:04:38,390
먼저 텍스트 문장을 입력을 할 거고요

100
00:04:38,390 --> 00:04:40,890
모든 띄어쓰기 공백을 제거하고

101
00:04:40,890 --> 00:04:44,020
그리고 내가 학습한 띄어쓰기 모델을 통해서

102
00:04:44,020 --> 00:04:47,730
텍스트를 출력하는 구조가 되겠습니다

103
00:04:47,730 --> 00:04:49,350
학습 가능한 띄어쓰기 프로그램

104
00:04:49,350 --> 00:04:51,620
학교에서 모레 학습과정의 필수적인데

105
00:04:51,620 --> 00:04:53,960
이제 모델 학습은 다음과 같은

106
00:04:53,960 --> 00:04:57,310
2 과정을 거치게 됩니다

107
00:04:57,310 --> 00:05:01,190
먼저 띄어쓰기를 할 일에 띄어쓰기 학습데이터를

108
00:05:01,190 --> 00:05:02,990
이제 데이터를 구성을 하고

109
00:05:02,990 --> 00:05:06,540
그 데이터를 토대로 모델 학습과 평가를 합니다

110
00:05:06,540 --> 00:05:08,130
평가한 후에는 테스트 성능

111
00:05:08,130 --> 00:05:11,720
확인한 다음에 만족한 성능이 나와 나오면

112
00:05:11,720 --> 00:05:13,250
그걸 재활용하면 되고

113
00:05:13,250 --> 00:05:14,480
아닌 경우에는 이

114
00:05:14,480 --> 00:05:20,030
두 가지 과정을 계속해서 반복할 수 있도록 합니다

115
00:05:20,030 --> 00:05:22,390
띄어쓰기 프로그램 구조설계 할 때는 가급적

116
00:05:22,390 --> 00:05:25,200
객체지향적인 구현을 시도했습니다

117
00:05:25,200 --> 00:05:27,990
이러한 시도는 뭐 대학생의 평가

118
00:05:27,990 --> 00:05:29,390
음악 실행

119
00:05:29,390 --> 00:05:32,180
그리고 학습 기능을 9분하는데 있어서

120
00:05:32,180 --> 00:05:36,150
이제 9분해서 개발하는데 효과적이었습니다

121
00:05:36,150 --> 00:05:38,070
띄어쓰기 프로그램 구조에 대해서 잠시 살펴보고

122
00:05:38,070 --> 00:05:40,160
가도록 하겠습니다

123
00:05:40,160 --> 00:05:43,770
먼저 컨피규레이션 다 제이슨 파일을 설정을 해 놓고

124
00:05:43,770 --> 00:05:47,490
여기에는 모델 학습이나 실행 거 같은 설정들

125
00:05:47,490 --> 00:05:49,410
여기다 담아 놔 할머니

126
00:05:49,410 --> 00:05:55,550
값들을 이젠 실행중인 에이전트 등록을 하게 되는데요

127
00:05:55,550 --> 00:05:57,560
액체는 모델과 토크나이저

128
00:05:57,560 --> 00:05:59,530
그리고 단어사전 등을 가지고 있습니다

129
00:05:59,530 --> 00:06:01,930
이걸 가지고 학습평가

130
00:06:01,930 --> 00:06:05,780
실행 기능을 수행할 수 있도록 합니다

131
00:06:05,780 --> 00:06:08,830
각 실행 함수는 학습 데이터관리 평가

132
00:06:08,830 --> 00:06:11,450
객체라는 별도의 객체를 더워서

133
00:06:11,450 --> 00:06:17,120
제각 함수안의 수행하는데 주요한 역할을 하게 되고

134
00:06:17,120 --> 00:06:19,930
이렇게 설계한 프로그램 구조는 단가 가지 제

135
00:06:19,930 --> 00:06:25,060
간단한 구현을 통해서 실행이 가능하도록 했습니다

136
00:06:25,060 --> 00:06:27,550
이제 띄어쓰기 프로그램 구조를 좀 봤다면

137
00:06:27,550 --> 00:06:29,780
본격적으로 핵심 인제 띄어쓰기

138
00:06:29,780 --> 00:06:34,300
모델개발에 대해서 이야기해 보도록 하겠습니다

139
00:06:34,300 --> 00:06:36,710
쓰기 모델은 시퀀스 분류 모델을 가지고

140
00:06:36,710 --> 00:06:40,240
구현함에 예를 들어서 오늘 서울 날씨

141
00:06:40,240 --> 00:06:43,220
나는 이제 텍스트가 있는데 이 텍스트를 모델을 입력

142
00:06:43,220 --> 00:06:45,760
하면은 띄어쓰기 정보로 음절

143
00:06:45,760 --> 00:06:49,700
위치에 비 또는 아이와 같은 책을 가지고

144
00:06:49,700 --> 00:06:52,550
정보에 대한 예측을 하는 겁니다

145
00:06:52,550 --> 00:06:54,940
띄어쓰기 모델은 대표적으로 아래는

146
00:06:54,940 --> 00:06:57,800
그리고 혹시 아래표와 같은 알고리즘 활용하는데

147
00:06:57,800 --> 00:07:01,160
제가 베이스 라인으로 활용할 모델은 이제 파

148
00:07:01,160 --> 00:07:04,830
lstm-crf 바이러스

149
00:07:04,830 --> 00:07:09,540
mcrf 모델은 아래는 교회 모델 중에 gardens london

150
00:07:09,540 --> 00:07:11,370
london 메모리라는 모델과

151
00:07:11,370 --> 00:07:13,100
그리고 컨디션 랜덤필드

152
00:07:13,100 --> 00:07:15,970
이라는 모델로 구성이 되어 있습니다

153
00:07:15,970 --> 00:07:17,970
balsan 같은 경우는

154
00:07:17,970 --> 00:07:20,030
입력한 토큰과 picks

155
00:07:20,030 --> 00:07:23,770
정보를 조합해서 띄어쓰기 지점인지 를 예측하고

156
00:07:23,770 --> 00:07:27,820
그리고 crf 는 더 나은 예측값의 순서

157
00:07:27,820 --> 00:07:30,910
보정하는 역할을 함

158
00:07:30,910 --> 00:07:32,550
실제 모델 고양이 어떻게 되는지

159
00:07:32,550 --> 00:07:36,810
좀 코드 좀 보겠습니다 이 모델은 파이토치 기반으로 보면

160
00:07:36,810 --> 00:07:39,800
되고 그게 모델생성 괄호

161
00:07:39,800 --> 00:07:44,130
수연산 그리고 모델 추론 등으로 구성이 되어 있습니다

162
00:07:44,130 --> 00:07:46,530
첫 번째로 모델 생성을 보도록 하겠습니다

163
00:07:46,530 --> 00:07:48,410
모델 생성은 앞서 보았던 칵

164
00:07:48,410 --> 00:07:51,100
네트워크들을 생성하는 과정인데

165
00:07:51,100 --> 00:07:54,970
워드임베딩 내려와 봐 lstm

166
00:07:54,970 --> 00:07:58,750
그리고 10월에 플레이어를 생성을 하고 있음

167
00:07:58,750 --> 00:08:01,500
생성된 네트워크는 로스 값을 구하거나

168
00:08:01,500 --> 00:08:03,950
모델 추론 연상이 사용하게 되는데

169
00:08:03,950 --> 00:08:05,950
먼저 로스 연산하는 거부터

170
00:08:05,950 --> 00:08:08,060
먼저 보시면은 패딩

171
00:08:08,060 --> 00:08:12,420
정보를 무시하기엔 마스크를 먼저 생성을 합니다

172
00:08:12,420 --> 00:08:15,280
그런 다음에 일을 가지고 입력

173
00:08:15,280 --> 00:08:17,660
입력 것과 함께 모델 연산을 하고

174
00:08:17,660 --> 00:08:19,260
마지막을 샤를 플레이어에 와서

175
00:08:19,260 --> 00:08:22,370
로스까스 출력하도록 했습니다

176
00:08:22,370 --> 00:08:24,700
모델 추로스 가면 사는 것과

177
00:08:24,700 --> 00:08:27,850
이제 유사한 놀이터 있는데

178
00:08:27,850 --> 00:08:30,330
여기서 그 차이는 마지막 Siri

179
00:08:30,330 --> 00:08:32,110
플레이어에서 BTOB

180
00:08:32,110 --> 00:08:34,620
디코딩을 활용해서 최적의 띄어쓰기

181
00:08:34,620 --> 00:08:36,390
시퀀스를 출력할 수 있도록 하는데

182
00:08:36,390 --> 00:08:39,170
있어서 차이가 있습니다

183
00:08:39,170 --> 00:08:41,310
이렇게 학습할 모델을 구현했다면

184
00:08:41,310 --> 00:08:44,690
이제 모델 학습 데이터셋이 이제 필요할겁니다

185
00:08:44,690 --> 00:08:46,380
구축할 데이터셋은 띄어쓰기가

186
00:08:46,380 --> 00:08:48,560
잘 된 데이터 쓰셔야 되는데

187
00:08:48,560 --> 00:08:51,370
어 이런 데이터는 대체로 세종코퍼스

188
00:08:51,370 --> 00:08:53,570
그리고 위키피디아 데이터

189
00:08:53,570 --> 00:08:57,710
신문 데이터셋 정도가 있습니다 이 중에 저는 세종코퍼스

190
00:08:57,710 --> 00:09:00,800
데이터셋을 활용하고자 합니다

191
00:09:00,800 --> 00:09:02,760
세종코퍼스 데이터 수집은 깃허브에

192
00:09:02,760 --> 00:09:05,260
제쿠로 엔지니어라는 분께서 세종코퍼스

193
00:09:05,260 --> 00:09:07,450
이제 코제트를 만드셨는데

194
00:09:07,450 --> 00:09:08,880
어 이걸 활용하였습니다

195
00:09:08,880 --> 00:09:11,210
이걸 가지고 가려고 하면은 간단하게

196
00:09:11,210 --> 00:09:13,710
내주 레커맨드 만으로도 띄어쓰기

197
00:09:13,710 --> 00:09:17,790
문장을 구축할 수 있었고요

198
00:09:17,790 --> 00:09:20,350
이제 구축한 데이터셋은 코퍼스란

199
00:09:20,350 --> 00:09:22,730
160만 개 정도 되었습니다

200
00:09:22,730 --> 00:09:25,580
그리고 백만 개 정도의 문장 있었고요

201
00:09:25,580 --> 00:09:29,330
문장에서는 80% 정도는 문어체 였고

202
00:09:29,330 --> 00:09:32,230
20% 정도가 구어체로 구성되어 있었습니다

203
00:09:32,230 --> 00:09:36,080
제 데이터 분석을 좀 보려 하는데

204
00:09:36,080 --> 00:09:40,380
학습 데이터에 대한 문제를 먼저 살펴 보았습니다 이 경우는

205
00:09:40,380 --> 00:09:41,470
어절단위 경우는 한

206
00:09:41,470 --> 00:09:44,170
십시 정도에 크게 많이 분포되어 있었고

207
00:09:44,170 --> 00:09:48,190
가장 긴 문장의 경우는 한 백 정도의 길에 있었습니다

208
00:09:48,190 --> 00:09:50,700
음절의 경우에는 한 10에서 30정도의 크게

209
00:09:50,700 --> 00:09:55,750
분포가 가장 긴 길이가 130 있었는데 이 정권은 나중에

210
00:09:55,750 --> 00:10:00,440
모델 하이퍼파라미터 활용하는 데 사용됩니다

211
00:10:00,440 --> 00:10:03,600
아 또 확인해 본 거는 세종코퍼스 다 어

212
00:10:03,600 --> 00:10:05,370
절 단어에 대한 공포였습니다

213
00:10:05,370 --> 00:10:08,120
나중에 모델 예측을 할 때

214
00:10:08,120 --> 00:10:12,660
어느 정도 좀 추론을 하고자 얻은 정보인데

215
00:10:12,660 --> 00:10:16,860
주로 보시면은 동사의 관련된 어이가 많이 나와 있고

216
00:10:16,860 --> 00:10:19,190
위중하다 와 관련된 파스

217
00:10:19,190 --> 00:10:21,240
많이 나와 있다는 것을 확인할 수 있었습니다

218
00:10:21,240 --> 00:10:22,820
또 인하

219
00:10:22,820 --> 00:10:25,470
그와 같은 지칭대명사 같은 단어

220
00:10:25,470 --> 00:10:30,980
한 달에 음절 단어들이 좀 많이 보였습니다

221
00:10:30,980 --> 00:10:33,170
모델 학습 방식은 셀프 슈퍼바이저

222
00:10:33,170 --> 00:10:37,860
러닝으로 제 했음 이 방식은 데이터 자체만으로

223
00:10:37,860 --> 00:10:40,740
슈퍼바이스 러닝을 하는 방식인데

224
00:10:40,740 --> 00:10:42,700
입력 데이터 A 에서

225
00:10:42,700 --> 00:10:46,310
레이블링 가능한 상태이기 때문이다

226
00:10:46,310 --> 00:10:48,710
띄어쓰기 경우는 단원 시작과 끝

227
00:10:48,710 --> 00:10:53,360
지점 활용해서 레이블을 생성 할 수가 있습니다

228
00:10:53,360 --> 00:10:57,360
레이블링 방식에는 보통 띄어쓰기 지점을 표시하는 경계

229
00:10:57,360 --> 00:10:59,480
인식 방식을 많이 활용합니다

230
00:10:59,480 --> 00:11:02,750
경계 인식 같은 경우는 경계지점

231
00:11:02,750 --> 00:11:04,970
판별하는 학습을 하는데

232
00:11:04,970 --> 00:11:08,140
여기서 저는 단어 영역을 인식할 수 있는 영역

233
00:11:08,140 --> 00:11:12,480
인식 방식을 같이 구워내서 학습해 봤습니다

234
00:11:12,480 --> 00:11:13,900
보다 구체적으로 레이블링

235
00:11:13,900 --> 00:11:17,120
방송에 대해서 보도록 하겠습니다

236
00:11:17,120 --> 00:11:19,550
경계 인식은 다음 예시와 같이

237
00:11:19,550 --> 00:11:22,050
단어의 시작지점을 경계로 모아서

238
00:11:22,050 --> 00:11:24,650
시작지점을 비긴 아닌

239
00:11:24,650 --> 00:11:28,480
지점을 인사이드로 해서 학습을 했습니다

240
00:11:28,480 --> 00:11:29,730
영역 인식 방식

241
00:11:29,730 --> 00:11:31,690
경로는 감을 시작

242
00:11:31,690 --> 00:11:34,670
중간 지점을 제각각 다른탭으로

243
00:11:34,670 --> 00:11:36,630
학습을 해서 단어의 영역이

244
00:11:36,630 --> 00:11:40,160
어디인지를 알 수 있도록 했습니다

245
00:11:40,160 --> 00:11:41,840
만약에 머저리 한 개

246
00:11:41,840 --> 00:11:43,950
음절로 될 경우에는 싱글 태그로

247
00:11:43,950 --> 00:11:48,730
둬서 벌써 9분을 해 두었고요

248
00:11:48,730 --> 00:11:49,980
어제 학습 데이터에 대한

249
00:11:49,980 --> 00:11:54,050
전체 구성을 어떻게 하는지 보도록 하겠습니다

250
00:11:54,050 --> 00:11:57,620
학습데이터셋 같은 경우는 전체 데이터셋에

251
00:11:57,620 --> 00:11:58,820
90% 를 뒀고

252
00:11:58,820 --> 00:12:02,080
나머지 10% 에 대해서 평가 데이터셋으로 했습니다

253
00:12:02,080 --> 00:12:07,130
검증데이터 세경 5년 학습 데이터 안 돼서

254
00:12:07,130 --> 00:12:08,850
이제 무작위로 50% 를

255
00:12:08,850 --> 00:12:13,410
추출해서 성능을 보는 것으로 했고요

256
00:12:13,410 --> 00:12:16,960
모델 학습 하이퍼파라미터 는 다음과 같습니다

257
00:12:16,960 --> 00:12:20,760
이제 워드임베딩 같은 경우는 보캡 사이즈가 3,700

258
00:12:20,760 --> 00:12:23,650
10개 정도의 32D 면적으로 돼 있고

259
00:12:23,650 --> 00:12:29,190
경우는 64에 양방향으로 구성이 되어 있습니다

260
00:12:29,190 --> 00:12:31,750
옵티마이저 같은 경우는 아담을 활용했고

261
00:12:31,750 --> 00:12:35,790
그리고 기본 러닝메이트로 설정을 해 두었습니다

262
00:12:35,790 --> 00:12:39,560
배치사이즈 128회 길이 제한은 아까 분석한 내용을 토대로

263
00:12:39,560 --> 00:12:42,240
백으로 설정을 했습니다

264
00:12:42,240 --> 00:12:46,940
검증에 포스코가 수정 될 때까지 학습을 했는데

265
00:12:46,940 --> 00:12:50,790
1080 TI gpu 를 통해서 갔을 때

266
00:12:50,790 --> 00:12:56,410
반나절에서 한 하루 정도 걸리는 시간이었습니다

267
00:12:56,410 --> 00:12:59,110
모델 평가는 세 가지로 평가를 했습니다

268
00:12:59,110 --> 00:13:02,700
첫 평가지표는 변개 인식 기준에서 F1

269
00:13:02,700 --> 00:13:05,020
스코어 있는데요 이 평가는

270
00:13:05,020 --> 00:13:07,900
기존 띄어쓰기 모델에서 활용한 방식입니다

271
00:13:07,900 --> 00:13:12,750
두 번째는 war 스포입니다 5월 8일 하는 건데

272
00:13:12,750 --> 00:13:16,650
어조로 음성 인식해서 많이 활용하는 평가 기준입니다

273
00:13:16,650 --> 00:13:18,130
책 한 문장을 정답

274
00:13:18,130 --> 00:13:21,280
문자 하고 비교해서 동일한 문장을 만드는 데

275
00:13:21,280 --> 00:13:24,950
연산 횟수를 가지고 점수내는 방식이고요

276
00:13:24,950 --> 00:13:26,840
마지막으로 sur 인데

277
00:13:26,840 --> 00:13:30,450
이거 같은 경우는 문장이 완전히 일치하는지를 보는점

278
00:13:30,450 --> 00:13:32,420
주셨습니다

279
00:13:32,420 --> 00:13:33,850
이제 모델도 구성했고

280
00:13:33,850 --> 00:13:35,110
데이터도 구축했고

281
00:13:35,110 --> 00:13:39,580
그래서 학습까지 다 돌렸으면 결과를 봐야 되겠죠

282
00:13:39,580 --> 00:13:42,190
제가 다음과 같습니다

283
00:13:42,190 --> 00:13:45,390
서우선 세종코퍼스 평가

284
00:13:45,390 --> 00:13:49,950
데이터 데이터 기준으로 봤을 때는 코스피 신고다

285
00:13:49,950 --> 00:13:53,480
조금 더 나은 성능을 좀 볼 수 있었고

286
00:13:53,480 --> 00:13:55,050
근소한 차이가 나지만

287
00:13:55,050 --> 00:13:57,790
은영 여긴 10시경에 인식 방식

288
00:13:57,790 --> 00:14:02,640
에 비해서 조금 더 높은 것을 볼 수 있습니다

289
00:14:02,640 --> 00:14:04,140
성능도 좀 확인했고

290
00:14:04,140 --> 00:14:08,170
이제 케이스 좀 보도록 하겠습니다

291
00:14:08,170 --> 00:14:09,920
쓰기 예측을 못 하는 경우는

292
00:14:09,920 --> 00:14:13,550
이제 복합명사의 많이 있었습니다

293
00:14:13,550 --> 00:14:15,280
사실 이런 부분은 일반인도

294
00:14:15,280 --> 00:14:17,190
잘 9분하게 좀 쉽지 않습니다

295
00:14:17,190 --> 00:14:18,570
여러분들도 띄어쓰기 하다

296
00:14:18,570 --> 00:14:20,550
보면은 이명사 복합명사

297
00:14:20,550 --> 00:14:23,080
NG 부터 판별해서 띄어쓰기를 하려면은

298
00:14:23,080 --> 00:14:25,800
그게 쉽지가 않은 방법입니다

299
00:14:25,800 --> 00:14:27,350
내 이런 부분에서 모델

300
00:14:27,350 --> 00:14:30,480
예측에서 좀 어려워 하는 부분이 있었고요

301
00:14:30,480 --> 00:14:32,030
아마도 데이터학습 데이터

302
00:14:32,030 --> 00:14:36,160
에서도 크게 영향을 주는 것 같습니다

303
00:14:36,160 --> 00:14:39,490
다른 펄스 케이스는 한글자가 오전 에 대한 띄어쓰기

304
00:14:39,490 --> 00:14:40,360
였음

305
00:14:40,360 --> 00:14:42,620
앞서 데이터 분석을 보면은

306
00:14:42,620 --> 00:14:45,810
한 글자 거절의 대해서 크게 많이 분포되어 있다

307
00:14:45,810 --> 00:14:48,590
라는 걸 눈으로 확인할 수 있었는데

308
00:14:48,590 --> 00:14:51,000
그럼에도 불구하고 띄어쓰기가 잘 안

309
00:14:51,000 --> 00:14:53,420
되는 결과를 볼 수 있었습니다

310
00:14:53,420 --> 00:14:56,660
아마도 한 글자 여전히 경우에는 주변 음절

311
00:14:56,660 --> 00:14:59,650
글자에 따라서 모델이 띄어쓰기를 판단하는데

312
00:14:59,650 --> 00:15:05,720
좀 혼동이 있는 가능성을 좀 확인할 수 있었고 이 점을

313
00:15:05,720 --> 00:15:11,950
모델에 대해서 좀 개선할점 이라고 생각을 했었습니다

314
00:15:11,950 --> 00:15:14,270
이렇게 해서 좀 결과를 봤습니다

315
00:15:14,270 --> 00:15:17,960
내일 모레 학습과목 평가 결과를 받는데

316
00:15:17,960 --> 00:15:21,850
제가 앞서 설명한 경계 인식 방식과 영역인 식빵

317
00:15:21,850 --> 00:15:26,280
지게차 있는 무엇인지 좀 궁금해 하셨을 겁니다

318
00:15:26,280 --> 00:15:28,290
저도 이 부근에 술 많이 궁금했는데

319
00:15:28,290 --> 00:15:29,940
우선 프랑스 케이스를 통해서

320
00:15:29,940 --> 00:15:32,780
두 방식의 차이를 확인하려 했지만은

321
00:15:32,780 --> 00:15:35,340
좀처럼 쉽지는 않았습니다

322
00:15:35,340 --> 00:15:38,110
분명 레이블 방식에선 차이를 뒀었는데

323
00:15:38,110 --> 00:15:43,380
이런 영향 이런 영향이 어디서 볼 수 있는지 좀 고민을 했었고

324
00:15:43,380 --> 00:15:44,870
띄어쓰기 판별하는데 입력

325
00:15:44,870 --> 00:15:47,370
정보가 어떻게 영향을 줄 수 있는지에 대해서

326
00:15:47,370 --> 00:15:50,730
고민을 했었습니다

327
00:15:50,730 --> 00:15:53,240
라임 라임 알고리즘은 보통 분류

328
00:15:53,240 --> 00:15:56,780
모델을 해석 및 검증하는데 사용합니다

329
00:15:56,780 --> 00:15:58,700
기초로 모델 예측을 할 때

330
00:15:58,700 --> 00:16:02,580
크게 영향을 주는 단어 가 무엇인지 보는 사용하는 알고리즘

331
00:16:02,580 --> 00:16:03,310
인데

332
00:16:03,310 --> 00:16:06,540
특히 시각적으로 이렇게 표현해주며

333
00:16:06,540 --> 00:16:12,210
칼로 좀 가장 임팩트있는 알고리즘이란 보고 있습니다

334
00:16:12,210 --> 00:16:14,860
띄어쓰기 에서 라임 알고리즘은 1음절

335
00:16:14,860 --> 00:16:16,980
토큰이 띄어쓰기 예측 할 때

336
00:16:16,980 --> 00:16:20,020
어떤 음절 토큰대리 가장 귀여운 할 수 있는지 확인 안 돼

337
00:16:20,020 --> 00:16:23,730
사용했습니다 A 예시에서 이제 안녕하세요

338
00:16:23,730 --> 00:16:28,620
저는 홍길동입니다 있는데 이 지점에서 홍 이라는 단어의 띄어쓰기

339
00:16:28,620 --> 00:16:33,320
예측을 하는데 음성 토큰을 제거해 보면서 어떤 음

340
00:16:33,320 --> 00:16:38,750
절 토큰이 가장 영향을 줄 수 있는지 보았습니다

341
00:16:38,750 --> 00:16:40,400
어 이러면 이제 라임

342
00:16:40,400 --> 00:16:43,570
알고리즘 통해서 분석을 1별관 보면은

343
00:16:43,570 --> 00:16:45,870
이제 경계 인식 모델의 경우

344
00:16:45,870 --> 00:16:46,910
제 띄어쓰기 전

345
00:16:46,910 --> 00:16:50,220
토큰에서 크게 영향을 주는 것으로 많이 볼 수 있어

346
00:16:50,220 --> 00:16:53,700
영역 인식 방식의 경우에는 띄어쓰기 지점

347
00:16:53,700 --> 00:16:59,270
주변 토큰에서 영양을 고르게 받을 수 있다 라는 걸 확인했습니다

348
00:16:59,270 --> 00:17:02,870
어 옆에 예시를 좀 보시면은 같은 문장이죠

349
00:17:02,870 --> 00:17:07,880
앞서 본 것과 여기서 홍이란 내 위치에 띄어쓰기 개척할 때

350
00:17:07,880 --> 00:17:11,120
경계 인식 방식에서는 혼자 앞에 있는 크게

351
00:17:11,120 --> 00:17:15,290
수치를 영향을 받고 있는 것을 확인할 수 있고

352
00:17:15,290 --> 00:17:16,550
영역 인식 모델의 경우

353
00:17:16,550 --> 00:17:18,530
홍 주변에 있는 음절

354
00:17:18,530 --> 00:17:20,980
토큰이 나름 고른 수치로

355
00:17:20,980 --> 00:17:23,820
영향을 주고 있는 것을 확인할 수 있습니다

356
00:17:23,820 --> 00:17:25,610
어 이 결과로만 봤을 때는

357
00:17:25,610 --> 00:17:29,250
상대적으로 입력정보를 편향적으로 같지 않는 것이

358
00:17:29,250 --> 00:17:31,990
띄어쓰기 예측을 도움을 줄 수 있다는 걸

359
00:17:31,990 --> 00:17:33,060
확인할 수 있었고

360
00:17:33,060 --> 00:17:34,610
그런 점이 영역 인식

361
00:17:34,610 --> 00:17:39,450
모델에서 드러나고 있다는 걸 확인할 수 있었습니다

362
00:17:39,450 --> 00:17:43,500
마지막으로 한 가지 더 보려고 합니다 한국어 버튼이다

363
00:17:43,500 --> 00:17:47,400
네 여기 많이 들어보셨을 분도 있을 것 같은데

364
00:17:47,400 --> 00:17:50,890
여기서 퍼트 모델을 띄어쓰기 모델에서 적용을 했을 때

365
00:17:50,890 --> 00:17:56,710
어떻게 나오고 어떤 영향을 줄 수 있는지 좀 살펴 봐

366
00:17:56,710 --> 00:17:58,460
버튼 알아보기전에 트랜스포머

367
00:17:58,460 --> 00:18:02,880
네트워크를 먼저 알아보도록 하겠습니다

368
00:18:02,880 --> 00:18:07,190
네트워크는 셀프어텐션 으로 이루어진 네트워크입니다 이 기법은

369
00:18:07,190 --> 00:18:12,140
이제 씻고 전체 정보의 관계를 학습하는데

370
00:18:12,140 --> 00:18:13,900
쓰이는 방법인데요

371
00:18:13,900 --> 00:18:17,610
여기서 열어 셀프어텐션 을 돈 멀티에서 텐션을 적용해서

372
00:18:17,610 --> 00:18:24,330
다양한 관점에서 시퀀스가 관계를 학습할 수 있도록

373
00:18:24,330 --> 00:18:29,370
저는 이제 차에서 리코더 모델을 이제 모델로

374
00:18:29,370 --> 00:18:32,670
이제 이루어져 있습니다 이 모델을 한국어

375
00:18:32,670 --> 00:18:38,490
텍스트데이터 를 통해서 먼저 마스킹된 단어를 예측하는 학습하고

376
00:18:38,490 --> 00:18:40,650
다음 문장을 예측한 학습을 하는데

377
00:18:40,650 --> 00:18:42,600
이를 저희는 세미원

378
00:18:42,600 --> 00:18:44,960
슈퍼바이스 러닝 이라고 얘기를 합니다

379
00:18:44,960 --> 00:18:50,090
이렇게 러닝을 통해서 언어모델을 저 만들

380
00:18:50,090 --> 00:18:54,020
이렇게 만들어진 프로테인 모델을 가지고 가게 4

381
00:18:54,020 --> 00:18:56,700
pics 크다가 아이튠 에서 적용해보면

382
00:18:56,700 --> 00:18:58,910
은 기존 테스크 모델 보다

383
00:18:58,910 --> 00:19:04,050
조금 더 나은 성능비를 많이 보이고 있는 편입니다

384
00:19:04,050 --> 00:19:05,820
이제 벅스를 적용한 띄어쓰기 모델

385
00:19:05,820 --> 00:19:07,970
구현 해 보도록 하겠습니다

386
00:19:07,970 --> 00:19:09,960
먼저 세포모델 것

387
00:19:09,960 --> 00:19:12,590
같이 못 엘 네트워크 로 생성을 하는데

388
00:19:12,590 --> 00:19:15,310
가장 중요한 거는 그냥 버튼 모델입니다

389
00:19:15,310 --> 00:19:18,250
이버트 모델은 제가 따로 구현 하지 않았고

390
00:19:18,250 --> 00:19:21,930
허깅페이스 라는 버튼 라이브러리를 활용한 하였습니다

391
00:19:21,930 --> 00:19:25,440
저 간단하게 한 줄로 구현할 수가 있었고

392
00:19:25,440 --> 00:19:27,750
그 다음 댄스 4개를 생성을 합니다

393
00:19:27,750 --> 00:19:31,770
여기서 액티베이션을 타네이치 활용을 했고

394
00:19:31,770 --> 00:19:33,910
그 이후에는 예측

395
00:19:33,910 --> 00:19:35,470
레이블을 출력할 수 있는

396
00:19:35,470 --> 00:19:39,630
리니어레이아웃 없이 생성을 했습니다

397
00:19:39,630 --> 00:19:40,910
이렇게 모델 구성을 하면

398
00:19:40,910 --> 00:19:45,330
바이러스 모델과 연산 가정을 맞춰 주기만 하면 됩니다

399
00:19:45,330 --> 00:19:48,310
여기서 좀 다른 점은 버트 모델의 입력할 값

400
00:19:48,310 --> 00:19:50,790
새로 맞춰 줘야 된다는 거 있는데

401
00:19:50,790 --> 00:19:52,650
모델 입력 마지막 지점에

402
00:19:52,650 --> 00:19:55,710
cls 라는 이제 입력 값을 넣어야 됩니다

403
00:19:55,710 --> 00:19:59,230
네 그래서 이 값을 같이 넣어서

404
00:19:59,230 --> 00:20:03,190
모델이 입력할 수 있도록 구성을 해주는 과정이 있고요

405
00:20:03,190 --> 00:20:09,800
나머지는 바이러스 mcrf 하고 비슷한 과정으로 보시면 되겠습니다

406
00:20:09,800 --> 00:20:13,510
이렇게 구현 버츠 모델 성능을 보면 다음과 같습니다

407
00:20:13,510 --> 00:20:16,710
지존파 lstm-crf 보다 훨씬 높은 데

408
00:20:16,710 --> 00:20:21,290
포스코와 wescosa sos 가 있는데

409
00:20:21,290 --> 00:20:24,760
놀랍게도 좀 버튼레이어 총을 12개를 다 쓰지 않고

410
00:20:24,760 --> 00:20:27,540
한 세 개 정도 레이어만 사용 사용하더라도

411
00:20:27,540 --> 00:20:30,140
충분히 좋은 성능을 낼 수 있는 걸

412
00:20:30,140 --> 00:20:32,760
확인할 수 있었습니다

413
00:20:32,760 --> 00:20:36,130
봤던 거는 한국어 버트 말고

414
00:20:36,130 --> 00:20:40,230
그냥 단순히 모델로 만으로도 학습을 해 봤는데

415
00:20:40,230 --> 00:20:45,280
상당히 좀 효과가 러닝 속도에서는 좀 느린 편이지만

416
00:20:45,280 --> 00:20:47,090
은 성능은 버트와 비슷하게

417
00:20:47,090 --> 00:20:49,060
올라가는 것을 확인할 수 있었습니다

418
00:20:49,060 --> 00:20:55,050
내 하지만 버튼 모델의 아쉬운 점은 모델 출원 속도

419
00:20:55,050 --> 00:20:58,010
바이러스 mcrf 성능과 비교를 하자면

420
00:20:58,010 --> 00:21:04,290
버튼 3레이어 기준에서 3배에서 4배 정도 이상의 성능

421
00:21:04,290 --> 00:21:06,870
속도차가 나는 걸 볼 수가 있었고

422
00:21:06,870 --> 00:21:08,280
문장 길이가 길어지면

423
00:21:08,280 --> 00:21:10,580
길어질수록 속도가 비례해서

424
00:21:10,580 --> 00:21:15,630
늘어난다는 것도 역시 볼 수 있었습니다 이 자체의 이야기의

425
00:21:15,630 --> 00:21:18,410
마무리를 좀 짓도록 하겠습니다

426
00:21:18,410 --> 00:21:21,250
저는 수집한 데이터를 활용한 띄어쓰기

427
00:21:21,250 --> 00:21:23,050
프로그램을 개발했고

428
00:21:23,050 --> 00:21:27,110
세종코퍼스 데이터셋을 통해서 검증을 하고자 있습니다

429
00:21:27,110 --> 00:21:28,660
학습모델 실험을 통해서

430
00:21:28,660 --> 00:21:31,120
모든 범죄에 대한 띄어쓰기

431
00:21:31,120 --> 00:21:33,750
잘 할 수 있지 않다는 점은 확인했고

432
00:21:33,750 --> 00:21:36,220
만약에 띄어쓰기 프로그램을 활용하고자 한다면은

433
00:21:36,220 --> 00:21:39,250
먼저 평가에 데이터셋을 제대로 구축하고

434
00:21:39,250 --> 00:21:40,870
그 다음에 그 그

435
00:21:40,870 --> 00:21:43,010
테스트기준 안에서 확실히

436
00:21:43,010 --> 00:21:45,750
잘 되는 것을 봐야 된다는 점이 중 이따 봤습니다

437
00:21:45,750 --> 00:21:49,010
어 또 다른 얘기는

438
00:21:49,010 --> 00:21:51,690
이제 띄어쓰기 정보를 좀 수용할 수 있는 학습이 필요하다

439
00:21:51,690 --> 00:21:53,130
생각을 했는데

440
00:21:53,130 --> 00:21:56,960
왜냐하면 띄어쓰기 사용자가 입력한 띄어쓰기 정보가 때론

441
00:21:56,960 --> 00:21:59,660
이용할 수 있어서 그랬습니다

442
00:21:59,660 --> 00:22:03,130
마지막으로 띄어쓰기 프로그램 을 개발하기 위해서는

443
00:22:03,130 --> 00:22:07,430
가급적 띄어쓰기가 잘 된 데이터셋을 많이 활용해

444
00:22:07,430 --> 00:22:10,730
보는 것을 관장하도록 하겠습니다

445
00:22:10,730 --> 00:22:13,330
대로 제가 그동안 진행했던

446
00:22:13,330 --> 00:22:14,990
프로젝트를 소개하고자 합니다

447
00:22:14,990 --> 00:22:21,130
타코스 프로젝트입니다 file specified 얘기해서

448
00:22:21,130 --> 00:22:22,500
데이트 학습이 가능한 뛰어쓰기

449
00:22:22,500 --> 00:22:27,180
알고리즘을 귀한 프로젝트 제가 기억했는데

450
00:22:27,180 --> 00:22:29,510
현재 깃허브에 올라온 상태이고

451
00:22:29,510 --> 00:22:33,610
간단하게 명령어를 통해서 설치가 가능합니다

452
00:22:33,610 --> 00:22:35,230
현재는 알파 버전에 있고

453
00:22:35,230 --> 00:22:37,700
개발 진행 사항 개 있는 상태고요

454
00:22:37,700 --> 00:22:40,050
기능이나 성능에 대한 진행 중에 있고

455
00:22:40,050 --> 00:22:41,640
이게 안정화 되었을 때

456
00:22:41,640 --> 00:22:45,800
다시 소셜 믿을 통해서 다시 공개 할 예정입니다

457
00:22:45,800 --> 00:22:48,370
현재는 프로젝트를 받으시면

458
00:22:48,370 --> 00:22:51,180
이렇게 구현해서 띄어쓰기 프로그램을 실행

459
00:22:51,180 --> 00:22:53,620
시킬 수 있습니다

460
00:22:53,620 --> 00:22:59,620
네 제 발표는 여기까지 혹시 궁금한 점 있으시면 질문이 부탁드리겠습니다
