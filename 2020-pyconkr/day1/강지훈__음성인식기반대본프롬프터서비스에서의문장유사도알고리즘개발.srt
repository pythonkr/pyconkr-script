1
00:00:10,790 --> 00:00:13,790
안녕하세요. 발표를 맡은 강지훈입니다

2
00:00:13,820 --> 00:00:17,190
대본 프롬프터 서비스를 개발하면서 겪은 경험 중

3
00:00:17,240 --> 00:00:20,030
문장 유사도 알고리즘 개발 경험을 공유드리고자

4
00:00:20,040 --> 00:00:21,850
발표를 시작하겠습니다

5
00:00:24,990 --> 00:00:27,500
우선 발표자인 저의 소개부터 드리겠습니다

6
00:00:27,740 --> 00:00:32,030
저는 현재 숭실대학교 컴퓨터 학부의 마지막 학기로 재학하고 있고

7
00:00:32,060 --> 00:00:35,880
작년에 소프트웨어 마에스트로 10기 연수생으로 참여하였습니다

8
00:00:36,650 --> 00:00:39,000
그 과정에서 대본 프롬프터 서비스인

9
00:00:39,000 --> 00:00:41,510
스크립트 슬라이드를 기획하고 개발하였는데

10
00:00:42,200 --> 00:00:44,890
그 과정에서 겪은 경험을 공유드리고자 합니다

11
00:00:45,620 --> 00:00:49,510
이후에 실리콘밸리에서 화상회의 스타트업인 c3.chat에서

12
00:00:49,540 --> 00:00:51,920
잡음 인지 프로젝트를 진행하였고

13
00:00:51,950 --> 00:00:55,550
최근에는 SK브로드밴드에서 엘라스틱 서치를 활용해

14
00:00:55,580 --> 00:00:59,780
트렌드를 모니터링 할 수 있는
오픈소스 트레모(tremo)를 개발하였습니다

15
00:01:04,280 --> 00:01:07,100
제가 공유 드리고자 하는 웹서비스의 모습입니다

16
00:01:07,550 --> 00:01:11,290
본격적으로 문장유사도 알고리즘을 개발하는 과정에서

17
00:01:11,310 --> 00:01:14,780
제가 공유드리고자 하는 기능이 어떤 기능인지

18
00:01:14,800 --> 00:01:19,160
어떤 시행착오와 도전을 하였는지 어떻게 구현하였는지

19
00:01:19,190 --> 00:01:21,860
마지막으로 느낀 점을 공유드리고자 합니다

20
00:01:25,160 --> 00:01:26,460
어떤 기술인가요

21
00:01:30,020 --> 00:01:33,790
저는 정치인 아나운서들이 사용하는 대본 프롬프터 기기를

22
00:01:33,820 --> 00:01:39,080
일반인들도 누구나 웹사이트에 접속할 수 있는 노트북과 태블릿만 있다면

23
00:01:39,110 --> 00:01:43,830
프롬프터를 활용하여 누구나 쉽게 발표할 수 있는 웹서비스를 개발하였습니다

24
00:01:44,630 --> 00:01:48,600
노트북과 태블릿은 대본을 보여주는 대본 스크린이 되고

25
00:01:48,630 --> 00:01:52,680
음성인식과 스마트폰은 대본에 넘겨주는 오퍼레이터가 됩니다

26
00:01:53,480 --> 00:01:57,410
그 과정에서 음성으로만 대본 슬라이딩할 수 있는 기능을 위해

27
00:01:57,440 --> 00:02:00,640
문장유사도 알고리즘을 분석하고 개발하였습니다

28
00:02:01,640 --> 00:02:04,520
실제 해당 기능을 사용하는 데모 영상입니다

29
00:02:05,270 --> 00:02:08,740
여러분들은 파이콘에 대해서는 어떻게 생각하시나요

30
00:02:09,500 --> 00:02:16,050
파이콘은 세계 각국의 파이썬 프로그래밍 언어 커뮤니티에서 주관하는 비영리 컨퍼런스입니다

31
00:02:16,910 --> 00:02:22,280
한국의 파이썬 개발자들이 지식을 공유하고 만남을 갖기 위한 장입니다

32
00:02:22,850 --> 00:02:25,850
이제 막 파이썬이 무엇인지 알게 된 사람들

33
00:02:25,880 --> 00:02:31,160
파이썬으로 무언가를 만들고 연구하며 세상에 기여하고 있는 사람들

34
00:02:31,580 --> 00:02:35,690
다른 이에게 파이썬을 더 널리 알리고 싶은 사람들까지

35
00:02:35,720 --> 00:02:39,230
이렇게 다양한 사람들이 모여 있는 파이콘 한국에서

36
00:02:39,260 --> 00:02:42,820
우리는 서로의 경험담에 응원을 보내고

37
00:02:42,830 --> 00:02:45,500
울고 웃으며 많은 이야기를 나눕니다

38
00:02:46,070 --> 00:02:51,790
그렇게 파이콘 한국은 점점 깊어지고 넓어지고 단단해졌습니다

39
00:02:52,610 --> 00:02:55,740
올해도 어김없이 열린 파이콘 한국을 통해

40
00:02:55,760 --> 00:02:59,280
여러분들의 세상이 한 발자국 더 넓어질 수 있기를 바랍니다

41
00:02:59,810 --> 00:03:04,900
이곳에 모인 우리는 함께 걸어갈 수 있는 힘을 가진 파이써니스타들이니까요

42
00:03:05,990 --> 00:03:11,410
기존의 프롬프터는 뒤에서 직접 사람이 넘겨주는 오퍼레이터의 인력이 필요하였습니다

43
00:03:11,990 --> 00:03:15,260
음성인식 기술을 활용해 읽어야 할 대본과

44
00:03:15,290 --> 00:03:20,930
현재 발언 내용을 비교해 발표 흐름에 맞게 자동으로 대본을 전환하는 기술입니다

45
00:03:24,380 --> 00:03:29,730
기능을 개발하는 과정에서 어떤 분석과 문제점이 존재하였는지 공유드리겠습니다

46
00:03:34,190 --> 00:03:38,360
우선 첫 번째로 사용자는 읽어야 할 타겟인 대본을 작성하면

47
00:03:38,390 --> 00:03:41,310
그 작성 대본을 데이터베이스에 저장하게 됩니다

48
00:03:43,670 --> 00:03:47,480
그 이후 사용자가 대본을 따라 읽었을 때 발화를 하게 됩니다

49
00:03:47,840 --> 00:03:53,150
그렇다면 텍스트인 작성 대본과 발화의 음성을 비교하려면 어떻게 해야 할까요?

50
00:03:55,700 --> 00:03:58,250
저는 발화된 음성을 텍스트로 변환하는

51
00:03:58,280 --> 00:04:03,410
Speech to Text인 STT를 사용하여 문장 간의 유사도를 비교하고자 하였습니다

52
00:04:05,420 --> 00:04:08,840
STT를 활용한 시스템 아키텍처의 설계도입니다

53
00:04:09,320 --> 00:04:12,070
스마트폰 웹사이트 인프론트 엔드에서

54
00:04:12,150 --> 00:04:16,470
STT 엔진을 사용해 발화 음성을 발화 문장으로 변환하여

55
00:04:16,500 --> 00:04:18,490
백 엔드 서버에 전송하게 됩니다

56
00:04:19,100 --> 00:04:23,600
그 이후에 서버는 STT 인식 결과와 DB에 저장되어 있던

57
00:04:23,620 --> 00:04:26,120
현재 대본과의 유사도를 비교하여

58
00:04:26,150 --> 00:04:30,110
프론트 사이드의 슬라이드를 할지 말지를 응답하는 구조입니다

59
00:04:34,040 --> 00:04:36,260
실시간 STT 엔진을 사용하여

60
00:04:36,280 --> 00:04:40,620
'여러분은 파이썬 프로그래밍 언어에 대해서 어떻게 생각하시나요'

61
00:04:40,620 --> 00:04:42,470
라는 발화를 진행했을 때

62
00:04:42,500 --> 00:04:46,120
인식 결과는 오른쪽처럼 연속적으로 받아볼 수 있습니다

63
00:04:46,820 --> 00:04:52,230
평균적으로 0.1초에서 0.5초 사이에 응답이 계속해서 이뤄지는데요

64
00:04:52,820 --> 00:04:55,580
슬라이드 기능을 실시간으로 실현시키기 위해

65
00:04:55,610 --> 00:04:59,790
퍼포먼스를 고려하여 알고리즘 함수를 비동기로 처리하였습니다

66
00:05:02,180 --> 00:05:05,440
또한 사용자가 작성할 수 있는 대본 스타일의 경우의 수는

67
00:05:05,460 --> 00:05:08,600
굉장히 많아 하나의 스타일로 변환해줬어야했습니다

68
00:05:09,260 --> 00:05:13,670
작성한 대본과 STT의 인식결과의 싱크를 맞추기 위해서는

69
00:05:13,700 --> 00:05:16,620
발화 대본을 인식 결과에 맞춰줘야 했습니다

70
00:05:17,390 --> 00:05:19,850
작성 대본의 전처리를 진행하였는데요

71
00:05:20,270 --> 00:05:22,830
우선 파이썬 정규 편식을 활용해서

72
00:05:22,870 --> 00:05:27,480
한글 숫자 영어를 제외한 모든 문자를 제거하였습니다

73
00:05:28,050 --> 00:05:31,200
그 이후의 외래어는 한글 발음으로 변환하여

74
00:05:31,220 --> 00:05:32,920
전처리를 진행하였습니다

75
00:05:36,500 --> 00:05:39,770
이제 문장 유사도를 계산하기 위한 준비는 마쳤습니다

76
00:05:40,160 --> 00:05:45,010
이제는 발화된 문장과 작성한 문장의 유사도 알고리즘을 개발해야 합니다

77
00:05:45,680 --> 00:05:49,140
Triple-S Algorithm이라고 저희가 네이밍을 진행해봤는데요

78
00:05:49,580 --> 00:05:53,790
Spoken-Sentence-Similarity
발화 대본유사도입니다

79
00:05:56,450 --> 00:06:00,140
저는 처음에 구글의 문장 유사도 알고리즘을 검색해보고

80
00:06:00,170 --> 00:06:03,760
그 중 가장 간단해 보이는
자카드 유사도을 개발해 보았습니다

81
00:06:04,790 --> 00:06:10,180
두 문장을 각각 집합으로 만든 뒤
두 집합을 통해 유사도를 측정하는 방식입니다

82
00:06:11,030 --> 00:06:16,210
측정하는 방법은 두 집합의 교집합을
두 집합의 합집합으로 나눠줍니다

83
00:06:17,330 --> 00:06:23,180
아래 예시코드에서는 파이썬 자료 구조인
셋을 사용하여 간단하게 작성해 볼 수 있습니다

84
00:06:24,530 --> 00:06:29,940
여기서 각각의 집합은 캐릭터 단위
즉 음절 단위로 셋을 구성하고 있습니다

85
00:06:30,560 --> 00:06:34,590
실제로 위와 같은 origin_sentence와
speech_sentence를

86
00:06:34,620 --> 00:06:40,150
인자로 받아 함수를 실행시켰을 때
유사도는 0.55인 것을 알 수 있습니다

87
00:06:42,740 --> 00:06:46,530
직전의 자카드 유사도 문자 단위로 셋을 구성했습니다

88
00:06:46,940 --> 00:06:53,220
그렇게 구성할 경우 문제점은 문장의 정확한
요소를 집합으로 정의하는 게 아니라고 생각하였습니다

89
00:06:53,960 --> 00:06:59,280
그래서 문자 단위가 아닌 형태소와 명사 단위를 추출하여 셋을 구성해 보았습니다

90
00:07:00,230 --> 00:07:05,450
형태소 분석기 오픈소스인
konlpy의 Komoran 라이브러리를 사용하여

91
00:07:05,480 --> 00:07:07,760
한글의 품사를 추출하고자 하였습니다

92
00:07:08,570 --> 00:07:13,790
오른쪽에 변경된 코드 예시를 보시면
Komoran의 morphs 함수를 사용해서

93
00:07:13,820 --> 00:07:17,990
모든 품사의 형태소를 추출하여
셋을 구성한 것을 알 수 있습니다

94
00:07:19,310 --> 00:07:23,340
실제 형태소로 추출한 결과는 좌상단의 예시와 같고

95
00:07:23,370 --> 00:07:27,330
실제 유사도를 계산했을 때 0.5라는 결과를 알 수 있습니다

96
00:07:28,190 --> 00:07:31,020
그 이후의 형태소로 셋을 구성하는 것이 아니라

97
00:07:31,050 --> 00:07:35,030
키워드 중심,
즉 명사로 구성해 보고자 해보았습니다

98
00:07:35,840 --> 00:07:39,120
아래와 같이 Komoran의 morphs 함수를 사용하여

99
00:07:39,140 --> 00:07:42,600
명사를 추출해 보았고 결과는 좌하단과 같습니다

100
00:07:43,670 --> 00:07:47,070
유사도는 0.36이라는 낮은 결과를 알 수 있었습니다

101
00:07:47,810 --> 00:07:53,320
그 이유는 같은 내용이더라도 하나의 철자가 틀리면
다른 요소라고 판단하기 때문입니다

102
00:07:53,960 --> 00:07:58,160
예를 들어 파이썬과 파이선의 차이를 들 수 있습니다

103
00:08:00,020 --> 00:08:03,560
그 이후에 조금 더 의미적으로
문장 유사도를 계산해 보고자

104
00:08:03,590 --> 00:08:07,410
텍스트로 구성된 하나의 단어에서 특징을 추출하고

105
00:08:07,450 --> 00:08:10,880
수치화한 뒤 딥러닝으로 풀어보고자 생각을 하였습니다

106
00:08:11,720 --> 00:08:16,540
각 문장을 벡터화 하기 위해서는 문장을 이루는 요소를 정의해야 합니다

107
00:08:17,300 --> 00:08:21,650
예시로는 띄어쓰기로 인한 어절로
하나의 문장을 나누었습니다

108
00:08:23,000 --> 00:08:25,630
또한 하나의 요소를 벡터화하는 방법에는

109
00:08:25,660 --> 00:08:31,790
카운트 벡터라이저, tf-idf 벡터라이저, word2vec 등 다양한 방법이 있지만

110
00:08:31,820 --> 00:08:38,980
예시에서는 sklearn 라이브러리의
tf-idf vectorizer를 통해 계산해 보았습니다

111
00:08:40,010 --> 00:08:44,540
두 문장이 각 요소들로 인해
벡터화되어 방향성을 가진다면

112
00:08:44,580 --> 00:08:48,470
다양한 자연어 처리 유사도를 통해
유사도를 계산해 볼 수 있습니다

113
00:08:49,340 --> 00:08:52,880
그 중에서도 코사인 유사도는
두 문장이 가르키는 방향

114
00:08:52,890 --> 00:08:55,010
즉 의미의 차이를 계산하여

115
00:08:55,040 --> 00:08:57,640
코사인 값인 유사도가 100% 같다면

116
00:08:57,660 --> 00:09:02,590
그 결과는 1로 100% 다르면 -1로 나타나는 유사도입니다

117
00:09:03,260 --> 00:09:07,070
예시로 sklearn 라이브러리 cosine_similarity() 함수를 통해

118
00:09:07,100 --> 00:09:10,580
계산해 본 결과 0.46 유사도를 도출할 수 있었습니다

119
00:09:12,770 --> 00:09:15,960
문장을 각각의 요소로 나눈 후 벡터화를 한 뒤에

120
00:09:15,990 --> 00:09:19,120
문장 유사도를 코사인 유사도 이외에도

121
00:09:19,150 --> 00:09:23,400
유클리디언, 맨하탄 유사도를 통해
유사도를 계산해 볼 수 있습니다

122
00:09:24,110 --> 00:09:29,090
유클리디언 유사도는 문장을 이루는
각각의 요소의 거리를 구하는 공식입니다

123
00:09:30,020 --> 00:09:32,270
두 개의 문장이 N개요소

124
00:09:32,290 --> 00:09:37,180
즉 N차원 공간에서 두 점 사이의 최단거리를 구하는 접근 방법입니다

125
00:09:38,270 --> 00:09:41,510
두 문장이 동일한 N개 요소를 가져야 하기 때문에

126
00:09:41,530 --> 00:09:44,120
각각의 요소를 이루는 개수가 다르다면

127
00:09:44,140 --> 00:09:49,480
0과 1 사이 또는 -1과 1 사이의 유사도를 기대할 수 없습니다

128
00:09:50,210 --> 00:09:53,840
그로 인해 각 요소의 값을 더한 크기가 1이 되도록

129
00:09:53,870 --> 00:09:58,670
요소들의 크기를 조절하는 L1 정규화를 통해 전처리를 진행해 보았습니다

130
00:10:00,320 --> 00:10:04,160
유클리디언 유사도는 두 문장의 직선 거리를 계산한 것이라면

131
00:10:04,190 --> 00:10:08,930
맨하탄 유사도는 직선거리가 아닌
사각형 격자로 이뤄진 차원에서

132
00:10:08,950 --> 00:10:11,890
두 문장단거리를 가로지르지 않고

133
00:10:11,910 --> 00:10:15,790
가로 세로 방향으로 도달할 수 있는
최단거리를 구하는 공식입니다

134
00:10:16,340 --> 00:10:20,540
실제 유사도를 계산해 봤을 때 0.48이라는 값을 알 수 있습니다

135
00:10:21,830 --> 00:10:25,160
예시에는 tf-idf 로 문장을 벡터화하여

136
00:10:25,190 --> 00:10:28,680
코사인, 유클리디언, 맨하탄 유사도를 계산하였습니다

137
00:10:29,630 --> 00:10:32,630
빈도를 기준으로 하는 tf-idf 값은

138
00:10:32,660 --> 00:10:37,190
문장 사이에 유사도를 명확하게 도출하긴 어렵다고 판단하여

139
00:10:37,220 --> 00:10:42,110
이후에는 Continuous bag of word(CBOW) 방식과 스킵 그래프(Skip graph) 방식으로

140
00:10:42,140 --> 00:10:47,780
word2vec 워드 임베딩 등을 통해
각 요소들에 유의미한 벡터화까지 진행해 보았지만

141
00:10:47,810 --> 00:10:49,640
결론적으로 포기하게 되었습니다

142
00:10:50,510 --> 00:10:52,970
포기하게 된 문제는 크게 세 가지가 있었습니다

143
00:10:53,930 --> 00:10:58,280
첫 번째는 딜레이 없이 빠르게 계산해야 하는 성능 이슈였습니다

144
00:10:58,940 --> 00:11:02,870
실시간으로 STT 결과를 통해 문장 유사도를 계산할 때

145
00:11:02,900 --> 00:11:07,130
딥러닝 자연어 처리로 접근하게 되면 속도 이슈가 존재하였습니다

146
00:11:07,940 --> 00:11:11,890
발표 특성상 빠르고 정확하게 흐름을 맞춰야 하는데

147
00:11:11,910 --> 00:11:14,390
딜레이가 존재하면 힘든 상황이었습니다

148
00:11:15,770 --> 00:11:19,590
두 번째로 가장 중요했던 건
다국어 지원이 어렵다는 점이었습니다

149
00:11:20,180 --> 00:11:24,610
저희 서비스는 두 달 안에 빠른 글로벌 베타 출시를 목표로 하고 있었습니다

150
00:11:25,250 --> 00:11:30,850
한국어 중국어 일본어 영어
프랑스어 스페인어 베트남어 등

151
00:11:31,270 --> 00:11:34,140
다양한 언어에 맞춘 키워드 추출 기능이나

152
00:11:34,160 --> 00:11:37,450
워드 임베딩을 위한 랭귀지 모델을 구축하기에는

153
00:11:37,480 --> 00:11:39,820
현실적으로 힘들다고 판단하였습니다

154
00:11:40,730 --> 00:11:46,430
그 이유는 각 나라마다 다른 언어는
띄어쓰기 유무, 표의어, 표현어 등

155
00:11:46,460 --> 00:11:48,310
다양한 성격을 띠고 있는데

156
00:11:48,380 --> 00:11:51,960
하나의 기능으로 모든 언어를 커버할 수는 없기 때문입니다

157
00:11:53,120 --> 00:11:58,400
마지막은 음성인식의 정확도가 낮을 경우 의미적으로 분석하기에 부적합했습니다

158
00:11:58,910 --> 00:12:02,130
주변인 조용하고 마이크와 가까운 환경에서는

159
00:12:02,160 --> 00:12:04,910
정확한 STT 결과를 기대할 수 있지만

160
00:12:05,090 --> 00:12:08,220
반대 환경이라면 부정확하였기 때문입니다

161
00:12:09,050 --> 00:12:12,480
결론적으로 문장의 의미를 파악해 유사도를 계산하는

162
00:12:12,510 --> 00:12:15,680
비교 방법을 포기하고 다른 방법을 모색하였습니다

163
00:12:17,030 --> 00:12:18,600
어떻게 구현하셨나요

164
00:12:19,910 --> 00:12:22,880
저는 가장 기본적인 음절 단위에 초점을 맞춰

165
00:12:22,910 --> 00:12:27,230
인위적 유사도 대신 단순 문자열 유사도로 기능을 개발하였습니다

166
00:12:27,980 --> 00:12:33,170
위와 같은 예시의 유사도 비교해서
좌측의 실제 목표 문장을 따라 읽었을 때

167
00:12:33,230 --> 00:12:37,220
STT를 통해 인식되는 결과는 우측과 같았습니다

168
00:12:38,150 --> 00:12:43,320
총장과 송장의 의미는 비슷하지 않지만
'장'이라는 음절이 일치하였고

169
00:12:43,670 --> 00:12:48,420
축사 제안과 축산제한도
인위적으로는 다른 단어지만

170
00:12:48,450 --> 00:12:51,350
'축'과 '제'가 일치하기 때문이었습니다

171
00:12:52,100 --> 00:12:55,070
그래서 저는 문장의 의미에 다가가지 않고

172
00:12:55,100 --> 00:12:57,860
문장을 이루는 문자 자체에 초점을 두어

173
00:12:57,890 --> 00:13:00,390
단순하게 계산해보고자 생각하였습니다

174
00:13:01,880 --> 00:13:04,940
1990년대의 오래된 논문이었지만

175
00:13:04,960 --> 00:13:09,470
'음성인식 기반의 자동 프롬프터 시스템'
이라는 논문으로 인해

176
00:13:09,500 --> 00:13:13,210
의미적으로 계산하는 것보다 음절 단위로 계산하는 것이

177
00:13:13,230 --> 00:13:15,910
알맞은 접근이라고 생각하는 계기가 되었습니다

178
00:13:16,640 --> 00:13:19,520
해당 논문에서는 N-word window

179
00:13:19,540 --> 00:13:24,400
즉 N 개의 단어만 판단하여
현재 읽고 있는 위치를 추적하였습니다

180
00:13:25,010 --> 00:13:30,240
논문의 이념을 참고하여 의미적이 아니라 발화적으로 비교하고자 하였고

181
00:13:30,260 --> 00:13:33,170
추가적인 예외처리 같은 방향으로 고도화하고자

182
00:13:33,200 --> 00:13:36,390
robust한 알고리즘을 개발하고자 결정하였습니다

183
00:13:37,520 --> 00:13:40,970
작성 대본은 우측과 같고
직접 대본을 보고 읽을 때

184
00:13:40,990 --> 00:13:44,080
좌측과 같이 발화한다면 어떻게 대응할 수 있을까요?

185
00:13:45,220 --> 00:13:46,430
대본을 보고 읽더라도

186
00:13:46,440 --> 00:13:50,070
같은 단어를 STT인식 결과가 정확하지 않거나

187
00:13:50,150 --> 00:13:53,630
중간 중간에 애드리브를 추가하여 말한다면 어떻게 할 수 있을까요?

188
00:13:54,440 --> 00:13:56,480
영상을 통해 예시를 보여드리겠습니다

189
00:13:58,070 --> 00:14:00,740
이제서야 막 파이썬을 알게 된 사람들

190
00:14:01,160 --> 00:14:03,860
파이썬으로 어떤 것이든 만들어보고

191
00:14:03,880 --> 00:14:06,620
세상에 기여해보고자 노력하고 있는 사람들

192
00:14:07,280 --> 00:14:11,530
다른 누군가에게 파이썬이 좋다고 알리고 싶은 사람들까지

193
00:14:13,760 --> 00:14:16,850
데모 영상에서 제가 발화한 문장은 우측과 같습니다

194
00:14:17,600 --> 00:14:20,510
이제라는 단어를 이제서야라고 말하고

195
00:14:20,540 --> 00:14:25,540
중간중간 발표 대본을 그대로 따라 읽지 않고 추가적인 애드리브가 발생하였습니다

196
00:14:26,300 --> 00:14:29,660
또한 문자가 일치하는 수도 반밖에 되지 않았는데

197
00:14:29,690 --> 00:14:33,750
어떻게 발표 흐름에 맞춰 슬라이드 기능이 가능하였는지 공유드리겠습니다

198
00:14:34,760 --> 00:14:39,140
저는 최장 공통수열인
LCS 알고리즘을 기반으로 개발하였습니다

199
00:14:39,950 --> 00:14:44,450
발화적으로 접근하는 단순 문자열 알고리즘에는
여러 가지가 있지만

200
00:14:44,480 --> 00:14:47,710
발표 도중에 대본에 없는 말을 길게 하더라도

201
00:14:47,730 --> 00:14:51,660
일치하는 부분만 매칭하기 위해
LCS 알고리즘을 사용하였습니다

202
00:14:52,640 --> 00:14:56,490
예시에서 멋진, 더 멋진, 매우 멋진과 같은

203
00:14:56,530 --> 00:14:59,530
애드리브가 발생하더라도 무시할 수 있기 때문입니다

204
00:15:00,640 --> 00:15:04,040
LCS 알고리즘은 간단한 DP 알고리즘 중 하나로

205
00:15:04,060 --> 00:15:07,020
시간 복잡도 O(N^2)을 가지며

206
00:15:07,340 --> 00:15:10,490
두 문장 사이에서 연속되지 않은 부분은 무시하고

207
00:15:10,510 --> 00:15:14,230
공통되는 문자열의 길이를 찾아낼 수 있는 알고리즘입니다

208
00:15:16,910 --> 00:15:22,400
LCS 알고리즘은 반복문을 수행하면서
두 가지 경우의 수에 따라 값을 결정합니다

209
00:15:23,720 --> 00:15:29,140
두 문자가 같을 때는 대각선 좌측에 있는 숫자에 1을 더한 값을 가집니다

210
00:15:29,810 --> 00:15:34,950
두 문자가 다를 때는
좌측이나 위에 있는 숫자 중 큰 값을 가지게 됩니다

211
00:15:35,780 --> 00:15:38,640
최종적으로 채워지는 값은 두 문장에서

212
00:15:38,670 --> 00:15:42,340
공통된 가장 긴 부분 문자열의 길이를 알아낼 수 있습니다

213
00:15:43,580 --> 00:15:45,350
코드의 예시는 다음과 같습니다

214
00:15:45,920 --> 00:15:49,340
origin_sentence와 speech_sentence를 인자로 받아

215
00:15:49,370 --> 00:15:55,610
두 문장의 길이만큼의 2차원 배열을
0로 채워 LCS 변수의 초기화를 진행합니다

216
00:15:56,660 --> 00:16:01,500
초기화 이후에 엔 제곱의 반복문을 진행하면서 두 가지 경우의 수에 따라

217
00:16:01,540 --> 00:16:06,110
미리 계산해 둔 값을 다시 활용하여 값을 설정합니다

218
00:16:06,140 --> 00:16:11,330
계산을 마친 후 최장 공통 길이 값을 common_cout로 설정하고

219
00:16:11,360 --> 00:16:14,880
원본 대본의 전체 길이를 sum_count로 설정합니다

220
00:16:15,800 --> 00:16:19,510
common_count 값을 sum_count로 나누어 최종적으로

221
00:16:19,610 --> 00:16:23,640
문장 유사도인 similarity를 반환하는 함수입니다

222
00:16:24,800 --> 00:16:29,360
기존 LCS 알고리즘에서 다양한 상황에서도 대본을 넘길 수 있도록

223
00:16:29,390 --> 00:16:32,040
Threshold와 가중치 개념을 추가하였습니다

224
00:16:33,320 --> 00:16:39,070
좌측의 예시 세 가지 때문에 음성인식
결과와 대본이 항상 일치하는 것은 아니었습니다

225
00:16:39,980 --> 00:16:44,360
다양한 상황에서도 robust하게 대응하고자 threshold,

226
00:16:44,390 --> 00:16:49,890
즉 임계치를 설정하여 유사도가 threshold를
넘겼을 때 슬라이딩하였습니다

227
00:16:50,820 --> 00:16:52,990
하지만 처음부터 정확하게 읽을 시,

228
00:16:53,010 --> 00:16:57,590
대본을 끝까지 다 읽지 않았는데도
threshold를 넘길 수 있기 때문에

229
00:16:57,620 --> 00:17:01,220
이러한 문제를 해결하기 위해 가중치를 부여하였습니다

230
00:17:02,210 --> 00:17:05,240
대본의 후반부일 수록 더 높은 가중치를 두어

231
00:17:05,280 --> 00:17:09,600
문장의 뒷부분까지 모두 읽어야
threshold를 넘길 수 있게 하였습니다

232
00:17:10,640 --> 00:17:12,890
추가된 코드 예시는 다음과 같습니다

233
00:17:13,370 --> 00:17:16,790
기존 LCS 알고리즘에서는 문자가 일치했을 때

234
00:17:16,830 --> 00:17:20,590
1를 더해줬다면 이제는 y=x의 그래프처럼

235
00:17:20,590 --> 00:17:22,520
대본에 인덱스를 더해주었습니다

236
00:17:23,170 --> 00:17:29,310
그러면서 전체 유사도를 계산하기 위한 방법도
수정하기 위해 sum_count 값을 수정하였습니다

237
00:17:30,350 --> 00:17:34,220
더 나아가서 발표 최적화를 위해 다양한 시행착오를 거쳤고

238
00:17:34,270 --> 00:17:36,630
그러면서 알고리즘을 고도화하였습니다

239
00:17:38,440 --> 00:17:41,410
첫 번째는 가중치에 로그 함수를 적용하였습니다

240
00:17:41,930 --> 00:17:45,800
기존에 y=x 가중치는 후반부에 과도하게 편향되어

241
00:17:45,830 --> 00:17:49,470
뒷 부분만 정확하게 말하는 것이 중요하여
문제점이 있었습니다

242
00:17:50,270 --> 00:17:55,310
문장 전체를 균등하게 파악하면서
뒷부분에도 가중치를 즐이기 위해

243
00:17:55,340 --> 00:18:00,770
기울기가 점차 감소하는
y=log(x) 그래프 가중치를 적용하였습니다

244
00:18:01,820 --> 00:18:04,210
변경된 코드 예시는 우측과 같습니다

245
00:18:04,850 --> 00:18:08,040
문자가 일치했을 때 인덱스 값을 더하는 것이 아니라

246
00:18:08,060 --> 00:18:10,880
위치에 log(인덱스) 값을 추가 하였고

247
00:18:10,920 --> 00:18:13,370
그로 인한 sum_count 변경하였습니다

248
00:18:14,330 --> 00:18:17,240
두 번째는 연속 일치에 대한 콤보 가중치입니다

249
00:18:17,720 --> 00:18:19,950
게임에서 miss 없이 연속으로 맞추면

250
00:18:19,970 --> 00:18:22,980
콤보라는 개념이 존재하는데, 동일한 원리입니다

251
00:18:23,720 --> 00:18:26,480
첫 일치 이후 연속으로 일치되는 문자에

252
00:18:26,510 --> 00:18:31,760
밑이 10인 log(x)의 그래프의 형태를 가지는 가중치를 더해

253
00:18:31,790 --> 00:18:36,680
추가적으로 콤보 가중치를 부여하였더니
더 자연스러운 슬라이드가 가능해졌습니다

254
00:18:37,460 --> 00:18:40,630
세 번째는 n-gram 기반으로 일치를 판단하였습니다

255
00:18:41,180 --> 00:18:44,390
n-gram은 n개의 연속적인 나열을 의미합니다

256
00:18:45,490 --> 00:18:50,330
좌측과 같이 '발표를 위해'와
'발로 만든 재무제표'에서

257
00:18:50,360 --> 00:18:55,180
발표라는 문자가 일치하였지만
사실 카운트를 하면 안 되는 경우였습니다

258
00:18:55,760 --> 00:19:01,360
이러한 문제를 해결하기 위해 기존에는
하나의 문자인 Uni-gram으로 판단하였다면

259
00:19:01,390 --> 00:19:04,730
이제는 두 개의 문자를 보는 Bi-gram을 적용하였습니다

260
00:19:05,720 --> 00:19:07,360
이를 반영한 코드 예시입니다

261
00:19:07,730 --> 00:19:09,950
기존에는 한 문자만 비교했지만

262
00:19:09,980 --> 00:19:15,210
이제는 두 개의 문자를 하나의 문자로
생각하여 Bi-gram 형식으로 비교하였습니다

263
00:19:15,750 --> 00:19:20,840
이후 유사도를 비교하여 threshold를
넘겼을 때 슬라이드하는 것뿐만 아니라

264
00:19:20,870 --> 00:19:22,930
현재 읽고 있는 위치를 계산하여

265
00:19:22,970 --> 00:19:25,910
현재 발표 위치까지 하이라이팅 하고

266
00:19:25,940 --> 00:19:29,470
일관된 시점에 슬라이딩을 할 수 있는 기능을 추가하였습니다

267
00:19:29,810 --> 00:19:32,100
다양한 테스트를 통해 가중치를 설정하여

268
00:19:32,130 --> 00:19:34,820
일관된 전환 시점을 설정하였지만

269
00:19:34,850 --> 00:19:38,730
문장의 길이가 짧거나 길 때 부자연스러운 문제가 있었습니다

270
00:19:39,330 --> 00:19:42,110
일관된 시점에 대본을 전환하기 위해서

271
00:19:42,140 --> 00:19:45,680
문장의 마지막 시점을 읽고 있을 때 자연스럽게 전환시켜

272
00:19:45,720 --> 00:19:47,660
다음 문장을 보여주어야 했습니다

273
00:19:48,680 --> 00:19:51,560
이를 해결하고자 실시간 발화 위치를 계산하여

274
00:19:51,590 --> 00:19:56,510
현재 위치와 threshold,
두 가지를 판단하여 전환하는 기능을 추가하였습니다

275
00:19:57,920 --> 00:20:01,340
실시간 발화 위치는 대부분 문장에서 일치하는 부분을

276
00:20:01,370 --> 00:20:05,990
전체적으로 판단하여 일치하는 문자들의 거리를 기반으로 판단하였습니다

277
00:20:06,710 --> 00:20:10,490
한 문장이 아무리 길고 임계치를 넘겼을 경우에도

278
00:20:10,520 --> 00:20:14,090
문장의 길이에 상관없이 자연스럽게 넘어가야 합니다

279
00:20:14,600 --> 00:20:17,340
이러한 경우에는 어떻게 해결할 수 있을까요?

280
00:20:17,720 --> 00:20:21,050
그 방법은 현재 위치를 실시간으로 계산하여

281
00:20:21,070 --> 00:20:25,250
임계치와 마찬가지로 특정 길이를 넘겼을 때의 기준을 정해

282
00:20:25,280 --> 00:20:26,870
모두 고려해야 합니다

283
00:20:27,890 --> 00:20:31,290
마지막으로 추가한 기능은 현재 문장을 읽지 않고도

284
00:20:31,320 --> 00:20:33,860
다음 문장으로 전환이 가능하도록 하였습니다

285
00:20:34,610 --> 00:20:38,510
발표를 진행할 때 문장의 순서를 지켜 진행하지 않고

286
00:20:38,540 --> 00:20:41,420
발표 상황에 맞춰 현재 문장은 스킵하여

287
00:20:41,440 --> 00:20:44,220
다음 문장부터 시작할 경우가 존재하였습니다

288
00:20:45,590 --> 00:20:49,580
다음 문장뿐만 아니라 다다음 문장, 다다다음 문장 등

289
00:20:49,610 --> 00:20:53,800
다양한 상황도 발생할 수 있지만
다음 문장에만 초점을 두었습니다

290
00:20:54,860 --> 00:20:58,260
이제 막 파이콘에 참여한 여러분 모두 환영합니다

291
00:20:58,850 --> 00:21:01,560
모두 값진 경험을 가져가시길 바랍니다

292
00:21:02,360 --> 00:21:04,120
코드 예시는 다음과 같습니다

293
00:21:04,340 --> 00:21:08,790
기존에는 문장이 변화할 때마다 현재 문장만 저장해 두었더라면

294
00:21:08,810 --> 00:21:13,130
이제는 다음 문장까지 저장하는 set_sentence() 함수를 추가하였습니다

295
00:21:14,120 --> 00:21:18,830
발화가 발생하면 현재 문장은 문장의 전체 길이로 판단하지만

296
00:21:18,860 --> 00:21:22,830
다음 문장은 다음 문장의 앞부분만 보고 판단하기로 하였습니다

297
00:21:23,510 --> 00:21:25,770
그래서 next_endpoint 변수에

298
00:21:25,800 --> 00:21:29,810
다음 문장의 몇 번째 인덱스까지 볼 것인지 설정하였습니다

299
00:21:31,280 --> 00:21:35,690
또한 현재 문장의 유사도 가중치인 current_weight와

300
00:21:35,720 --> 00:21:39,530
다음 문장의 유사도 가중치인 next_weight를 설정하여

301
00:21:39,560 --> 00:21:43,990
다음 문장에 현재 문장보다 더 적은 가중치를 설정하였습니다

302
00:21:45,410 --> 00:21:50,120
그 이후 각각 threshold를 넘겼는지 판단하여 슬라이드를 진행하였고

303
00:21:50,150 --> 00:21:54,680
다음 문장을 말해 패스하였다면 다음 문장이 다시 현재 문장이 되어

304
00:21:54,710 --> 00:21:56,990
연속적으로 진행할 수 있도록 하였습니다

305
00:21:59,240 --> 00:22:04,520
코드 예시들에서는 간단히 설정한 threshold와 가중치로 설명해 드렸지만

306
00:22:04,550 --> 00:22:07,750
실제 프로덕트 코드에서는 다양한 테스트를 통해

307
00:22:07,800 --> 00:22:09,630
문장 길이에 비례한 값과

308
00:22:09,680 --> 00:22:13,780
음절 뿐만 아니라 어절 기준으로 판단하는 피처들이 존재합니다

309
00:22:14,810 --> 00:22:20,570
한 단계씩 고도화해 나가면서 실시간성과
일관성이 높은 알고리즘을 계속 최적화하였습니다

310
00:22:21,680 --> 00:22:24,020
마지막으로 노이즈가 없는 환경과

311
00:22:24,080 --> 00:22:26,630
가사가 없는 클래식 음악을 재생하여

312
00:22:26,660 --> 00:22:30,660
노이즈가 있는 환경
두 가지에서 성능 테스트를 진행해 보았습니다

313
00:22:31,190 --> 00:22:34,820
노이즈가 없는 환경에서는 95%의 성공률을 보였고

314
00:22:34,850 --> 00:22:38,610
노이즈가 있는 환경에서는 91%의 성공률 했고요

315
00:22:38,680 --> 00:22:45,080
robust한 알고리즘을 개발하였습니다

316
00:22:45,110 --> 00:22:46,560
무엇을 느끼셨나요

317
00:22:46,910 --> 00:22:50,000
저는 웹서비스를 개발하면서 많은 부분을 느꼈습니다

318
00:22:50,030 --> 00:22:52,350
저는 이번 프로젝트를 진행하기 전에는

319
00:22:52,380 --> 00:22:55,880
깃을 사용한 협업 경험, 백엔드 관련 경험,

320
00:22:55,980 --> 00:22:59,680
문장 유사도와 같은 NLP 지식도 전무한 상태였습니다

321
00:23:00,320 --> 00:23:03,740
단지 컴퓨터 학부에 다니며 수업만 듣고 있던 학생이었습니다

322
00:23:05,030 --> 00:23:09,200
운이 좋게 소프트웨어 마에스트로라는
대외 활동을 진행하게 되었고

323
00:23:09,230 --> 00:23:12,340
팀원들에게 개발 과정에 해가 되지 않기 위해 노력하였습니다

324
00:23:13,280 --> 00:23:17,000
처음엔 백엔드 서버 개발을 위해 프레임워크를 선택할 때

325
00:23:17,030 --> 00:23:21,620
Spring, Node 등 다른 프레임워크보다 파이썬 기반의 장고(Django)는

326
00:23:21,650 --> 00:23:23,960
러닝 커브가 굉장히 낮다는 정보에

327
00:23:23,990 --> 00:23:27,900
Django를 선택하여
핵심 로직에만 집중할 수 있었던 것 같습니다

328
00:23:29,300 --> 00:23:33,240
짧은 기간 내에 웹, 통신, NLP를 공부하면서

329
00:23:33,270 --> 00:23:35,220
빠르게 개발할 수 있었던 이유도

330
00:23:35,240 --> 00:23:39,850
간결하고 생태계가 잘 구축되어 있는
파이썬 덕분이라고 생각합니다

331
00:23:46,430 --> 00:23:48,410
제가 느낀 점은 크게 세 가지입니다

332
00:23:48,440 --> 00:23:53,960
첫 번째는 하나의 기능을 정확하게 구현하기 위해
정말 다양한 테스트를 진행하였고

333
00:23:53,990 --> 00:23:59,450
정답이 없는 문제였기에 팀원들과 소통하여 문제를 정의하고 풀어나갔습니다

334
00:24:00,050 --> 00:24:04,800
그 과정에서 많은 실패와 시행착오도 있었지만 계속해서 최적화를 진행하였습니다

335
00:24:05,590 --> 00:24:09,540
오픈소스를 사용해 개발한 것이 아니기 때문에 계속해서 고민하고

336
00:24:09,570 --> 00:24:12,330
팀원들과 함께 문제들을 하나씩 하나씩

337
00:24:12,350 --> 00:24:14,580
해결해 나가 의미 있는 경험이었습니다

338
00:24:15,890 --> 00:24:19,940
두 번째로 두 달 만에 빠르게 배타 출시를 진행하였습니다

339
00:24:19,970 --> 00:24:23,490
그로 인해 9만 명 이상의 글로벌 사용자 수를 확보하였고

340
00:24:23,510 --> 00:24:26,570
다양한 기술 매체에서도 소개하였습니다

341
00:24:27,650 --> 00:24:31,590
빠르게 개발할 수 있었던 이유는 역시 파이썬 때문이라고 생각합니다

342
00:24:32,460 --> 00:24:36,990
마지막으로 초반에 계속해서 기반이 되는 백그라운드 없이

343
00:24:37,010 --> 00:24:41,020
단지 딥러닝 NLP 같은 최신 기술을 사용해보고 싶었습니다

344
00:24:41,810 --> 00:24:45,650
그 이후로 계속해서 인위적인 방향에서만 다가가었지만

345
00:24:45,680 --> 00:24:50,510
빠르게 포기하고 방향을 바꿔
조금 더 프로젝트 스케일에 적합하고

346
00:24:50,540 --> 00:24:56,030
기능의 성격에 맞는 기술을 사용하고자
다양한 시도를 하면서 많이 성장할 수 있었습니다

347
00:24:59,090 --> 00:25:02,250
끝까지 긴 발표 경청해 주셔서 감사드립니다

348
00:25:02,900 --> 00:25:05,440
부족한 내용이지만 제가 경험한 내용을

349
00:25:05,560 --> 00:25:08,790
어떻게 간결하게 전해드릴 수 있을지 많이 고민한 만큼

350
00:25:08,820 --> 00:25:11,720
여러분들께 조금이라도 도움이 되셨으면 합니다

351
00:25:12,500 --> 00:25:16,410
추가적으로 궁금한 사항
메일로 연락주시면 답변드리도록 하겠습니다

352
00:25:17,210 --> 00:25:21,920
또한 깃허브에 소스 코드도 있으니
궁금하시면 확인하실 수 있습니다

353
00:25:22,500 --> 00:25:26,160
코로나 19로 인해 힘든 상황이지만
모두 건강하시길 바랍니다

354
00:25:26,750 --> 00:25:29,330
감사합니다.
발표자 강지훈이었습니다

