1
00:00:10,540 --> 00:00:17,040
안녕하세요. 자연어 처리 초보자에 BERT 도전이라는
주제로 발표할 Common Computer 인턴 김윤기입니다

2
00:00:17,620 --> 00:00:23,737
먼저 제가 했던 파이썬과 딥러닝을 이용해서
만든 프로젝트들을 간단히 소개를 드리려고 합니다

3
00:00:24,370 --> 00:00:31,174
이것은 시각장애인을 위한 보행로 안내 AI로
시각장애인에게 인도와 차도를 구분해주는 프로그램입니다

4
00:00:31,930 --> 00:00:36,305
시각장애인이 인도에서 벗어나 차도로 가지 않도록 하는 안내견 역할을 하는데

5
00:00:36,791 --> 00:00:42,970
고등학생 때 딥러닝을 공부하면서 만든 프로그램이
이렇게 중앙일보에 나와서 알려지기도 했습니다

6
00:00:43,300 --> 00:00:49,550
그 이후로 작년에 1년 동안 정부과제를 통해
인도 보행데이터 구축사업에 참여하면서

7
00:00:49,630 --> 00:00:53,598
실제 상황에 대응할 수 있는 데이터를 수집을 하기도 했습니다

8
00:00:53,955 --> 00:00:57,406
이 프로그램을 상용화할 수 있도록 계속 개발 중에 있습니다

9
00:00:57,430 --> 00:01:02,338
아래에 보이는 깃헙에 이 프로젝트의 파이썬코드를 오픈소스로 공개되어 있습니다

10
00:01:03,490 --> 00:01:07,927
이후에 좋은 기회로 네이버 클로바 AI에서 인턴을 하게 되었는데요

11
00:01:08,319 --> 00:01:14,475
이렇게 뉴스에 나온 수화를 학습시켜서 음성이나
텍스트를 수화로 바꿔주는 인공지능을 만들기도 했습니다

12
00:01:14,980 --> 00:01:18,556
고3 때 진행한 프로젝트나 학교를 다니면서 논문을 썼습니다

13
00:01:18,580 --> 00:01:23,220
다만 아직은 기술적으로 어려운 부분이 많아서 feature work로 남겨두고 있습니다

14
00:01:23,680 --> 00:01:29,672
이 프로젝트는 네이버 클로바 AI팀에 있을 때
개발되었기 때문에 깃헙에 공개되어 있지는 않습니다

15
00:01:30,130 --> 00:01:32,590
지금 한 1학년 1학기를 마친 대학생이고

16
00:01:32,615 --> 00:01:36,708
블록체인 분산 컴퓨팅을 만드는 Common Computer라는 회사에서

17
00:01:36,740 --> 00:01:39,646
여름방학 때부터 두 달째 인턴을 하고 있습니다

18
00:01:40,420 --> 00:01:42,513
무엇을 해볼까 고민을 하고 있었는데

19
00:01:42,538 --> 00:01:47,951
이번 기회에 그동안 관심이 많았던 자연어 처리 분야에 도전을 해봤습니다

20
00:01:48,400 --> 00:01:53,356
진입장벽이 높기도 하고 컴퓨팅 자원을 많이 필요해서 그동안 못하고 있었는데

21
00:01:53,380 --> 00:01:58,950
회사에서 충분한 자원을 제공받아서 이번에
자연어 처리 분야에 처음 입문을 해보았습니다

22
00:01:59,890 --> 00:02:05,585
이제 본론으로 넘어가서 최근에 BERT라는
모델을 많이 들어보셨을 것으로 생각이 됩니다

23
00:02:06,250 --> 00:02:11,218
문장 시퀀스가 들어왔을 때 텍스트에서 특징을 뽑는 언어 모델인데요

24
00:02:11,680 --> 00:02:16,656
BERT란 Bidirectional Encoder
Representations from Transformers의 약자로

25
00:02:16,687 --> 00:02:19,358
2018년에 구글에서 공개한 모델입니다

26
00:02:20,920 --> 00:02:26,787
BERT 언어 모델을 학습할 때 Masked Language 모델과 Next
Sentence Prediction 방법을 사용하는데요

27
00:02:27,460 --> 00:02:31,006
Masked Language 모델은 오른쪽 사진의 설명을 해주고 있고

28
00:02:31,031 --> 00:02:35,670
Next Sentence Prediction은 왼쪽 아래 사진이 설명을 해주고 있습니다

29
00:02:37,270 --> 00:02:41,121
Masked Language 모델은 입력 문장의 마스크로 빈칸을 뚫어서

30
00:02:41,146 --> 00:02:45,621
양쪽 맥락에서 빈칸에 단어를 예측하도록 하는 학습방법이고

31
00:02:47,230 --> 00:02:50,753
NXP는 원래 문장과 랜덤한 문장을 섞어서 주었을 때

32
00:02:50,778 --> 00:02:55,511
해당 문장이 다음 문장인지를 is next, not next로 예측합니다

33
00:02:57,910 --> 00:03:00,675
Masked Language 랭귀지 모델 방식이 주로 쓰이는데

34
00:03:00,700 --> 00:03:03,870
인터넷에 있는 언어 데이터에 그냥 빈칸만 뚤어도

35
00:03:03,895 --> 00:03:09,020
언어에 대한 확률적인 매핑이 되어서
각 단어가 어떤 뜻인지를 알 수 있게 됩니다

36
00:03:09,370 --> 00:03:13,126
BERT가 기존에 NLP 분야에서 쓰이던 방법과의 주된 차이점은

37
00:03:13,150 --> 00:03:17,909
기존에 Word to Vector와 같은 방법은 한 단어의 뜻을 숫자로 나타냈다면

38
00:03:18,280 --> 00:03:24,053
BERT는 transformer라는 모델을 통해 단어의 좌우
맥락을 고려해서 의미를 파악한다고 할 수 있습니다

39
00:03:25,030 --> 00:03:28,748
예를 들어서 사과라고 하면 과일뜻도 있지만 다른 뜻도 있는데

40
00:03:29,050 --> 00:03:33,690
아래처럼 문장을 통체로 학습하면
맥락에 따라 다른 매핑을 할 수 있는 것입니다

41
00:03:35,131 --> 00:03:41,296
그밖에도 기존에는 단어마다 인코딩을 해서
RNN과 같은 sequential한 모델에 다시 넣어줬다면

42
00:03:41,351 --> 00:03:47,956
트렌스포머 모델은 처음부터 끝까지 attention이라는 단일
모델 구조를 통해서 더 높은 정확도와 성능을 달성했습니다

43
00:03:47,980 --> 00:03:51,378
최근의 알파고 2015년 이후로 딥러닝을 적용하면서

44
00:03:51,403 --> 00:03:55,073
영상 처리 분야와 음성인식 분야의 큰성능 향상이 있었는데요

45
00:03:55,900 --> 00:04:02,485
자연어 처리는 2019년까지 큰 빛을 발하지 못하다가
BERT모델을 기점으로 큰 성능 향상이 있었습니다

46
00:04:03,921 --> 00:04:09,789
오른쪽은 구글 트렌드 그래프인데 자연어
처리 분야가 서서히 인기를 끌고 있다고 보입니다

47
00:04:10,960 --> 00:04:13,606
또 제가 자연어 처리가 중요하다고 생각하는 이유가

48
00:04:13,630 --> 00:04:17,139
언어는 인간과 다른 동물들을 구분하는 매우 중요한 것인데

49
00:04:17,690 --> 00:04:22,995
기계가 언어를 이해할 수 있다면 인간의
지식을 매우 빠른 속도로 빨아 들일 수 있기 때문에

50
00:04:23,019 --> 00:04:28,104
자연어 처리는 인공지능이 삶에 녹아들기 위한 가장 중요한 스텝이라고 생각합니다

51
00:04:29,110 --> 00:04:35,727
대표적인 자연어 처리 태스크는 Language 모델은
가장 쉬운 예로 검색어 추천을 예를 들 수 있고

52
00:04:36,100 --> 00:04:38,896
텍스트 분류는 감정분석 스팸분류

53
00:04:39,021 --> 00:04:43,716
질의 응답은 질문에 대한 답은 글에서 찾거나 답하는 테스크입니다

54
00:04:44,710 --> 00:04:47,461
Text Generation은 말 그대로 글쓰기인데요

55
00:04:47,485 --> 00:04:51,461
책이나 뉴스 기사를 쓸 수 있고 챗봇으로도 쓰일 수 있습니다

56
00:04:52,540 --> 00:04:56,663
Summarization은 긴 글을 주면 개요를 작성해주는 데스크

57
00:04:56,688 --> 00:05:00,578
Translation은 구글 번역기나 파파고를 예를 들 수 있습니다

58
00:05:01,720 --> 00:05:06,126
저는 BERT로 뭘 해볼까 하다가 Question
Answering에 관심을 가져왔는데요

59
00:05:06,520 --> 00:05:13,402
사진처럼 질문과 컨텍스트가 주어졌을 때 답에 해당하는
부분의 시작 지점과 끝 지점을 찾아야 하는 테스크입니다

60
00:05:14,140 --> 00:05:20,960
사진을 보시면 입력 문장이 한 문장 들어왔을 때
레퍼런스 텍스트 안에 어느 부분에 답이 있는지를 찾아야 하고

61
00:05:21,460 --> 00:05:27,670
시작지점이 될 확률이 가장 높은 부문과 끝이 점이 될
확률이 가장 높은 복원 SPAN을 출력합니다

62
00:05:29,320 --> 00:05:33,312
SQuAD 스커드는 더 스탠포드 Question and Answering 데이터 셋으로

63
00:05:33,337 --> 00:05:36,546
2016년에 시작된 영어로 된 챌린지인데

64
00:05:36,880 --> 00:05:41,200
저는 한국어를 해보고 싶어서 찾은 것이 KorQuAD 2.0 라는 테스크입니다

65
00:05:41,840 --> 00:05:45,979
역시나 Leaderboard에는 대기업들로 꽉 차 있어서 많이 어려워 보였는데요

66
00:05:46,004 --> 00:05:50,847
과연 할 수 있을까? 하는 생각이 많이 들었는데
일단 해보자 하고 도전을 했습니다

67
00:05:51,707 --> 00:05:55,253
이 Leaderboard는 KorQuAD 홈페이지에서 보실 수 있습니다

68
00:05:56,035 --> 00:05:58,636
KorQuAD 1.0과 2.0이 조금 다르긴 한데요

69
00:05:58,661 --> 00:06:01,689
1.0은 짧은 텍스트에서 답을 찾는 것이고

70
00:06:01,714 --> 00:06:06,402
2.0은 위키피디아홈페이지 전체를 줬을 때 답을 찾아야 됩니다

71
00:06:06,940 --> 00:06:09,922
HTML 텍스트가 쭉 주어졌을 때 답의 시작지점

72
00:06:09,947 --> 00:06:13,072
저 사진에서는 3024번째 글자에서부터

73
00:06:13,142 --> 00:06:17,926
3031번째 글자에 있는 SK이노베이션을 찾아야 하는 것이죠

74
00:06:17,950 --> 00:06:21,551
특이한 점은, 결과에 HTML 태그도 포함이 되어 있습니다

75
00:06:21,970 --> 00:06:25,540
자연어 처리는 Pre-Training와 Fine-Tuning 관계로 나눠지는데

76
00:06:25,626 --> 00:06:29,026
Pre-Training은 많은 라벨링 되지 않은 데이터를 학습시켜서

77
00:06:29,050 --> 00:06:31,876
언어에 대한 이해도를 높이는 과정이라면

78
00:06:31,900 --> 00:06:35,634
Fine-Tuning은 주어진 테스크에 맞게 모델을 약간 수정하는 것입니다

79
00:06:36,790 --> 00:06:39,976
아무래도 QA 에 대한 데이터가 많이 없기 때문에

80
00:06:40,000 --> 00:06:45,500
우선한 한글 데이터를 많이 집어넣고
적은 QA 데이터로 파인튜닝을 시키는 것이죠

81
00:06:46,480 --> 00:06:51,909
그래서 KorQuAD에서 점수가 잘 나오면 한국어에
대한 전반적인 성능이 좋다고 할 수 있습니다

82
00:06:52,510 --> 00:06:56,213
저는 이 KorQuAD도 파이썬으로 작성을 하기로 했습니다

83
00:06:56,800 --> 00:07:00,776
우선 머신 러닝 분야에서는 사진 처리, 텍스트 처리, 음성 처리 등

84
00:07:00,830 --> 00:07:05,955
전부 코드를 처리 알 수 없기 때문에
패키지라는 것을 설치해서 불러와서 쓰는데요

85
00:07:07,390 --> 00:07:12,710
다른 프로그래밍 언어와 다르게 확장성이
매우 좋아서 원하는 기능은 대부분 있는 편입니다

86
00:07:13,750 --> 00:07:18,640
그리고 다른 언어에 비해 훨씬 간결하기 때문에
같은 기능이라도 파이썬 500줄이면

87
00:07:18,665 --> 00:07:22,204
C++ 이나 자바는 1000줄이상의 코드가 되는 것이죠

88
00:07:23,410 --> 00:07:27,166
파이썬을 하다가 다른 언어를 쓰면 '이게 안 돼' 라는 순간이 엄청 많습니다

89
00:07:27,190 --> 00:07:30,900
파이썬에서는 당연하게 쓰는 기능이 없는 경우가 많기 때문이죠

90
00:07:31,600 --> 00:07:36,239
다시 KorQuAD로 돌아와서 제가 올해 7월부터 KorQuAD 프로젝트를 시작했고

91
00:07:36,264 --> 00:07:39,278
그동안 NLP 분야 공부랑 전처리 코드를 만들고

92
00:07:39,303 --> 00:07:41,623
지금 발표자료를 만든 시점에서

93
00:07:41,648 --> 00:07:45,586
Leaderboard의 베이스라인을 넘겨서 11일까지 성능을 올렸습니다

94
00:07:45,610 --> 00:07:49,828
아직 시작한 지 두 달 밖에 안 돼서 본격적인 연구는 이제부터 시작인데요

95
00:07:50,230 --> 00:07:53,901
이 영상이 올라갈 시점에는 Leaderboard에 올라가 있으면 좋겠습니다

96
00:07:54,250 --> 00:07:58,531
이것은 제가 BERT 관련 공부하면서 좋았던 링크를 모아둔 것인데요

97
00:07:59,200 --> 00:08:03,481
페이스북에 올렸던 글이라 여기 QR코드나 링크로 보실 수 있습니다

98
00:08:04,780 --> 00:08:08,266
제가 이번 발표에서는 NLP 분야 개념을 따로 안 다뤄서

99
00:08:08,290 --> 00:08:10,243
여기에 올라가 있는거 링크만 봐도

100
00:08:10,268 --> 00:08:14,408
2020년형 것까지는 충분히 이해가 가능할 것으로 생각합니다

101
00:08:14,710 --> 00:08:19,038
또 BERT 모델 공부에 도움이 된 것
Huggingface Transformers라는

102
00:08:19,063 --> 00:08:22,797
버트 모델 관련해서 굉장히 유명한 파이썬 라이브러리인데요

103
00:08:23,530 --> 00:08:27,639
PyTorch와 Tensorflow를 자유롭게
선택할 수 있고 모델 이름만 넣으면

104
00:08:27,664 --> 00:08:31,882
Pre-Trained모델을 코드한 줄로 바꿔가면서 테스트 할 수 있습니다

105
00:08:32,650 --> 00:08:37,156
위의 사진은 Seoel is capital of 빈칸이라는 문장을 주고

106
00:08:37,181 --> 00:08:40,071
빈칸에 뭐가 들어갈지를 예측하는 것인데요

107
00:08:40,630 --> 00:08:45,692
Korea의 확률이 48%로 한국의 수도가 서울이라고 정확하게 예측을 했죠

108
00:08:46,514 --> 00:08:50,467
위에 코드처럼 모델 이름을 입력하고 테스크를 지정해주면

109
00:08:50,492 --> 00:08:53,225
되게 짧은 코드로 작동을 시킬 수가 있습니다

110
00:08:54,040 --> 00:08:59,297
학습코드는 조금 더 늘어나긴 하는데
직접 개발하는 것보다 몇 배는 수월하게 할 수 있습니다

111
00:09:01,840 --> 00:09:05,900
실제로 KorQuAD를 해보기 위해서는 데이터셋을 받아야 하는데

112
00:09:05,925 --> 00:09:10,128
KorQuAD 공식 사이트에서 링크를 클릭하시면 받으실 수 있습니다

113
00:09:11,500 --> 00:09:13,666
데이터셋은 7기가 정도가 되는데요

114
00:09:13,690 --> 00:09:20,440
1000 개의 질문과 답변 그리고 그 답변의 출처가 될
수 있는 위키피디아 문서가 저희 JSON으로 저장되어 있습니다

115
00:09:20,950 --> 00:09:25,895
Huggingfaced Transformers에 Github Repo을 보면 SQuAD가 포함이 되어 있는데요

116
00:09:26,290 --> 00:09:32,485
기존의 SQuAD는 영어로 된 데이터 셋을 입력 받기에
KorQuAD를 입력받을 수 있도록 수정이 필요했습니다

117
00:09:33,850 --> 00:09:37,537
물론 데이터 셋 자체의 형식은 거의 비슷한 구조로 되어 있더라구요

118
00:09:37,840 --> 00:09:42,433
데이터는 다음과 같은 흐름을 타고 모델로 들어가서 결과가 나오게 됩니다

119
00:09:43,990 --> 00:09:48,700
위키 문서와 질문 그리고 답변을 토큰으로
이어서 Raw Text로 입력하고

120
00:09:48,725 --> 00:09:51,404
형태소 분석을 해서 토큰으로 만들고요

121
00:09:51,735 --> 00:09:55,485
이 토큰을 딕셔너리로 라벨링하여 벡터 값으로 지원합니다

122
00:09:56,080 --> 00:10:00,212
아시다시피 파이썬 3는 한글은 유니코드로 처리가 되는데요

123
00:10:00,790 --> 00:10:06,790
같은 양의 데이터를 영어로 넣었을 때와 비교하면
한글의 경우 메모리 사용을 더 많이 하는 것을 알 수 있습니다

124
00:10:08,080 --> 00:10:12,436
SQuAD 데이터 셋 40MB 밖에 않되는데 KorQuAD 7GB다 보니

125
00:10:12,460 --> 00:10:17,155
구글에서 공개한 코드를 그대로 사용하면
메모리 사용량 200GB 넘게 사용해서

126
00:10:17,180 --> 00:10:19,217
파이프라인을 바꾸어주어야 했습니다

127
00:10:20,170 --> 00:10:23,801
JSON을 한번 로드하는 대신에 한 질의 응답 세트씩로 로드해서

128
00:10:23,826 --> 00:10:25,466
Redis 데이터베이스에 넣고

129
00:10:25,505 --> 00:10:30,154
다시 불러와서 전처리하는 방식으로
트레이닝시 메모리 사용량을 크게 줄었습니다

130
00:10:31,690 --> 00:10:34,619
학습에 필요한 순간 순간의 데이터만 불러오게 하고

131
00:10:34,644 --> 00:10:38,190
나머지는 파이썬의 가비지 컬렉션에 맡기는 선택을 하면서

132
00:10:38,221 --> 00:10:42,119
메모리 사용량도 70GB로 줄이고 성능도 확보했습니다

133
00:10:43,030 --> 00:10:45,701
그리고 파이썬의 자체 내장 라이브러리인

134
00:10:45,726 --> 00:10:50,186
멀티프로세싱을 사용해서 CPU 256개를 병렬 처리하면서

135
00:10:50,264 --> 00:10:53,748
10시간 걸리던 전 처리가 3분으로 단축되기도 했습니다

136
00:10:55,330 --> 00:11:00,384
functiontools에 partial과 multiprocess pool이 너무 궁합이 좋았습니다

137
00:11:01,360 --> 00:11:04,195
그래도 많은 부분에서 병목이 남아 있었습니다

138
00:11:04,360 --> 00:11:08,266
한글 지원을 위해 추가로 작성한 부분에서 특히 병목이 생겼는데요

139
00:11:08,950 --> 00:11:11,301
파이썬에서 제공하는 프로파일러를 사용해서

140
00:11:11,326 --> 00:11:16,145
각 함수가 얼마나 걸리는지 무엇을
호출하는지를 그래프로 나타낼 수가 있습니다

141
00:11:17,320 --> 00:11:21,343
이렇게 해서 성능 저하의 병목점이 어디인지 쉽게 파악할 수가 있었습니다

142
00:11:22,540 --> 00:11:25,546
이 화면은 Pandas에서 값을 가져오는 화면인데요

143
00:11:25,570 --> 00:11:29,109
값을 가져오는데만 37초가 걸렸다고 나오고 있습니다

144
00:11:29,680 --> 00:11:32,164
여기에 쓰인 코드는 다음 장에 있는데요

145
00:11:35,080 --> 00:11:37,423
왼쪽의 코드가 바로 그 코드입니다

146
00:11:38,200 --> 00:11:40,848
Pandas의 read_csv 기능을 이용해서

147
00:11:40,873 --> 00:11:46,082
아주 큰 용량의 CSV를 파싱하고 필요한 값을 Redis에 삽입했는데요

148
00:11:47,350 --> 00:11:53,389
하지만 Pandas에서 값을 가져오는 부분이 느려서
Redis에 추가하는 성능이 만족스럽지 않았습니다

149
00:11:53,950 --> 00:11:57,796
다행히 저희가 가지고 있는 CSV 파일이 well-format된 파일이라서

150
00:11:57,820 --> 00:12:02,249
그냥 파이썬의 기본 내장 for문을 파일을 열어서 한 줄씩 받은 다음

151
00:12:02,280 --> 00:12:05,740
split으로 쪼개서 처리했더니 충분히 빠른 결과가 나왔습니다

152
00:12:06,250 --> 00:12:11,746
역시 네이티브가 좋더라고요 이런 결정을
내렸는데 도와줄 링크를 아래에 첨부했습니다

153
00:12:11,770 --> 00:12:15,196
이렇게 했는데도 정확도가 이상하게 안 나와서 분석해보니

154
00:12:15,220 --> 00:12:21,095
한글이랑 영어 유니코드 처리 방식이 달라서
evaluation 할 때 모두 오답 처리가 되는 것이었습니다

155
00:12:21,610 --> 00:12:27,047
저렇게 조합형으로 쪼개진 한국어의 음절들을
string으로 조인하니까 제대로 된 문장이 나왔습니다

156
00:12:27,550 --> 00:12:29,745
그렇지만 그 정답이 조합형로 되어 있어서

157
00:12:29,770 --> 00:12:33,503
완성형인 실제 정답과 바이트 레벨에서의 차이가 생겼습니다

158
00:12:34,690 --> 00:12:40,065
파이썬에서는 다행히 유니코드 데이터라는
내장 라이브러리가 있어서 잘 해결할 수 있었습니다

159
00:12:41,130 --> 00:12:44,676
유니코드 노말라이즈라는 간단해법으로 해결을 하긴 했는데

160
00:12:44,693 --> 00:12:47,661
자연어 처리 분야가 공개된 노하우가 많이 적어서

161
00:12:48,160 --> 00:12:54,074
특히 한국어에서는 직접 문제를 겪고
삽질을 해야만 하는 경우가 많았던 것 같습니다

162
00:12:54,640 --> 00:12:58,405
다른 분들은 저처럼 이 문제로 고생하지 않으셨으면 좋겠습니다

163
00:12:58,600 --> 00:13:02,232
사실 아직 시작한 지 두 달밖에 안 되어서 많이 한 것이 없는데요

164
00:13:02,410 --> 00:13:06,046
그래도 처음에는 불가능해 보였던 목표에 어느 정도 근접을 했고

165
00:13:06,070 --> 00:13:11,921
하다 보니 전처리가 만만치않게 많고 어려워서
사실상 두 달 동안 전처리만한 것 같습니다

166
00:13:12,430 --> 00:13:16,117
KorQuAD는 앞으로 성능을 많이 올려서 1등을 하는 게 목표입니다

167
00:13:19,630 --> 00:13:22,692
그리고 최근에 핫한 GPT-3 라는 모델이 있는데요

168
00:13:23,020 --> 00:13:26,480
이게 특별한 이유는 이렇게 긴 텍스트를 추가적인 학습없이도

169
00:13:26,505 --> 00:13:29,942
사람이 보기에 그럴 듯한 텍스트를 만들어낸다는 것입니다

170
00:13:30,520 --> 00:13:33,135
소설을 쓰기도 하고 사람에게 조언을 해주기도 하고

171
00:13:33,160 --> 00:13:37,605
엑셀을 다루기도 하고 그동안 불가능하다고 여겨지던 일들을 너무 잘해냅니다

172
00:13:39,473 --> 00:13:44,293
왼쪽에 예시처럼 사람이 말하듯이 굉장히 잘 텍스트를 생성해내고 있고

173
00:13:44,800 --> 00:13:51,042
오른쪽에 예시는 글을 주었을 때 방법을 알려주지도
않았는데 이렇게 표를 만들어낸 것을 볼 수 있습니다

174
00:13:53,950 --> 00:13:58,910
이렇게 GPT -3가 잘 되는 이유는
모델의 크기를 200배가량 키웠다는 것인데요

175
00:13:59,380 --> 00:14:03,903
BERT도 상당히 큰 모델에 해당하는데 그것에 200배면 얼마나 큰지 알 수 있죠

176
00:14:05,020 --> 00:14:08,668
GPT-3 를 한번 학습시키는 데만 50억 원이 든다고 합니다

177
00:14:09,130 --> 00:14:13,347
대신 이렇게 큰 모델을 한번 잘 학습시키면 따로 Fine-Tuning을 하지 않아도

178
00:14:13,372 --> 00:14:17,817
예시 몇 개를 입력으로 주면 어떤 테스크던지 제너럴하게 해낸다는 것입니다

179
00:14:18,194 --> 00:14:23,428
OpenAI는 이렇게 학습시킨 GPT-3
모델을 유로 API를 공개할 계획이라고 하는데요

180
00:14:23,950 --> 00:14:26,887
한번 request를 날릴 때마다 돈을 내는 방법이죠

181
00:14:27,640 --> 00:14:30,804
그래서 이번에 해보고 싶은 것이 한국어 데이터를 많이 모아서

182
00:14:30,828 --> 00:14:34,124
GPT-3 와 같은 범용 모델을 만드는 것이 목표입니다

183
00:14:34,330 --> 00:14:37,259
그래서 KorQuAD에서 연습삼아 의미 있는 점수를 찍고

184
00:14:37,284 --> 00:14:41,009
GPT-3 모델을 잘 만들어서 공개하는 것이 저의 목표입니다

185
00:14:41,530 --> 00:14:46,576
또 개인적으로 해보고 싶은 프로젝트라면
대학생이다 보니 글쓰기를 상당히 많이 해야 되는데요

186
00:14:46,960 --> 00:14:50,975
개요를 주면 자동으로 에세이를 써주는 것도 가능하지 않을까? 생각이 듭니다

187
00:14:51,250 --> 00:14:56,687
BERT 모델이 상당히 큰 편에 속하는데 개인
컴퓨터에서 쉽게 돌리지 못하는 문제점이 있습니다

188
00:14:57,550 --> 00:15:00,870
GPU 메모리가 12GB는 되어야 학습이 가능한데

189
00:15:00,909 --> 00:15:06,385
GTX-1080TI가 8GB 메모리이기 때문에
사실상 개인이 돌리기는 쉽지 않습니다

190
00:15:08,980 --> 00:15:13,425
그래서 저희 회사에서 만든 Ainize에서
무료로 돌려볼 수 있는 방법이 있습니다

191
00:15:13,780 --> 00:15:15,780
BERT에서 서비스 API인데요

192
00:15:16,060 --> 00:15:19,122
파이썬 request 모듈을 이용해서 바로 요청하시면

193
00:15:19,147 --> 00:15:22,880
우리가 원하는 문장을 BERT를 거쳐서 벡터를 얻으실 수 있습니다

194
00:15:23,534 --> 00:15:26,823
원래 기존에 깃허브에 공개되어 있던 bert-as-a-service를

195
00:15:26,848 --> 00:15:29,730
Ainize에 넣어서 API화 한 것입니다

196
00:15:30,880 --> 00:15:34,079
JSON에 넣을 값에 대한 설명은 링크해보시면

197
00:15:34,104 --> 00:15:36,602
오픈 API 문서를 통해 확인하실 수 있습니다

198
00:15:36,627 --> 00:15:38,697
웹에서 바로 요청도 가능합니다

199
00:15:42,550 --> 00:15:48,112
비슷한 예시로 한국어 형태소 분석기인 KONLPy코웬앤파에도 Ainize에 올라와 있습니다

200
00:15:48,700 --> 00:15:50,518
오른쪽에 링크와 코드가 있고요

201
00:15:50,543 --> 00:15:53,097
사이트 내에서도 바로 시도해 볼 수 있습니다

202
00:15:54,760 --> 00:15:59,580
Common Computer가 만드는 Ainize는
OpenSource-as-a-Service Platform인데요

203
00:16:00,130 --> 00:16:05,114
쉽게 말하자면 깃헙 주소를 입력하면
클라우드에 올라온 서비스를 얻으실 수 있습니다

204
00:16:05,829 --> 00:16:08,056
무거워서 메모를 많이 차지하는 모델도

205
00:16:08,081 --> 00:16:13,165
인스턴스에 GPU가 필요한 코드까지
다 지원하니 한번 explorer텝을 확인해보세요

206
00:16:13,660 --> 00:16:16,058
NL 분야에 많은 지식들이 올라와 있습니다

207
00:16:17,380 --> 00:16:21,520
Common Computer는 Collaborative Computing 블록체인을 만들고 있습니다

208
00:16:22,030 --> 00:16:27,373
이 키워드에 관심이 생기신다면 Common Computer
홈페이지를 방문해주시고 커리어 탭도 확인해주세요

209
00:16:27,910 --> 00:16:31,894
세션에 대한 질의 응답은 후원사 부스를 통해서 진행하게 될 것 같습니다

210
00:16:32,167 --> 00:16:36,023
지금까지 자연어 처리 초보자에 BERT 도전기를 들어주셔서 감사합니다



