1
00:00:10,460 --> 00:00:11,617
안녕하세요
 

2
00:00:12,023 --> 00:00:15,319
pandas 코드로 빅데이터를 분석해보자 – Koalas
 

3
00:00:15,390 --> 00:00:17,311
발표를 하게된 박현우입니다
 

4
00:00:17,948 --> 00:00:21,418
저는 영상처리 석사과정을 졸업한 후에
 

5
00:00:21,456 --> 00:00:26,058
2017년도부터 빅데이터 분산 서버 솔루션 개발을 했습니다
 

6
00:00:26,410 --> 00:00:31,144
현재는 카카오에서 데이터 플랫폼 서버를
개발하고 있는 4년차 데이터 엔지니어입니다 

7
00:00:32,770 --> 00:00:38,926
제가 주로 하는 일은 빅데이터에서 가치 있는 정보를
추출하기 위한 기반 시스템을 구축하는 일을 하고 있으며 

8
00:00:38,950 --> 00:00:42,332
파이썬과 Scala를 사용해서 개발하는 걸 좋아합니다
 

9
00:00:43,570 --> 00:00:46,426
이번 발표 전반부는 빅데이터 처리 시스템과
 

10
00:00:46,450 --> 00:00:52,226
시스템 내에서 데이터 분석가와 데이터 엔지니어의
역할과 도구에 대한 소개를 드릴 거고요 

11
00:00:52,251 --> 00:00:56,774
발표 중반부터 본격적으로 Koalas에 대한 소개를 드리도록 하겠습니다
 

12
00:00:59,170 --> 00:01:05,623
이 발표는 데이터 분석가 또는 데이터 분석가를
위해서 공부 중인 학생분들을 대상으로 합니다 

13
00:01:06,011 --> 00:01:09,796
특히 점차 큰 규모를 가진 데이터를 다루면서
 

14
00:01:09,820 --> 00:01:14,374
분석 성능에 대한 고민을 시작하게 된 분들이 들어주시면 더 좋을 것 같습니다
 

15
00:01:15,850 --> 00:01:19,693
R이나 Pandas 같은 분석도구를 처음에 학습을 할 때
 

16
00:01:19,718 --> 00:01:24,038
보통 CSV 예제 데이터 파일들을 많이 활용하는데요
 

17
00:01:24,370 --> 00:01:30,166
이러한 잘 정제된 적은 용량의 데이터를
학습을 하면서 아마 많이 다뤄보셨을 겁니다 

18
00:01:31,840 --> 00:01:34,306
그런데 현업에서는 회사마다 다르겠지만
 

19
00:01:34,330 --> 00:01:41,531
서비스 규모가 커짐에 따라서 매일 수억 수조건
수테라바이트 단위의 데이터가 새롭게 생성이되는데요 

20
00:01:42,289 --> 00:01:44,806
그렇게 정제된 데이터를 얻는 과정 자체에
 

21
00:01:44,830 --> 00:01:47,134
굉장히 큰 기술과 노력이 필요합니다
 

22
00:01:47,650 --> 00:01:53,866
그래서 이 그림에서 오른쪽에 많은 도구들
오픈소스들을 확인하실 수 있는데 

23
00:01:53,890 --> 00:01:57,194
크게는 소집 변환 적재 ETL 과정이 있습니다
 

24
00:01:58,000 --> 00:02:04,210
우리가 참치를 원양어선에서 낚아서
참치캔을 먹는 과정에 비유를 한번 해보겠습니다 

25
00:02:06,040 --> 00:02:11,956
데이터가 참치라면은 원양어선에서 바다에서 잡아오는 수집과정이 있겠고요
 

26
00:02:11,980 --> 00:02:17,644
그 다음에 참치를 해체하고 정제하고 가공하는 그런 처리 과정 있겠습니다
 

27
00:02:17,680 --> 00:02:21,828
그리고 참치를 보관하기 쉽게 캔에 보관을 하고
 

28
00:02:21,853 --> 00:02:24,758
냉장고에 보관하는 일련의 과정
 

29
00:02:24,790 --> 00:02:28,844
이러한 파이프라인을 구축하는 작업이라고 생각하시면 되겠습니다
 

30
00:02:29,493 --> 00:02:35,250
데이터를 수집할 때는 어떤 Batch로 대용량 파일을 한꺼번에 한 번을 받아오거나
 

31
00:02:35,410 --> 00:02:40,441
Kafka나 RabbitMQ 같은 메시징 툴로
실시간 스트리밍으로 수집을 할 수 있습니다 

32
00:02:41,260 --> 00:02:43,636
받아온 데이터의 중복을 제거를 하고
 

33
00:02:43,660 --> 00:02:46,978
그 다음에 enrichment 하거나 cardinality를 최적화하기 위해서
 

34
00:02:47,003 --> 00:02:50,909
Spark라든지 Hive, Presto 같은 분산처리 엔진을 사용하기도 합니다
 

35
00:02:51,280 --> 00:02:53,476
이렇게 정제된 데이터를 빠르게 검색하기 위해서
 

36
00:02:53,500 --> 00:02:57,226
사전에 aggregation하고 뭐 인덱스를 생성해주고
 

37
00:02:57,250 --> 00:03:01,757
저장 효율성을 위한 압축 방법을 선택을 하게 되고요
 

38
00:03:02,050 --> 00:03:04,660
데이터 고가용성을 위해서 분산 파일 시스템에
 

39
00:03:04,730 --> 00:03:08,503
이중화 또는 삼중화를 해서 서버 장애에 대비합니다
 

40
00:03:11,095 --> 00:03:14,907
이렇게 데이터 전처리 과정에 대해서
전체 처리 과정에 대해서 

41
00:03:14,932 --> 00:03:16,533
장황하게 말씀드린 이유는
 

42
00:03:17,080 --> 00:03:21,946
데이터 분석가와 엔지니어가 이런 시스템에서 각각 어떤 포지션을 가지고 있고
 

43
00:03:21,970 --> 00:03:25,923
각기 사용하는 기술 도메인에서 차이를 말씀드리기 위함입니다
 

44
00:03:26,560 --> 00:03:32,005
데이터 엔지니어는 앞서 말씀드린 기술을 바탕으로
데이터 파이프라인을 구축하는 일을 하는 반면에 

45
00:03:32,530 --> 00:03:37,546
분석가는 데이터 그 자체의 도메인 지식과 수리 통계학 지식을 바탕으로
 

46
00:03:37,570 --> 00:03:41,171
데이터를 모델링하고 가치 있는 정보를 추출합니다
 

47
00:03:41,620 --> 00:03:45,316
이러한 분석 과정에서 데이터 파이프라인에 피드백을 주기도 하고
 

48
00:03:45,340 --> 00:03:48,847
데이터 엔지니어가 이를 데이터 파이프라인에 반영하기도 합니다
 

49
00:03:51,130 --> 00:03:54,130
앞서 보여드린 것처럼 시스템만 잘 구축하면 될까요?
 

50
00:03:54,850 --> 00:03:57,662
현실은 또 다른 여러 문제점들이 존재합니다
 

51
00:03:58,270 --> 00:04:00,824
데이터 엔지니어들은
 

52
00:04:00,849 --> 00:04:05,691
generel하게 데이터 구조를 구성을 해서 데이터를 적재해 둡니다
 

53
00:04:05,950 --> 00:04:10,606
하지만 상황마다 분석하고자 하는 데이터 구조가 다르거나
 

54
00:04:10,630 --> 00:04:14,294
기존 데이터 구조 이외에 분석 니즈가 발생하는 경우가 있습니다
 

55
00:04:14,560 --> 00:04:18,286
예를 들어서 일회성으로 데이터 분석이 필요한 경우도 있고요
 

56
00:04:19,120 --> 00:04:25,620
그런 경우는 각각 다른 서비스 도메인 간에 범 서비스적 분석을 하거나
 

57
00:04:26,019 --> 00:04:31,185
프로모션이 진행되고 나서 특정 조건에
따른 통계 데이터가 필요한 경우가 있습니다 

58
00:04:31,209 --> 00:04:35,426
또는 데이터 생성단에서부터 데이터 태깅을 해서
 

59
00:04:35,451 --> 00:04:38,958
데이터 파이프라인이 제대로 구축이 되어 있는지 검증하는 경우도 있습니다
 

60
00:04:39,400 --> 00:04:45,046
이렇게 여러 경우가 있는데 분석가들과
엔지니어 간의 커뮤니케이션 부하가 생기게 되고 

61
00:04:45,070 --> 00:04:48,710
분석가들은 보다 자유로운 데이터 접근에 대한 니즈가 생기게 됩니다
 

62
00:04:49,270 --> 00:04:53,676
하지만 분석가들이 가진 무기만으로는 쉽지 않은 것이 현재 상황입니다
 

63
00:04:55,004 --> 00:04:57,496
방금 분석가들이 가진 무기라고 말씀을 드렸는데
 

64
00:04:57,520 --> 00:05:01,121
현재 전 세계에서 데이터 분석가들이 가장 많이 사용하는 도구인
 

65
00:05:01,215 --> 00:05:03,848
Pandas를 간략하게 소개해 드리도록 하겠습니다
 

66
00:05:05,035 --> 00:05:07,576
Pandas는 관계형 데이터를 빠르고 유연하게
 

67
00:05:07,600 --> 00:05:09,956
효율적으로 처리하는데 사용되는 라이브러리인데요
 

68
00:05:10,360 --> 00:05:13,256
여러 데이터 사이언스 시스템과도 통합이 되고
 

69
00:05:13,281 --> 00:05:17,546
손쉽게 원하는 데이터 분석을 하도록 도와주는 매우 강력한 툴입니다
 

70
00:05:19,030 --> 00:05:22,486
Spark는 데이터 엔지니어들에게 익숙한 도구인데요
 

71
00:05:22,510 --> 00:05:25,666
Spark는 분산 클러스터에서
 

72
00:05:25,713 --> 00:05:31,142
병렬적으로 Job을 빠르게 수행하는 대용량 통합 분석 엔진입니다
 

73
00:05:32,950 --> 00:05:35,918
동시에 여러 테스크를 여러 노드에서 분산해서
 

74
00:05:35,943 --> 00:05:39,707
고민 없이 병렬 처리하는데 매우 강력한 성능을 발휘합니다
 

75
00:05:41,380 --> 00:05:44,896
앞서 말씀드린 Pandas, Spark를 비교해서 말씀드리면
 

76
00:05:44,920 --> 00:05:49,606
Spark 같은 경우는 어떤 액션이 일어나기 전까지는
 

77
00:05:49,630 --> 00:05:54,526
앞선 transform의 DAG를 최적화하는 과정을 통해서
 

78
00:05:54,550 --> 00:05:58,306
그 과정에서 lazy-execution을 채택을 하는데요
 

79
00:05:58,330 --> 00:06:01,962
또한 병렬 처리의 락에 대한 고민이 없이
 

80
00:06:01,987 --> 00:06:07,479
동시성을 확보하기 위해서 내부적으로 immutable한 RDD 구조를 사용을 합니다
 

81
00:06:07,854 --> 00:06:12,244
이와 다르게 Pandas는 명령을 수행하는 즉시에 DataFrame이 수정이 되고
 

82
00:06:12,689 --> 00:06:16,216
하지만 Pandas 같은 경우는 한대 머신에 제한되면서
 

83
00:06:16,243 --> 00:06:18,985
Scale up이 불가능하다는 단점을 가지고 있습니다
 

84
00:06:20,712 --> 00:06:24,844
Pandas를 통해서 다뤄야 하는 데이터가 10GB가 넘어가게 되면은
 

85
00:06:24,922 --> 00:06:26,954
분석 성능의 저하가 체감이 되고요
 

86
00:06:27,220 --> 00:06:31,595
100GB가 넘어가면은 한대 컴퓨터로는
데이터 분석하는 것이 매우 어려워집니다 

87
00:06:32,700 --> 00:06:35,919
어떤 간단한 분석 코드를 돌리는데 데이터가 커지니까
 

88
00:06:35,944 --> 00:06:38,850
몇 시간이 걸린 경우를 아마 경험을 해보셨을 겁니다
 

89
00:06:39,460 --> 00:06:43,426
그래서 분석성능 향상을 위해서 Spark를 새로 학습을 하자니
 

90
00:06:43,450 --> 00:06:46,543
러닝커브가 굉장히 존재하게 되고요
 

91
00:06:46,957 --> 00:06:51,046
정리하자면 Pandas를 오래 사용해온 분석가 입장에서는
 

92
00:06:51,070 --> 00:06:53,596
Pandas는 굉장히 쓰기 쉽지만
 

93
00:06:53,620 --> 00:07:00,179
그리고 Spark를 새로 배워야 하고 Spark는
익숙하지 않지만 매우 빠르고 강력합니다 

94
00:07:03,190 --> 00:07:05,993
그렇다면 쓰기 쉽지만 빠른 도구가 없을까요?
 

95
00:07:06,018 --> 00:07:10,291
그래서 이러한 고민을 덜어주기 위해서
나온 프로젝트가 바로 Koalas입니다 

96
00:07:11,440 --> 00:07:16,236
2019년 4월 24일에 발표된 굉장히 따끈따끈한 프로젝트인데요
 

97
00:07:16,480 --> 00:07:19,246
기존 Pandas 코드를 거의 그대로 사용하면서
 

98
00:07:19,270 --> 00:07:24,160
내부적으로는 Spark 엔진을 사용해서 대규모 데이터를 분석할 수 있습니다
 

99
00:07:24,803 --> 00:07:28,654
오른쪽에 보시듯이 conda나 pip로 간단하게 설치 가능합니다
 

100
00:07:31,810 --> 00:07:35,755
Koalas는 Spark를 최초 제작한 Databricks사 에서
 

101
00:07:35,860 --> 00:07:38,239
주도적으로 개발되고 있는 프로젝트입니다
 

102
00:07:38,680 --> 00:07:43,172
발표한 지 1년이 조금 지났는데 전 세계적으로 굉장히 빠르게 성장하고 있습니다
 

103
00:07:43,690 --> 00:07:46,306
하루 다운로드 수가 3만 건 이상이며
 

104
00:07:46,330 --> 00:07:51,158
전 세계적으로 PySpark 사용자의 20%가 Koalas를 사용하고 있습니다
 

105
00:07:54,010 --> 00:07:57,080
기본적인 코드를 보며 비교해 보겠습니다
 

106
00:07:58,447 --> 00:08:03,400
왼쪽 위에 코드를 보시면 데이터를 로컬에서 읽어와서 DataFrame을 생성하고
 

107
00:08:03,540 --> 00:08:08,141
컬럼명을 지정하고 새로운 컬럼을 생성하는 간단한 코드입니다
 

108
00:08:09,130 --> 00:08:12,706
보시듯이 동일한 역할을 하는 PySpark 같은 경우는
 

109
00:08:12,731 --> 00:08:15,325
코드 전환을 위해서 많은 작업이 필요해 보입니다
 

110
00:08:17,110 --> 00:08:22,396
Koalas 코드 예시를 보시면 라이브러리의 호출단만 이렇게 변경을 해주면
 

111
00:08:22,420 --> 00:08:24,638
매우 편리하게 활용할 수 있습니다
 

112
00:08:27,250 --> 00:08:31,367
그러면 Koalas가 어떻게 이걸 가능하게 했는지 살펴보겠습니다
 

113
00:08:32,080 --> 00:08:35,351
Koalas 내부에는 Spark DataFrame을 포함하는
 

114
00:08:35,376 --> 00:08:37,954
Internal Frame 이라는 데이터 구조를 가지고 있습니다
 

115
00:08:38,800 --> 00:08:42,616
Internal Frmae은 Pandas API를 지원하기 위해서
 

116
00:08:42,640 --> 00:08:48,475
Koalas의 컬럼명과 인덱스명이 스파크의 컬럼명으로 매핑된 정보를 포함합니다
 

117
00:08:49,210 --> 00:08:55,456
또한 Spark와 Pandas의 DataFrame으로 전환하는
로직을 제공해 주어서 심리스한 전환이 가능한데요 

118
00:08:55,480 --> 00:08:58,011
이는 뒤에 예시로 보여드리도록 하겠습니다
 

119
00:08:59,350 --> 00:09:03,771
Internal Frame은 내부적으로 Immutable한
Spark DataFrame을 가지고 있기 때문에 

120
00:09:04,006 --> 00:09:07,036
데이터를 수정하는 API 호출의 수행이 됐을 때
 

121
00:09:07,060 --> 00:09:11,497
새로운 Spark DataFrame을 카피해서 생성을 해줍니다
 

122
00:09:11,800 --> 00:09:14,696
만약에 Spark DataFrame 자체 데이터 변환이 없을 경우에는
 

123
00:09:14,721 --> 00:09:17,916
Internal Frame만 정보만 새로 카피 되는 경우도 있습니다
 

124
00:09:23,545 --> 00:09:29,246
데모를 통해 Koalas의 기본 사용법과
Pandas 분석된 코드를 

125
00:09:29,271 --> 00:09:32,466
Koalas로 전환하는 예시를 보여드리도록 하겠습니다
 

126
00:09:34,120 --> 00:09:37,659
Pandas 같은 경우는 다음과 같이 import 해서 사용을 하고요
 

127
00:09:38,020 --> 00:09:41,090
Koalas는 다음과 같이 import 해서
 

128
00:09:41,620 --> 00:09:46,786
각각 pd와 ks로 Koalas와 Pandas 라이브러리를
 

129
00:09:46,810 --> 00:09:49,127
호출해서 사용을 해보도록 하겠습니다
 

130
00:09:49,720 --> 00:09:54,704
일단 첫째로 Pandas와 Koalas DataFrame간의
전환을 보여드리도록 하겠습니다 

131
00:09:56,680 --> 00:09:58,930
이렇게 Pandas DaraFrame을 생성해서
 

132
00:09:59,740 --> 00:10:05,115
from_pandas라는 함수를 사용해서 바로
Koalas DataFrame으로 전환할 수 있습니다 

133
00:10:05,770 --> 00:10:09,207
전환된 Koalas DataFrame을 다시 to_pandas를 통해
 

134
00:10:09,232 --> 00:10:11,974
전환한 모습을 확인하실 수 있습니다
 

135
00:10:12,580 --> 00:10:18,798
Spark와 Koalas 간에 DataFrame 전환도 마찬가지로 굉장히 쉽게 가능한데요
 

136
00:10:19,376 --> 00:10:23,236
Spark DataFrame, Pandas 그리고 Koalas DataFrame 간에
 

137
00:10:23,260 --> 00:10:26,252
굉장히 심리스한 전환을 확인하실 수 있습니다
 

138
00:10:27,910 --> 00:10:32,596
이거는 Koalas를 통해서 DataFrame을 직접 생성해서
 

139
00:10:32,620 --> 00:10:37,576
예를 들어 A, B 컬럼에 차원 데이터가 있고 C, D에 메트릭 컬럼이 있을 때
 

140
00:10:37,600 --> 00:10:42,045
기존에 사용하던 Pandas 라이브러리의 함수를
 

141
00:10:42,070 --> 00:10:44,536
그대로 사용해서 결과를 확인해볼 수 있습니다
 

142
00:10:44,560 --> 00:10:46,606
예를 들어서 이 describe 같은 경우는
 

143
00:10:47,980 --> 00:10:52,839
DataFrame에 있는 매트릭들의 요약정보를 요약해서 보여줍니다
 

144
00:10:53,740 --> 00:10:58,816
groupby도 마찬가지로 어떤 A 컬럼의 sum을 해서 결과를 내봤고
 

145
00:10:58,840 --> 00:11:03,738
그 다음에 여러 개 컬럼도 다음과 같이
groupby한 결과를 확인하실 수 있습니다 

146
00:11:04,330 --> 00:11:07,283
matplotlib도 마찬가지로
 

147
00:11:07,720 --> 00:11:12,626
Koalas Serise와 Koalas DataFrame에 적용을 해서
 

148
00:11:13,210 --> 00:11:18,316
이렇게 바로 시각화 라이브러리와
integration 되는 것을 확인하실 수 있습니다 

149
00:11:21,256 --> 00:11:26,201
이 예시는 공공데이터 포털의 상가업소정보 데이터를 가지고
 

150
00:11:26,256 --> 00:11:30,021
지도에 시각화 해보는 상권 분석을 해보는 예시를
 

151
00:11:30,046 --> 00:11:31,733
Koalas로 전환한 건데요
 

152
00:11:32,140 --> 00:11:35,146
공공데이터 포털에서 데이터 하나하나 크기가 크기 때문에
 

153
00:11:35,171 --> 00:11:38,186
네 개의 파일로 나눠서 제공을 하고 있습니다
 

154
00:11:39,640 --> 00:11:44,086
그러면 이 파일을 각각 Pandas DataFrame으로 불러와서
 

155
00:11:44,110 --> 00:11:47,149
concat을 이용해서 하나의 DataFrame으로 합쳐서
 

156
00:11:47,250 --> 00:11:51,929
컬럼수와 DataFrame의 로우 수를 한번 확인해보도록 하겠습니다
 

157
00:11:52,780 --> 00:11:57,100
총 로우 수는 약270만 건 정도가 되는데
 

158
00:11:57,910 --> 00:12:02,167
데이터 용량이 크기 때문에 취합하는데도
시간이 오래 걸리는 것을 볼 수 있습니다 

159
00:12:04,180 --> 00:12:08,896
이렇게 취합한 데이터를 특정 우리가 원하는 컬럼만 필터링하고
 

160
00:12:08,920 --> 00:12:15,420
그다음에 서울지역에 업종분류명이 '커피'인 것 중에서
 

161
00:12:15,580 --> 00:12:19,606
우리가 원하는 어떤 커피숍 목록만 추출을 한 다음에
 

162
00:12:19,631 --> 00:12:25,052
브랜드명을 이제 cardinality 한 4개로 그룹화에서 줄이는 모습을
 

163
00:12:25,544 --> 00:12:26,926
보실 수가 있는데
 

164
00:12:27,160 --> 00:12:29,574
방금 취합한 속도를 봤을 때
 

165
00:12:29,599 --> 00:12:32,776
총 데이터 수는 이렇게 되고 38.5초가 소요된 것을 확인하실 수가 있습니다
 

166
00:12:34,558 --> 00:12:37,120
이 코드를 Koalas로 한번 전환을 해보겠습니다
 

167
00:12:37,729 --> 00:12:42,557
아주 간단하게 호출하는 부분만 이렇게 수정을 해서
 

168
00:12:42,869 --> 00:12:44,681
다시 한 번 수행을 해보도록 하겠습니다
 

169
00:12:45,048 --> 00:12:48,594
이렇게 하면은 내부적으로는 Spark를 통해서
 

170
00:12:49,438 --> 00:12:53,570
Spark 엔진의 힘을 가지고 데이터를 추출해서 합쳤을때
 

171
00:12:53,875 --> 00:12:59,609
지금 보시면은 9.16초로 속도가 약 3~4배 정도
빨라진 것을 확인하실 수 있습니다 

172
00:13:01,765 --> 00:13:05,327
이렇게 해서 전처리를 동일한 코드를 가지고
 

173
00:13:05,890 --> 00:13:10,244
Pandas에서도 마찬가지로 같은 코드로 전처리를 할 수가 있고요
 

174
00:13:10,479 --> 00:13:14,049
Koalas도 이렇게 수행을 해서 봤을 때 결과적으로
 

175
00:13:14,074 --> 00:13:20,158
서울지역에 위치한 각각 카페별 업소의 수가 나타나게 되고
 

176
00:13:21,619 --> 00:13:24,736
다음은 folium이란 라이브러리를 사용을 해서
 

177
00:13:24,767 --> 00:13:28,399
지도에 위도와 경도를 한번 찍어서 시각화해서
 

178
00:13:29,057 --> 00:13:32,243
상권을 확인해보는 그런 예제입니다
 

179
00:13:32,931 --> 00:13:35,352
이 예제는 어떤 특정 모듈이
 

180
00:13:36,507 --> 00:13:40,007
특정 모듈의 인풋이 Pandas로만 받을 수 있다고 가정을 했을 때
 

181
00:13:40,108 --> 00:13:43,201
이런 식으로 다시 Pandas DataFrame으로 수정을 해서
 

182
00:13:44,632 --> 00:13:46,796
어떤 모듈의 입력으로 넣었을 때
 

183
00:13:46,921 --> 00:13:49,921
기존의 코드를 활용을 해서 이렇게 바로
 

184
00:13:49,946 --> 00:13:55,024
시각화해서 분석을 해볼 수 있는 예시를 보여 드렸습니다
 

185
00:13:56,797 --> 00:13:59,257
기존의 작성하신 Pandas 코드를
 

186
00:13:59,297 --> 00:14:02,679
Koalas로 전환할 때 필요한 팁을 공유드리도록 하겠습니다
 

187
00:14:03,554 --> 00:14:06,272
적은 양의 데이터 처리는 Pandas가 더 빠릅니다
 

188
00:14:06,889 --> 00:14:10,982
분산 데이터 처리의 네트워크IO나 DAG 최적화 과정이 존재하기 때문에
 

189
00:14:11,349 --> 00:14:15,067
Spark 같은 경우는 수기가 바이트 이하의 분석 데이터는
 

190
00:14:15,092 --> 00:14:17,145
Pandas를 사용하는 게 더 빠를 수 있습니다
 

191
00:14:17,980 --> 00:14:21,425
그리고 대부분의 사용자들이 많이 사용하는 Pandas 함수는
 

192
00:14:21,450 --> 00:14:23,379
대부분 Koalas에 구현이 되어 있습니다
 

193
00:14:23,380 --> 00:14:29,403
그러나 아직 구현되어 있지 않은 그런 Pandas API 를 사용하고 싶은 경우에
 

194
00:14:29,559 --> 00:14:34,546
to_pandas를 사용을해서 Koalas DataFrame을 Pandas로 전환한 후에
 

195
00:14:34,570 --> 00:14:37,874
Pandas 함수를 적용해서 다시 Koalas로 변환하는 경우도 있고
 

196
00:14:39,160 --> 00:14:42,910
또는 공식문서에서 더 권장하는 방법인데요
 

197
00:14:43,360 --> 00:14:47,383
map_in_pandas를 사용을 해서 오른쪽 예시와 같이
 

198
00:14:47,408 --> 00:14:49,756
Pandas 함수를 인자로 넘겨주면
 

199
00:14:49,780 --> 00:14:52,944
그대로 Pandas 함수와 통합되어서 사용이 가능합니다
 

200
00:14:53,410 --> 00:14:57,917
그리고 Koalas를 사용할 때 주의하셔야 될 점을 말씀드리겠습니다
 

201
00:14:59,003 --> 00:15:03,040
Spark는 RDD를 분산해서 저장하기 때문에 데이터 순서를 보장하지 않습니다
 

202
00:15:03,065 --> 00:15:08,369
따라서 Koalas는 인덱스 순서도 보장하게 하는 여러 옵션을 추가적으로 제공을 하는데
 

203
00:15:08,830 --> 00:15:11,594
옵션에 대한 이러한 이해가 부족한채로 사용하게 되면
 

204
00:15:11,619 --> 00:15:15,892
예를 들어서 소팅 같은 경우에 한대의 머신에 모든
데이터를 불러올 수 있기 때문에 

205
00:15:15,917 --> 00:15:17,728
사용하는데 주의하셔야 합니다
 

206
00:15:18,220 --> 00:15:22,726
또는 NaN 같은 처리가 Pandas와 Spark가 기존에 다르기 때문에
 

207
00:15:22,750 --> 00:15:28,606
원하는 결과가 Koalas를 사용했을 때 나온 결과와 다룰 수 있다는 점을
 

208
00:15:28,630 --> 00:15:30,833
유의하시고 사용하시기 바랍니다
 

209
00:15:32,380 --> 00:15:36,496
그리고 Koalas를 사용할 때 가장 유용하게
사용할 수 있는 함수가 apply입니다 

210
00:15:36,520 --> 00:15:42,554
모든 로우에 대해서 Spark Worker들이
병렬적으로 우리가 구현을 Job을 수행을 하는데요 

211
00:15:42,579 --> 00:15:48,016
예를 들어서 웹스크래핑을 하거나 각 로우에 딕셔너리 매핑을 할 때 활용하면
 

212
00:15:48,071 --> 00:15:51,938
매우 유용하게 굉장히 빠른 결과를 얻으실 수 있습니다
 

213
00:15:54,220 --> 00:15:57,751
Koalas를 실제로 활용한 회사를 하나 소개해 드리도록 하겠습니다
 

214
00:15:58,210 --> 00:16:03,092
Hyperloop는 일론 머스크가 설계한 굉장히 혁신적인 차세대 교통수단인데요
 

215
00:16:03,730 --> 00:16:09,151
Virgin Hyperloop One 이라는 회사는 이것을
상용화하기 위해서 노력하고 있는 회사입니다 

216
00:16:09,520 --> 00:16:13,301
Hyperloop 운행을, 개발한 Hyperloop를 실험을 하고
 

217
00:16:13,332 --> 00:16:16,683
실험 데이터를 분석하는데 기존에 Pandas 코드를 사용을 했습니다
 

218
00:16:17,140 --> 00:16:19,897
실험을 하면 할수록 데이터가 점점 증가하면서
 

219
00:16:19,960 --> 00:16:23,364
Pandas만으로는 도저히 분석을 할 수가 없게 됐습니다
 

220
00:16:23,389 --> 00:16:28,818
그래서 기존의 Pandas 코드를 전부 Spark로 전환을 하느라 고군분투를 했는데
 

221
00:16:29,260 --> 00:16:33,252
Koalas를 도입을 했고 기존의 코드를 1%만 수정을 하고
 

222
00:16:33,277 --> 00:16:36,860
10배 이상의 분석 성능 향상을 나타냈다고 합니다
 

223
00:16:38,950 --> 00:16:43,379
이 그래프를 보시면 오른쪽으로 갈수록
데이터 로우 수가 증가하는 것을 나타냅니다 

224
00:16:43,810 --> 00:16:47,626
Pandas 처리 시간을 보면 데이터가 증가함에 따라서
 

225
00:16:47,650 --> 00:16:51,548
Exponential 하게 처리시간이 증가하는 것을 볼 수 있습니다
 

226
00:16:53,230 --> 00:16:56,190
빨간색의 Koalas 처리 시간을 보면
 

227
00:16:56,740 --> 00:17:00,886
PySpark 성능 향상에 따라서 속도가 향상되는 걸 확인할 수 있습니다
 

228
00:17:00,910 --> 00:17:04,433
물론 PySpark를 그대로 사용하는 것보다는 약간 느림니다
 

229
00:17:05,110 --> 00:17:08,781
그러면 여기서 여러분이 얼마나 많은 컴퓨터를 구매할 수 있느냐
 

230
00:17:09,490 --> 00:17:13,652
그 능력이 얼마가 되느냐에 따라서 처리시간을 줄일 수가 있습니다
 

231
00:17:13,677 --> 00:17:17,231
그러나 Pandas 같은 경우는 아무리 자원이 있어도
 

232
00:17:17,859 --> 00:17:23,358
분산 확장이, 스케일이 불가능하기 때문에 처리시간이 줄어들지 않습니다
 

233
00:17:26,745 --> 00:17:31,335
현재 Koalas는 1.0.0 버전을 최근에 발표를 했고요
 

234
00:17:31,359 --> 00:17:33,846
계속 개선되고 성장하고 있습니다
 

235
00:17:34,270 --> 00:17:37,126
내부에는 모두 파이썬 코드로 개발이 되어 있고요
 

236
00:17:37,150 --> 00:17:40,759
특이점은 국내에 메인 Commiter가 두 분이 계십니다
 

237
00:17:41,530 --> 00:17:44,576
오픈소스 Contribution에 관심 있는 파이썬 개발자 분들이
 

238
00:17:44,795 --> 00:17:48,818
이런 글로벌 프로젝트에 기여를 할 수 있는 굉장히 좋은 기회라고 생각을 합니다
 

239
00:17:49,150 --> 00:17:53,086
그래서 저도 가끔 퇴근 후에 contribution을 하고 있긴 한데
 

240
00:17:53,110 --> 00:17:55,216
많이 많은 분들이 참여를 해주시면
 

241
00:17:55,240 --> 00:17:58,255
분석가들이 손쉽게 빅데이터를 다룰 수 있는
 

242
00:17:58,280 --> 00:18:01,536
강력한 도구를 만드는 데 기여할 수 있을 것입니다
 

243
00:18:02,740 --> 00:18:04,585
제 발표는 여기까지고요
 

244
00:18:05,080 --> 00:18:09,070
질문 사황은 여기 해당하는 메일 주시면 감사하겠습니다
 

245
00:18:09,550 --> 00:18:11,351
제 발표를 들어주셔서 감사합니다


